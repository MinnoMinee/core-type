{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import pickle\n",
    "import laspy\n",
    "import matplotlib.pyplot    as plt\n",
    "import numpy                as np\n",
    "import cupy                 as cp\n",
    "import open3d               as o3d\n",
    "from scipy.stats            import skew, kurtosis\n",
    "from scipy.ndimage          import convolve\n",
    "from cupyx.scipy.ndimage    import convolve as cpconvolve\n",
    "from collections            import deque\n",
    "from scipy.interpolate      import interp1d\n",
    "from scipy.spatial import KDTree\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ljx_processor:\n",
    "    def __init__(self, file_path, DBSCAN_model_path = None, window_size = 10, y_shift = 0, name=None,  \n",
    "                strong_edge_threshold = 80, weak_edge_threshold = 30, strong_PCA_threshold = 0.01, weak_PCA_threshold = 0.0075, colourmap = 'binary'):\n",
    "        if DBSCAN_model_path is None:\n",
    "            current_dir = os.getcwd()\n",
    "            self.DBSCAN_model_path = os.path.join(current_dir, 'cluster_kd_tree.pkl')\n",
    "        else: \n",
    "            self.DBSCAN_model_path = DBSCAN_model_path\n",
    "            \n",
    "        self.file_path = file_path\n",
    "        self.colourmap = colourmap\n",
    "        self.name = name if name else file_path\n",
    "        self.window_size = window_size\n",
    "        self.strong_edge_threshold = strong_edge_threshold\n",
    "        self.weak_edge_threshold = weak_edge_threshold\n",
    "        self.strong_PCA_threshold = strong_PCA_threshold\n",
    "        self.weak_PCA_threshold = weak_PCA_threshold\n",
    "        self.y_shift = y_shift\n",
    "        self.tree = None\n",
    "        self.labels = None\n",
    "\n",
    "        self.correction_windows = None\n",
    "        self.labeled_x_values = None   \n",
    "\n",
    "        self.edge_array = None\n",
    "        self.gradient = None\n",
    "        self.PCA_mask = None\n",
    "        self.x_start = None\n",
    "        self.x_stop = None\n",
    "        self.y_seed_point = None\n",
    "        self.y_offset = None\n",
    "        self.vectors = []\n",
    "\n",
    "        \n",
    "\n",
    "        self._build_processor()\n",
    "    \n",
    "    def _collect_garbage(self):\n",
    "        self.tree = None\n",
    "        self.labels = None\n",
    "        self.correction_windows = None\n",
    "        self.labeled_x_values = None\n",
    "        self.gradient = None\n",
    "        self.PCA_mask = None\n",
    "        self.component_parameters_path = None\n",
    "        self.lidar2xrf_path = None\n",
    "        self.bpc_path = None\n",
    "    \n",
    "    def _find_files(self):\n",
    "        self.component_parameters_path = None\n",
    "        self.lidar2xrf_path = None\n",
    "        self.bpc_path = None\n",
    "\n",
    "        for file_name in os.listdir(self.file_path):\n",
    "            full_path = os.path.join(self.file_path, file_name)\n",
    "            if file_name.endswith(\".component_parameters.txt\"):\n",
    "                self.component_parameters_path = full_path\n",
    "            elif file_name.endswith(\".lidar2xrf\"):\n",
    "                self.lidar2xrf_path = full_path\n",
    "            elif file_name.endswith(\".bpc\"):\n",
    "                self.bpc_path = full_path\n",
    "\n",
    "    def _validate_files(self):\n",
    "        missing_files = [\n",
    "            name for name, path in {\n",
    "                \"bpc\": self.bpc_path,\n",
    "            }.items() if path is None\n",
    "        ]\n",
    "\n",
    "        non_essential_mising_files = [\n",
    "            name for name, path in {\n",
    "                \"component_parameters\": self.component_parameters_path,\n",
    "                \"lidar2xrf\": self.lidar2xrf_path,\n",
    "            }.items() if path is None\n",
    "        ]\n",
    "\n",
    "        if missing_files:\n",
    "            raise FileNotFoundError(f\"Missing required files: {', '.join(missing_files)}\")\n",
    "        if non_essential_mising_files:\n",
    "            print (f\"   Missing: {', '.join(non_essential_mising_files)}, contents will be assumed\")\n",
    "    \n",
    "    def _load_component_parameters(self):\n",
    "        self.x_start = 50000\n",
    "        self.x_stop = 0\n",
    "        self.y_offset = 0\n",
    "        if self.component_parameters_path is not None:\n",
    "            with open(self.component_parameters_path) as file:\n",
    "                lines = file.readlines()\n",
    "                for line in lines:\n",
    "                    if \"XRAY_DPP[Acquisition]#0.X.Start:\" in line:\n",
    "                        self.x_start = float(line.split(\":\")[1].strip())\n",
    "                    if \"XRAY_DPP[Acquisition]#0.X.Stop:\" in line:\n",
    "                        self.x_stop = float(line.split(\":\")[1].strip())\n",
    "                    if \"XRAY_DPP[Acquisition]#0.Y.Start:\" in line:\n",
    "                        self.y_offset = float(line.split(\":\")[1].strip())\n",
    "    \n",
    "    def _load_lidar_data(self):\n",
    "        if self.lidar2xrf_path is None:\n",
    "            self.transformation_matrix = np.array([[1,0,0,192],\n",
    "                                                  [0,-1,0,9.3],\n",
    "                                                  [0,0,-1,53.8],\n",
    "                                                  [0,0,0,1]])\n",
    "        else: \n",
    "            with open(self.lidar2xrf_path) as file:\n",
    "                lines = file.readlines()\n",
    "                self.transformation_matrix = np.array([list(map(float, line.strip().split(\",\"))) for line in lines])\n",
    "\n",
    "        self.point_cloud = np.fromfile(self.bpc_path, dtype=np.float32).reshape(-1, 3)\n",
    "    \n",
    "        self.original_cloud_limits = [np.nanmax(self.point_cloud[:,0]),np.nanmin(self.point_cloud[:,0]), len(np.unique(self.point_cloud[:,0])),\n",
    "                                      np.nanmax(self.point_cloud[:,1]),np.nanmin(self.point_cloud[:,1]), len(np.unique(self.point_cloud[:,1])),\n",
    "                                      np.nanmax(self.point_cloud[:,2]),np.nanmin(self.point_cloud[:,2]), len(self.point_cloud[:,2])]\n",
    "\n",
    "        self.point_cloud = (np.hstack((self.point_cloud, np.ones((self.point_cloud.shape[0], 1)))) @ self.transformation_matrix.T)[:,:3]\n",
    "\n",
    "        self.translated_cloud_limits = [np.nanmax(self.point_cloud[:,0]),np.nanmin(self.point_cloud[:,0]), len(np.unique(self.point_cloud[:,0])),\n",
    "                                      np.nanmax(self.point_cloud[:,1]),np.nanmin(self.point_cloud[:,1]), len(np.unique(self.point_cloud[:,1])),\n",
    "                                      np.nanmax(self.point_cloud[:,2]),np.nanmin(self.point_cloud[:,2]), len(self.point_cloud[:,2])]\n",
    "    \n",
    "    def _get_gradient(self):\n",
    "        array_z = cp.array(self.point_cloud, dtype=cp.float32)\n",
    "        y_values = self.i_to_y_list\n",
    "        sobel_y = cp.array([\n",
    "                [-20.75,],\n",
    "                [ -11.6,],\n",
    "                [ -6.27,],\n",
    "                [    -2,],\n",
    "                [     0,],\n",
    "                [     2,],\n",
    "                [  6.27,],\n",
    "                [  11.6,],\n",
    "                [ 20.75,]\n",
    "        ])\n",
    "        sobel_x = sobel_y.T\n",
    "\n",
    "        x_grad_z = cp.abs(cpconvolve(array_z, sobel_y))\n",
    "        y_grad_z = cp.abs(cpconvolve(array_z, sobel_x))\n",
    "        magnitude_z = cp.sqrt(x_grad_z**2 + y_grad_z**2)\n",
    "        y_grad_z = cp.abs(cpconvolve(magnitude_z, sobel_x))\n",
    "        magnitude = cp.sqrt(x_grad_z**2 + y_grad_z**2)\n",
    "\n",
    "        y_bottom = np.argmin(np.abs(y_values - self.window_size))\n",
    "        y_top = np.argmin(np.abs(y_values + self.window_size))\n",
    "\n",
    "        magnitude[:y_top, :] = 0\n",
    "        magnitude[y_bottom:, :] = 0\n",
    "\n",
    "        self.gradient = cp.asnumpy(magnitude)\n",
    "\n",
    "    def _create_PCA_mask(self,y_window = 10, x_window = 10, batch_size = 100, i = 1, **kwargs):\n",
    "        for key, value in kwargs.items():\n",
    "            if value is not None and hasattr(self, key):\n",
    "                setattr(self, key, value)\n",
    "\n",
    "        s = self.strong_PCA_threshold\n",
    "        w = self.weak_PCA_threshold\n",
    "        pc = cp.array(self.point_cloud)\n",
    "        y_values = self.i_to_y_list\n",
    "\n",
    "        y_range, x_range = 2 * y_window + 1, 2 * x_window + 1\n",
    "\n",
    "        y_bottom = np.argmin(np.abs(y_values - self.window_size))\n",
    "        y_top = np.argmin(np.abs(y_values + self.window_size))\n",
    "\n",
    "        x_n = cp.arange(-x_window, x_window + 1) /6.5\n",
    "        y_n = cp.arange(-y_window, y_window + 1) /6.5\n",
    "        valid_x = cp.repeat(x_n, y_range).flatten()\n",
    "        valid_y = cp.tile(y_n, x_range).flatten()\n",
    "        eigvals_2 = cp.zeros_like(pc) \n",
    "        pc = cp.pad(pc, ((y_window,y_window), (x_window,x_window)), mode='edge')\n",
    "\n",
    "        for x in range(x_window, pc.shape[1] - x_window, batch_size):\n",
    "            for y in range(y_window, pc.shape[0] - y_window, batch_size):\n",
    "                batch = pc[y - y_window:y + batch_size + y_window, x - x_window:x + batch_size + x_window]\n",
    "\n",
    "                points = cp.lib.stride_tricks.sliding_window_view(batch, (y_range, x_range))\n",
    "\n",
    "                height, width = points.shape[:2]\n",
    "                points = points.reshape(height, width, y_range * x_range)\n",
    "\n",
    "                points = cp.stack((\n",
    "                    cp.broadcast_to(valid_x, (height, width, y_range * x_range)),\n",
    "                    cp.broadcast_to(valid_y, (height, width, y_range * x_range)),\n",
    "                    points), axis=2)\n",
    "\n",
    "                mean_vals = cp.mean(points[:, :, 2, :], axis=2)\n",
    "                points[:, :, 2, :] -= mean_vals[..., None]\n",
    "\n",
    "                cov_matrices = cp.einsum('...ik,...jk->...ij', points, points) / (y_range * x_range - 1)\n",
    "\n",
    "                eigvals = cp.linalg.eigvalsh(cov_matrices)\n",
    "                print(eigvals[0,0])\n",
    "                e2 = eigvals[:, :, i] \n",
    "\n",
    "                eigvals_2[y - y_window:y + batch_size - y_window, x - x_window:x + batch_size - x_window] = e2\n",
    "\n",
    "        eigvals_2 = cp.asnumpy(eigvals_2)\n",
    "\n",
    "        eigvals[:y_bottom,:] = 0\n",
    "        eigvals[y_top:,:] = 0\n",
    "        neighbours = [(-1, -1), (-1, 0), (-1, 1), (0, -1), (0, 1), (1, -1), (1, 0), (1, 1)]\n",
    "        strong_y, strong_x = np.where(eigvals_2 >= s)\n",
    "        weak_values = (eigvals_2 >= w) & (eigvals_2 < s).astype(np.uint8) \n",
    "        return_array = np.zeros_like(eigvals_2, dtype=cp.uint8)\n",
    "        \n",
    "        cp.get_default_memory_pool().free_all_blocks()\n",
    "\n",
    "        queue = deque(zip(strong_y, strong_x))\n",
    "        while queue:\n",
    "            y, x = queue.popleft() \n",
    "            return_array[y, x] = 1\n",
    "            for dy, dx in neighbours:\n",
    "                ny, nx = y + dy, x + dx\n",
    "                if 0 <= ny < weak_values.shape[0] and 0 <= nx < weak_values.shape[1]:\n",
    "                    if weak_values[ny, nx]:\n",
    "                        weak_values[ny, nx] = 0 \n",
    "                        queue.append((ny, nx)) \n",
    "        del weak_values \n",
    "\n",
    "        self.PCA_mask = return_array\n",
    "\n",
    "    def _get_props(self, distribution1, distribution2):\n",
    "            properties = []\n",
    "            return_properties = []\n",
    "\n",
    "            variance =  np.var(distribution1) *((10/self.window_size)**2)\n",
    "            skw = skew(distribution1)\n",
    "            kurt = kurtosis(distribution1)\n",
    "            mean = np.sqrt(np.mean(np.abs(distribution2)))\n",
    "            max = np.sqrt(np.max(np.abs(distribution2)))\n",
    "\n",
    "            \n",
    "            properties.append(variance)\n",
    "            properties.append(skw)\n",
    "            properties.append(kurt)\n",
    "\n",
    "            norm = np.linalg.norm(properties)\n",
    "            \n",
    "            if norm > 0:\n",
    "                properties = [x / norm for x in properties]\n",
    "\n",
    "            z = properties[0]\n",
    "\n",
    "            return_properties.append(mean)\n",
    "            return_properties.append(max)\n",
    "            return_properties.append(np.abs(properties[1]))\n",
    "            return_properties.append(np.arctan(z)/(np.pi/2))\n",
    "\n",
    "            self.vectors.append(return_properties)\n",
    "\n",
    "\n",
    "            return return_properties, np.uint8(properties[1] > 0)\n",
    "        \n",
    "    def _load_DBSCAN_model(self):\n",
    "            if (self.tree is None) or (self.labels is None):\n",
    "                with open(self.DBSCAN_model_path, 'rb') as f:\n",
    "                    self.tree, self.labels = pickle.load(f)\n",
    "\n",
    "    def _build_processor(self):\n",
    "        self._find_files()\n",
    "        self._validate_files()\n",
    "        self._load_component_parameters()\n",
    "        self._load_lidar_data()\n",
    "        \n",
    "        mask = (self.point_cloud[:,0] <= self.x_start) & (self.point_cloud[:,0] >= self.x_stop) & ((self.point_cloud[:,1]) <= (self.window_size + 5 + self.y_shift)) & ((self.point_cloud[:,1]) >=  -(self.window_size + 5 - self.y_shift))\n",
    "        self.point_cloud = self.point_cloud[mask]\n",
    "        self.point_cloud[:,1] -= self.y_shift\n",
    "\n",
    "        min_z = np.nanmax(self.point_cloud[:,2])\n",
    "\n",
    "        x_values = np.unique(self.point_cloud[:,0])\n",
    "        y_values = np.unique(self.point_cloud[:,1]) \n",
    "        x_range = len(x_values)\n",
    "\n",
    "        x_value_dict = {x: index for index,x in enumerate(x_values)}\n",
    "        y_value_dict = {y: index for index,y in enumerate(y_values)}\n",
    "\n",
    "        point_array = np.full((len(y_values), x_range),np.nan)\n",
    "        point_dictionary = {(row[0],row[1]): (index, row[2]) for index,row in enumerate(self.point_cloud)}\n",
    "\n",
    "        for x in range (x_range):\n",
    "            for y in range (len(y_values)):\n",
    "                x_val = x_values[x]\n",
    "                y_val = y_values[y]\n",
    "\n",
    "                point_z = point_dictionary.get((x_val,y_val))\n",
    "\n",
    "                if point_z[1] != min_z:\n",
    "                    point_array[y,x] = point_z[1]\n",
    "                else:\n",
    "                    point_array[y,x] = 250\n",
    "        \n",
    "        self.y_seed_point = np.argmin(np.abs(y_values))\n",
    "        self.point_cloud = point_array\n",
    "        self.x_to_i_dict = x_value_dict\n",
    "        self.i_to_x_list = x_values\n",
    "        self.y_to_i_dict = y_value_dict\n",
    "        self.i_to_y_list = y_values\n",
    "\n",
    "    def _create_edge_array(self,  **kwargs):\n",
    "        for key, value in kwargs.items():\n",
    "            if value is not None and hasattr(self, key):\n",
    "                setattr(self, key, value)\n",
    "\n",
    "        self._get_gradient()\n",
    "        if self.PCA_mask is None:\n",
    "            self._create_PCA_mask()\n",
    "\n",
    "\n",
    "        y_values = self.i_to_y_list\n",
    "        neighbours = [(-1, 0), (0, -1), (0, 1), (1, 0)]\n",
    "    \n",
    "        result_array = np.zeros_like(self.gradient)\n",
    "\n",
    "        masked_gradient = self.gradient * self.PCA_mask \n",
    "        \n",
    "        strong_y, strong_x = np.where(masked_gradient >= self.strong_edge_threshold)\n",
    "        weak_edges = ((self.gradient >= self.weak_edge_threshold) & (masked_gradient < self.strong_edge_threshold)).astype(np.uint8) \n",
    "\n",
    "        queue = deque(zip(strong_y, strong_x))\n",
    "        while queue:\n",
    "            y, x = queue.popleft() \n",
    "            result_array[y, x] = 1\n",
    "            for dy, dx in neighbours:\n",
    "                ny, nx = y + dy, x + dx\n",
    "                if 0 <= ny < self.gradient.shape[0] and 0 <= nx < self.gradient.shape[1]:\n",
    "                    if weak_edges[ny, nx]:\n",
    "                        weak_edges[ny, nx] = 0 \n",
    "                        queue.append((ny, nx)) \n",
    "\n",
    "        kernel = cv2.getStructuringElement(cv2.MORPH_ELLIPSE, (6,22))\n",
    "        y_top = np.argmin(np.abs(y_values - self.window_size))\n",
    "        y_bottom = np.argmin(np.abs(y_values + self.window_size))\n",
    "        \n",
    "\n",
    "        result_array = cv2.morphologyEx(result_array, cv2.MORPH_CLOSE, kernel)\n",
    "        result_array[y_top, :] = 1\n",
    "        result_array[y_bottom, :] = 1\n",
    "\n",
    "        self.edge_array = np.where(result_array ==  1, 1 , np.nan)\n",
    "\n",
    "    def _define_sections(self, noise_threshold = 3,**kwargs):\n",
    "        for key, value in kwargs.items():\n",
    "            if value is not None and hasattr(self, key):\n",
    "                setattr(self, key, value)\n",
    "\n",
    "        self._create_edge_array()\n",
    "        self._load_DBSCAN_model()\n",
    "        convolved_point_cloud = convolve(self.point_cloud,np.array([[-1],[-2],[0],[2],[1]]))\n",
    "        neighbours = [(-1, 0), (0, -1), (0, 1), (1, 0)]\n",
    "        nan_mask = np.isnan(self.edge_array) \n",
    "        \n",
    "        self.labeled_x_values = np.zeros(self.point_cloud.shape[1], dtype=int)\n",
    "\n",
    "        for x in range(self.edge_array.shape[1]):\n",
    "            center_x_vals = []\n",
    "            avg_z_vals = {}\n",
    "            avg_cz_vals = {}\n",
    "            size = 0\n",
    "            if nan_mask[self.y_seed_point, x]: \n",
    "                queue = deque([(self.y_seed_point, x)])\n",
    "                while queue:\n",
    "                    y, x = queue.popleft()\n",
    "                    size += 1\n",
    "\n",
    "                    if y == self.y_seed_point:\n",
    "                        center_x_vals.append(x)\n",
    "\n",
    "                    if y not in avg_z_vals.keys():\n",
    "                        avg_z_vals[y] = []\n",
    "                        avg_cz_vals[y] = []\n",
    "\n",
    "                    avg_z_vals[y].append(self.point_cloud[y,x])\n",
    "                    avg_cz_vals[y].append(convolved_point_cloud[y,x])\n",
    "                    nan_mask[y, x] = False  \n",
    "\n",
    "                    neighbors_to_add = [\n",
    "                        (ny, nx) for dy, dx in neighbours\n",
    "                        if (0 <= (ny := y + dy) < self.edge_array.shape[0] and \n",
    "                            0 <= (nx := x + dx) < self.edge_array.shape[1] and \n",
    "                            nan_mask[ny, nx])  \n",
    "                    ]\n",
    "                    queue.extend(neighbors_to_add) \n",
    "                    for ny, nx in neighbors_to_add:\n",
    "                        nan_mask[ny, nx] = False\n",
    "            \n",
    "            if size > 5000:\n",
    "                avg_z_vals = [np.nanmedian(z_values) for z_values in avg_z_vals.values()]\n",
    "                avg_cz_vals = [np.nanmedian(z_values) for z_values in avg_cz_vals.values()]\n",
    "\n",
    "                v,b = self._get_props(avg_z_vals,avg_cz_vals)\n",
    "                closest_label = 0\n",
    "                if not np.any(np.isnan(v)):  \n",
    "                    dist, ind = self.tree.query([v], k=1)  \n",
    "\n",
    "                    if dist[0] <= noise_threshold: \n",
    "                        closest_label = self.labels[ind[0]] \n",
    "                        \n",
    "                        if closest_label == 2:\n",
    "                            closest_label += b\n",
    "                for x in center_x_vals:\n",
    "                    self.labeled_x_values[x] = closest_label\n",
    "\n",
    "    def _classify_rubble(self, x_window=3, y_window=4, **kwargs):\n",
    "        for key, value in kwargs.items():\n",
    "            if value is not None and hasattr(self, key):\n",
    "                setattr(self, key, value)\n",
    "\n",
    "        pc = cp.array(self.point_cloud)\n",
    "        pc = pc[self.y_seed_point - y_window:self.y_seed_point + y_window + 1,:]\n",
    "\n",
    "        width = pc.shape[1]\n",
    "        y_range, x_range = 2 * y_window + 1, 2 * x_window + 1\n",
    "\n",
    "        x_n = cp.arange(-x_window, x_window + 1) /6.5\n",
    "        y_n = cp.arange(-y_window, y_window + 1) /6.5\n",
    "        valid_x = cp.repeat(x_n, y_range).flatten()\n",
    "        valid_y = cp.tile(y_n, x_range).flatten()\n",
    "\n",
    "        points = cp.lib.stride_tricks.sliding_window_view(\n",
    "            cp.pad(pc, ((0,0), (x_window,x_window)), mode='edge'), (y_range, x_range)\n",
    "        )\n",
    "\n",
    "        points = points.reshape(width, y_range*x_range)\n",
    "\n",
    "        points = cp.stack((\n",
    "            cp.broadcast_to(valid_x, (width, y_range*x_range)),\n",
    "            cp.broadcast_to(valid_y, (width, y_range*x_range)),\n",
    "            points), axis=2)\n",
    "        mean_vals = cp.mean(points[:,:,2], axis=(1), keepdims=True)\n",
    "        points[:,:,2] -= mean_vals\n",
    "\n",
    "        cov_matrices = cp.matmul(points.transpose(0,2,1), points) / (y_range * x_range - 1)\n",
    "\n",
    "        eigvals, eigvecs = cp.linalg.eigh(cov_matrices)\n",
    "\n",
    "        eigvecs = eigvecs[:, :, 0]\n",
    "\n",
    "        eigvals = eigvals[:,0]/(eigvals[:,0] + eigvals[:,1]  + eigvals[:,2]) \n",
    "        \n",
    "        x_offset = cp.abs(cp.arctan(eigvecs[:,0]/eigvecs[:,2]))\n",
    "        y_offset = cp.abs(cp.arctan(eigvecs[:,1]/eigvecs[:,2]))\n",
    "\n",
    "        results = {self.i_to_x_list[i]: self.labeled_x_values[i] if self.labeled_x_values[i] != 0 else [float(eigvals[i]),float(x_offset[i]),float(y_offset[i])] for i in range(len(self.i_to_x_list))}\n",
    "\n",
    "        cp.get_default_memory_pool().free_all_blocks()\n",
    " \n",
    "        self.rubble_classifications = results\n",
    "   \n",
    "    def _define_correction_windows(self, xrf_window_size=10,noise_threshold = 1, **kwargs):\n",
    "        for key, value in kwargs.items():\n",
    "            if value is not None and hasattr(self, key):\n",
    "                setattr(self, key, value)\n",
    "\n",
    "        self._define_sections(noise_threshold=noise_threshold)\n",
    "        self._classify_rubble()\n",
    "\n",
    "        windows = {}\n",
    "\n",
    "        for x_start in range(0, round(np.nanmax(self.i_to_x_list)), xrf_window_size):\n",
    "            values = [self.rubble_classifications[i] for i, x in zip(self.i_to_x_list, self.i_to_x_list) \n",
    "            if x_start <= x < x_start + xrf_window_size]\n",
    "    \n",
    "            if values:\n",
    "                x_end = max(x for x in self.i_to_x_list if x_start <= x < x_start + xrf_window_size)\n",
    "                x_start = min(x for x in self.i_to_x_list if x_start <= x < x_start + xrf_window_size)\n",
    "            \n",
    "                labels = np.array([v for v in values if v in [1,2,3]])\n",
    "                rubble_points = [v for v in values if v not in [0,1,2,3]]\n",
    "                \n",
    "                rubble_points = np.array(rubble_points)\n",
    "            \n",
    "                half_perc = np.sum(labels == 1) / len(values)\n",
    "                empty_perc = np.sum(labels == 2) / len(values)\n",
    "                full_perc = np.sum(labels == 3) / len(values)\n",
    "                rubble_perc = 1 - half_perc - empty_perc - full_perc\n",
    "\n",
    "                if rubble_points.size > 0:\n",
    "                    avg_var = np.nanmean(rubble_points[:, 0])\n",
    "                    avg_x_offset = np.nanmean(rubble_points[:, 1])\n",
    "                    avg_y_offset = np.nanmean(rubble_points[:, 2])\n",
    "                else:\n",
    "                    avg_var = avg_x_offset = avg_y_offset = np.nan  \n",
    "\n",
    "                windows[(x_start, x_end)] = [half_perc, full_perc, empty_perc, rubble_perc, avg_var, avg_x_offset, avg_y_offset]\n",
    "\n",
    "        self.correction_windows = windows\n",
    "\n",
    "    def _save_correction_windows(self, xrf_window_size=10, **kwargs):\n",
    "        for key, value in kwargs.items():\n",
    "            if value is not None and hasattr(self, key):\n",
    "                setattr(self, key, value)\n",
    "\n",
    "        if self.correction_windows == None:\n",
    "            self._define_correction_windows(xrf_window_size)\n",
    "        \n",
    "        os.makedirs(self.file_path, exist_ok=True)\n",
    "        \n",
    "        file_path = os.path.join(self.file_path, 'rubble_classification.pkl')\n",
    "        \n",
    "        with open(file_path, 'wb') as f:\n",
    "            pickle.dump(self.correction_windows, f)\n",
    "\n",
    "    def _plot_correction_windows(self, width = 150, height = 7, dpi = 75, noise_threshold = 1, xrf_window_size=None,**kwargs):\n",
    "        changed = False\n",
    "        for key, value in kwargs.items():\n",
    "            if value is not None and hasattr(self, key):\n",
    "                changed = True\n",
    "                setattr(self, key, value)\n",
    "\n",
    "        if  xrf_window_size is not None:\n",
    "            self._define_correction_windows(xrf_window_size)\n",
    "\n",
    "        if self.correction_windows is None or changed:\n",
    "            self._define_correction_windows()\n",
    "\n",
    "\n",
    "        fig, ax = plt.subplots(figsize=(width, height), dpi=dpi)\n",
    "\n",
    "        colormap = [\"green\", \"blue\", \"purple\", \"red\"]\n",
    "        cmap1 = plt.cm.cool  \n",
    "        cmap2 = plt.cm.cool\n",
    "\n",
    "        all_vars = []\n",
    "        all_angles = []\n",
    "\n",
    "        for values in self.correction_windows.values():\n",
    "            var, x_angle, y_angle = values[4:7]\n",
    "            all_vars.append(var)\n",
    "            all_angles.append(x_angle)\n",
    "\n",
    "        min_var = np.nanmin(all_vars)\n",
    "        max_var = np.nanmax(all_vars)\n",
    "        min_angle = np.nanmin(all_angles)\n",
    "        max_angle = np.nanmax(all_angles)\n",
    "\n",
    "        display = self.point_cloud\n",
    "        ax.imshow(np.flipud(display), cmap=self.colourmap, interpolation='nearest', alpha=1, aspect= 'auto')\n",
    "\n",
    "        for (x_start, x_end), values in self.correction_windows.items():\n",
    "            half_perc, empty_perc, full_perc, rubble_perc = values[:4]\n",
    "\n",
    "            ratios = np.array([half_perc, empty_perc, full_perc, rubble_perc])\n",
    "            ratios /= ratios.sum()  \n",
    "\n",
    "            width = self.x_to_i_dict[x_end] - self.x_to_i_dict[x_start] + 1\n",
    "            bar_heights = ratios * 12  \n",
    "            bottoms = self.y_seed_point - 6 + np.insert(np.cumsum(bar_heights[:-1]), 0, 0)\n",
    "\n",
    "            for j in range(4):\n",
    "                ax.bar(self.x_to_i_dict[x_start], height=bar_heights[j], width=width,\n",
    "                    bottom=bottoms[j], color=colormap[j], alpha=0.65, align='edge')\n",
    "\n",
    "            if rubble_perc > 0:\n",
    "                var, x_angle, y_angle = values[4:]\n",
    "                norm1 = plt.Normalize(vmin=min_var, vmax=max_var)\n",
    "                norm2 = plt.Normalize(vmin=min_angle, vmax=max_angle)\n",
    "                color1 = cmap1(norm1(var))\n",
    "                color2 = cmap2(norm2(x_angle))\n",
    "                color3 = cmap2(norm2(y_angle))\n",
    "                extra_heights = 7.5\n",
    "\n",
    "                ax.bar(self.x_to_i_dict[x_start], height=extra_heights, width=width,\n",
    "                    bottom=0, color=color1, alpha=0.75, align='edge')\n",
    "                ax.bar(self.x_to_i_dict[x_start], height=extra_heights, width=width,\n",
    "                    bottom=extra_heights, color=color2, alpha=0.75, align='edge')\n",
    "                ax.bar(self.x_to_i_dict[x_start], height=extra_heights, width=width,\n",
    "                    bottom=extra_heights*2, color=color3, alpha=0.75, align='edge')\n",
    "\n",
    "        ax.set_xlabel(\"X index\",fontsize = 20)\n",
    "        ax.set_ylabel(\"Y index\",fontsize = 20)\n",
    "        ax.set_title(self.name, fontsize=35)\n",
    "\n",
    "        plt.show()\n",
    "\n",
    "    def _plot_gradient(self,width = 150, height = 7, dpi = 75, **kwargs):\n",
    "        changed = False\n",
    "        for key, value in kwargs.items():\n",
    "            if value is not None and hasattr(self, key):\n",
    "                changed = True\n",
    "                setattr(self, key, value)\n",
    "\n",
    "        if self.gradient is None or changed:\n",
    "            self._get_gradient()\n",
    "            \n",
    "        fig, ax = plt.subplots(figsize=(width, height), dpi=dpi)\n",
    "        ax.imshow(cp.flipud(self.gradient), cmap='nipy_spectral', interpolation='nearest', alpha = 1, aspect = 'auto')\n",
    "        ax.set_xlabel(\"X index\",fontsize = 20)\n",
    "        ax.set_ylabel(\"Y index\",fontsize = 20)\n",
    "        ax.set_title(self.name, fontsize=35)\n",
    "    \n",
    "    def _plot_edges(self,width = 150, height = 7, dpi = 75, **kwargs):\n",
    "        changed = False\n",
    "        for key, value in kwargs.items():\n",
    "            if value is not None and hasattr(self, key):\n",
    "                changed = True\n",
    "                setattr(self, key, value)\n",
    "\n",
    "        if self.edge_array is None or changed:\n",
    "            self._create_edge_array()\n",
    "            \n",
    "        fig, ax = plt.subplots(figsize=(width, height), dpi=dpi)\n",
    "        ax.imshow(cp.flipud(self.edge_array), cmap='nipy_spectral', interpolation='nearest', alpha = 1, aspect = 'auto')\n",
    "        ax.set_xlabel(\"X index\",fontsize = 20)\n",
    "        ax.set_ylabel(\"Y index\",fontsize = 20)\n",
    "        ax.set_title(self.name, fontsize=35)\n",
    "\n",
    "    def _plot_PCA_mask(self,plot_point_cloud = False, width = 150, height = 7, dpi = 75, **kwargs):\n",
    "\n",
    "        changed = False\n",
    "\n",
    "        for key, value in kwargs.items():\n",
    "            if value is not None and hasattr(self, key):\n",
    "                changed = True\n",
    "                setattr(self, key, value)\n",
    "\n",
    "        if self.PCA_mask is None or changed:\n",
    "            self._create_PCA_mask()\n",
    "        fig, ax = plt.subplots(figsize=(width, height), dpi=dpi)\n",
    "        a = 1\n",
    "\n",
    "        if plot_point_cloud:\n",
    "            ax.imshow(cp.flipud(self.point_cloud), cmap=self.colourmap, interpolation='nearest', alpha = 1, aspect = 'auto')\n",
    "            a = 0.25\n",
    "        ax.imshow(cp.flipud(self.PCA_mask), cmap='nipy_spectral', interpolation='nearest', alpha = a, aspect = 'auto')\n",
    "        ax.set_xlabel(\"X index\")\n",
    "        ax.set_ylabel(\"Y index\")\n",
    "        ax.set_title(self.name)\n",
    "\n",
    "    def _plot_sections(self,plot_point_cloud = True, width = 150, height = 7, dpi = 75, **kwargs):\n",
    "        changed = False\n",
    "        for key, value in kwargs.items():\n",
    "            if value is not None and hasattr(self, key):\n",
    "                changed = True\n",
    "                setattr(self, key, value)\n",
    "\n",
    "        if self.edge_array is None or changed:\n",
    "            self._create_edge_array()\n",
    "        sections = self.edge_array.copy()\n",
    "    \n",
    "        neighbours = [(-1, 0), (0, -1), (0, 1), (1, 0)]  \n",
    "        nan_mask = np.isnan(sections)  \n",
    "\n",
    "        int = 2\n",
    "        for x in range(sections.shape[1]):\n",
    "            if nan_mask[self.y_seed_point, x]: \n",
    "                queue = deque([(self.y_seed_point, x)])\n",
    "                while queue:\n",
    "                    y, x = queue.popleft()\n",
    "                    sections[y, x] = int \n",
    "                    nan_mask[y, x] = False  \n",
    "                    neighbors_to_add = [(ny, nx) for dy, dx in neighbours\n",
    "                        if (0 <= (ny := y + dy) < sections.shape[0] and \n",
    "                            0 <= (nx := x + dx) < sections.shape[1] and nan_mask[ny, nx])]\n",
    "                    queue.extend(neighbors_to_add) \n",
    "                    for ny, nx in neighbors_to_add:\n",
    "                        nan_mask[ny, nx] = False \n",
    "            int += 1\n",
    "        \n",
    "        sections = np.where(sections > 1, sections, np.nan)\n",
    "\n",
    "        fig, ax = plt.subplots(figsize=(width, height), dpi=dpi)\n",
    "        a = 1\n",
    "        if plot_point_cloud:\n",
    "            ax.imshow(cp.flipud(self.point_cloud), cmap=self.colourmap, interpolation='nearest', alpha = 1, aspect= 'auto')\n",
    "            a = 0.8\n",
    "        ax.imshow(cp.flipud(sections), cmap='cool', interpolation='nearest', alpha = a, aspect= 'auto')\n",
    "        ax.set_xlabel(\"X index\")\n",
    "        ax.set_ylabel(\"Y index\")\n",
    "        ax.set_title(self.name)\n",
    "\n",
    "    def _print_instance_attributes(self):\n",
    "        for attr, value in vars(self).items():\n",
    "            print(f\"{attr}: {'None' if value is None else 'Not None'}\")\n",
    "\n",
    "    def _view_point_cloud(self):\n",
    "        x = (list)(self.i_to_x_list) * len(self.i_to_y_list)\n",
    "        y = np.repeat(self.i_to_y_list, len(self.i_to_x_list))\n",
    "        z = self.point_cloud.flatten()\n",
    "\n",
    "        pcd = o3d.geometry.PointCloud()\n",
    "        points = np.column_stack((x, y, -z))\n",
    "        pcd.points = o3d.utility.Vector3dVector(points)\n",
    "        \n",
    "        o3d.visualization.draw_geometries([pcd])\n",
    "\n",
    "    def _plot_point_cloud(self,width = 150, height = 7, dpi = 75, **kwargs):\n",
    "        for key, value in kwargs.items():\n",
    "            if value is not None and hasattr(self, key):\n",
    "                setattr(self, key, value)\n",
    "\n",
    "        fig, ax = plt.subplots(figsize=(width, height), dpi=dpi)\n",
    "        ax.imshow(cp.flipud(self.point_cloud), cmap=self.colourmap, interpolation='nearest', alpha = 1, aspect = 'auto')\n",
    "        ax.set_xlabel(\"X index\")\n",
    "        ax.set_ylabel(\"Y index\")\n",
    "        ax.set_title(self.name)\n",
    "\n",
    "    def _get_data_cube(self):\n",
    "        x = (list)(self.i_to_x_list) * len(self.i_to_y_list)\n",
    "        y = np.repeat(self.i_to_y_list, len(self.i_to_x_list))\n",
    "        z = self.point_cloud.flatten()\n",
    "\n",
    "        return np.column_stack((x, y, z))\n",
    "\n",
    "    def _save_to_las(self):\n",
    "        x = (list)(self.i_to_x_list) * len(self.i_to_y_list)\n",
    "        y = np.repeat(self.i_to_y_list, len(self.i_to_x_list))\n",
    "        z = self.point_cloud.flatten()\n",
    "\n",
    "        file_path = os.path.join(self.file_path, \"point_cloud.las\")\n",
    "\n",
    "        header = laspy.LasHeader(point_format=1, version=\"1.2\") \n",
    "        las = laspy.LasData(header)\n",
    "\n",
    "        las.x = np.array(x)\n",
    "        las.y = np.array(y)\n",
    "        las.z = np.array(z)\n",
    "\n",
    "        las.write(file_path)\n",
    "\n",
    "    def _print_scan_limits(self, translated = False):\n",
    "        if translated:\n",
    "            data = self.translated_cloud_limits\n",
    "            print(f\"limits in machine coordinates for {self.name}:\")\n",
    "        else:\n",
    "            data = self.original_cloud_limits\n",
    "            print(f\"limits in lidar coordinates for {self.name}:\")\n",
    "\n",
    "        print(f\" x value range: {data[0]}mm to {data[1]}mm, number of lines in the x direction: {data[2]}\")\n",
    "        print(f\" y value range: {data[3]}mm to {data[4]}mm, number of lines in the y direction: {data[5]}\")\n",
    "        print(f\" z value range: {data[6]}mm to {data[7]}mm, total number of points: {data[8]}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "LP = ljx_processor(r\"C:\\Users\\eashenhurst\\Desktop\\test_csv_core\", window_size= 15, y_shift = 0)\n",
    "LP._print_scan_limits(translated=True)\n",
    "LP._plot_point_cloud()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "LP._create_PCA_mask(batch_size = 100, i = 0, y_window = 15, x_window = 15, strong_PCA_threshold = 0.45, weak_PCA_threshold = 0.075)\n",
    "LP._print_instance_attributes()\n",
    "LP._plot_PCA_mask()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "LP._plot_gradient()\n",
    "LP._plot_edges(strong_edge_threshold = 500, weak_edge_threshold = 250)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "LP._plot_sections(strong_edge_threshold = 1000, weak_edge_threshold = 250)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "LP._define_correction_windows(noise_threshold = 0.35)\n",
    "LP._plot_correction_windows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(15, 4), dpi=100)\n",
    "gs = fig.add_gridspec(1, 1)\n",
    "ax = fig.add_subplot(gs[0, 0])\n",
    "\n",
    "x_vals = [v[2] for v in LP.vectors]\n",
    "y_vals = [v[2] for v in LP.vectors]\n",
    "\n",
    "ax.set_xlabel(\"skew\")\n",
    "ax.set_ylabel(\"Azimuthal angle\")\n",
    "\n",
    "ax.scatter(x_vals, y_vals, color=\"red\", s=1)\n",
    "\n",
    "a = 0.1\n",
    "s = 7\n",
    "t = 6.5\n",
    "x_func = np.linspace(-1, 1, 100)\n",
    "y_func = (t - (1 / np.sqrt(2 * np.pi * a**2)) * np.exp(-((x_func)**2) / (2 * a**2))) / s\n",
    "\n",
    "ax.plot(x_func, y_func, color='cyan', linestyle='--', linewidth=2, label=\"gauss\")\n",
    "\n",
    "triangle_x = [0.5, 0.775, 0.5, 0.5]\n",
    "triangle_y = [0.6, 0.55, 0.4, 0.6]\n",
    "\n",
    "ax.plot(triangle_x, triangle_y, color='magenta', linestyle='-', linewidth=2, label=\"Triangle\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "LP_env",
   "language": "python",
   "name": "lp_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
