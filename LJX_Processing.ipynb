{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import pickle\n",
    "import laspy\n",
    "import matplotlib.pyplot    as plt\n",
    "import numpy                as np\n",
    "import cupy                 as cp\n",
    "import open3d               as o3d\n",
    "from scipy.stats            import skew, kurtosis\n",
    "from scipy.ndimage          import convolve\n",
    "from cupyx.scipy.ndimage    import convolve as cpconvolve\n",
    "from collections            import deque\n",
    "from scipy.interpolate      import interp1d\n",
    "from scipy.spatial import KDTree\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ljx_processor:\n",
    "    def __init__(self, file_path, DBSCAN_model_path = None, window_size = 10, y_shift = 0, name=None,  \n",
    "                strong_PCA_threshold = 0.15, weak_PCA_threshold = 0.025, strong_edge_threshold = 0.25, weak_edge_threshold = 0.075, \n",
    "                colourmap = 'binary_r', x_stop = 550 , box_length = 1500):\n",
    "        \n",
    "        if DBSCAN_model_path is None:\n",
    "            current_dir = os.getcwd()\n",
    "            self.DBSCAN_model_path = os.path.join(current_dir, 'cluster_kd_tree.pkl')\n",
    "        else: \n",
    "            self.DBSCAN_model_path = DBSCAN_model_path\n",
    "            \n",
    "        self.file_path = file_path\n",
    "        self.colourmap = colourmap\n",
    "        self.name = name if name else file_path\n",
    "        self.window_size = window_size\n",
    "        self.strong_edge_threshold = strong_edge_threshold\n",
    "        self.weak_edge_threshold = weak_edge_threshold\n",
    "        self.strong_PCA_threshold = strong_PCA_threshold\n",
    "        self.weak_PCA_threshold = weak_PCA_threshold\n",
    "        self.y_shift = y_shift\n",
    "        self.x_stop = x_stop\n",
    "        self.x_start = self.x_stop + box_length\n",
    "        self.tree = None\n",
    "        self.labels = None\n",
    "\n",
    "        self.correction_windows = None\n",
    "        self.labeled_x_values = None   \n",
    "\n",
    "        self.edge_array = None\n",
    "        self.gradient = None\n",
    "        self.PCA_mask = None\n",
    "        self.y_seed_point = None\n",
    "\n",
    "        self._build_processor()\n",
    "    \n",
    "    def _collect_garbage(self):\n",
    "        self.tree = None\n",
    "        self.labels = None\n",
    "        self.correction_windows = None\n",
    "        self.labeled_x_values = None\n",
    "        self.gradient = None\n",
    "        self.PCA_mask = None\n",
    "        self.component_parameters_path = None\n",
    "        self.lidar2xrf_path = None\n",
    "        self.point_path = None\n",
    "        self.intensity_path = None\n",
    "    \n",
    "    def _find_files(self):\n",
    "        self.component_parameters_path = None\n",
    "        self.lidar2xrf_path = None\n",
    "        self.point_path = None\n",
    "        self.intensity_path = None\n",
    "\n",
    "        for file_name in os.listdir(self.file_path):\n",
    "            full_path = os.path.join(self.file_path, file_name)\n",
    "            if file_name.endswith(\".component_parameters.txt\"):\n",
    "                self.component_parameters_path = full_path\n",
    "            elif file_name.endswith(\".lidar2xrf\"):\n",
    "                self.lidar2xrf_path = full_path\n",
    "            elif file_name.endswith(\".bpc\"):\n",
    "                if \"intensity\" in file_name:\n",
    "                    self.intensity_path = full_path\n",
    "                else:\n",
    "                    self.point_path = full_path\n",
    "\n",
    "    def _validate_files(self):\n",
    "        missing_files = [\n",
    "            name for name, path in {\n",
    "                \"point_cloud\": self.point_path,\n",
    "                \"intensity_cloud\": self.intensity_path\n",
    "            }.items() if path is None\n",
    "        ]\n",
    "\n",
    "        non_essential_mising_files = [\n",
    "            name for name, path in {\n",
    "                \"component_parameters\": self.component_parameters_path,\n",
    "                \"lidar2xrf\": self.lidar2xrf_path,\n",
    "            }.items() if path is None\n",
    "        ]\n",
    "\n",
    "        if missing_files:\n",
    "            raise FileNotFoundError(f\"Missing required files: {', '.join(missing_files)}\")\n",
    "        if non_essential_mising_files:\n",
    "            print (f\"   Missing: {', '.join(non_essential_mising_files)}, contents will be assumed\")\n",
    "    \n",
    "    def _load_component_parameters(self):\n",
    "        self.y_offset = 0\n",
    "        if self.component_parameters_path is not None:\n",
    "            with open(self.component_parameters_path) as file:\n",
    "                lines = file.readlines()\n",
    "                for line in lines:\n",
    "                    if \"XRAY_DPP[Acquisition]#0.X.Start:\" in line:\n",
    "                        self.x_start = float(line.split(\":\")[1].strip())\n",
    "                    if \"XRAY_DPP[Acquisition]#0.X.Stop:\" in line:\n",
    "                        self.x_stop = float(line.split(\":\")[1].strip())\n",
    "                    if \"XRAY_DPP[Acquisition]#0.Y.Start:\" in line:\n",
    "                        self.y_offset = float(line.split(\":\")[1].strip())\n",
    "    \n",
    "    def _load_lidar_data(self):\n",
    "        if self.lidar2xrf_path is None:\n",
    "            self.transformation_matrix = cp.array([[1,0,0,192],\n",
    "                                                  [0,-1,0,9.3],\n",
    "                                                  [0,0,-1,53.8],\n",
    "                                                  [0,0,0,1]])\n",
    "        else: \n",
    "            with open(self.lidar2xrf_path) as file:\n",
    "                lines = file.readlines()\n",
    "                self.transformation_matrix = cp.array([list(map(float, line.strip().split(\",\"))) for line in lines])\n",
    "\n",
    "        self.point_cloud = cp.fromfile(self.point_path, dtype=np.float32).reshape(-1, 3)\n",
    "        self.intensity_cloud = cp.fromfile(self.intensity_path, dtype=np.float32).reshape(-1, 3)[:,2]\n",
    "\n",
    "\n",
    "        self.original_cloud_limits = [cp.nanmax(self.point_cloud[:,0]),cp.nanmin(self.point_cloud[:,0]), len(cp.unique(self.point_cloud[:,0])),\n",
    "                                      cp.nanmax(self.point_cloud[:,1]),cp.nanmin(self.point_cloud[:,1]), len(cp.unique(self.point_cloud[:,1])),\n",
    "                                      cp.nanmax(self.point_cloud[:,2]),cp.nanmin(self.point_cloud[:,2]), len(self.point_cloud[:,2])]\n",
    "        \n",
    "        self.point_cloud = (cp.hstack((self.point_cloud, cp.ones((self.point_cloud.shape[0], 1)))) @ self.transformation_matrix.T)[:,:3]\n",
    "    \n",
    "    def _build_processor(self):\n",
    "        self._find_files()\n",
    "        self._validate_files()\n",
    "        self._load_component_parameters()\n",
    "        self._load_lidar_data()\n",
    "\n",
    "        \n",
    "        self.point_cloud[:,1] -= self.y_shift\n",
    "        \n",
    "        \n",
    "        mask = (self.point_cloud[:,0] <= self.x_start) & (self.point_cloud[:,0] >= self.x_stop) & ((self.point_cloud[:,1]) <= (self.window_size + 5)) & ((self.point_cloud[:,1]) >=  -(self.window_size + 5))\n",
    "        self.point_cloud = self.point_cloud[mask]\n",
    "        self.intensity_cloud = self.intensity_cloud[mask]\n",
    "        min_z = cp.nanmax(self.point_cloud[:,2])\n",
    "\n",
    "        missing = np.where(self.point_cloud[:,2] == min_z)\n",
    "\n",
    "        self.point_cloud[missing,2] = 250\n",
    "\n",
    "        missing = np.where(self.intensity_cloud == 0)\n",
    "\n",
    "        self.intensity_cloud[missing] = 1\n",
    "\n",
    "        x_values = cp.unique(self.point_cloud[:,0])\n",
    "\n",
    "        self.x_pixel_size = cp.median(cp.diff(x_values))\n",
    "        y_values = cp.unique(self.point_cloud[:,1])\n",
    "        self.y_pixel_size = cp.mean(cp.diff(y_values))\n",
    "\n",
    "        height = len(y_values)\n",
    "        width = len(x_values)\n",
    "\n",
    "        point_array = self.point_cloud[:,2].reshape(width,height).T[::-1]\n",
    "        intensity_array = self.intensity_cloud.reshape(width,height).T[::-1]\n",
    "\n",
    "        \n",
    "            \n",
    "        self.y_seed_point = np.argmin(np.abs(y_values.get()))\n",
    "        self.point_cloud = cp.asnumpy(point_array)\n",
    "        self.intensity_cloud = cp.asnumpy(intensity_array)\n",
    "        self.i_to_x_list = x_values.get()\n",
    "        self.i_to_y_list = y_values.get()\n",
    "    \n",
    "    def _create_PCA_mask(self,y_window = 3, x_window = 9, batch_size = 100, **kwargs):\n",
    "\n",
    "        y_window = int(cp.round(0.75/self.y_pixel_size))\n",
    "        x_window = int(cp.round(1.5/self.x_pixel_size))\n",
    "\n",
    "        for key, value in kwargs.items():\n",
    "            if value is not None and hasattr(self, key):\n",
    "                setattr(self, key, value)\n",
    "\n",
    "        s = self.strong_PCA_threshold \n",
    "        w = self.weak_PCA_threshold \n",
    "        pc = cp.array(self.point_cloud)\n",
    "        y_values = self.i_to_y_list\n",
    "\n",
    "        y_range, x_range = 2 * y_window + 1, 2 * x_window + 1\n",
    "\n",
    "        y_bottom = np.argmin(np.abs(y_values - self.window_size))\n",
    "        y_top = np.argmin(np.abs(y_values + self.window_size))\n",
    "\n",
    "        x_n = cp.arange(-x_window, x_window + 1) * self.x_pixel_size\n",
    "        y_n = cp.arange(-y_window, y_window + 1) * self.y_pixel_size\n",
    "        valid_x = cp.repeat(x_n, y_range).flatten()\n",
    "        valid_y = cp.tile(y_n, x_range).flatten()\n",
    "        eigvals = cp.zeros_like(pc) \n",
    "        pc = cp.pad(pc, ((y_window,y_window), (x_window,x_window)), mode='edge')\n",
    "\n",
    "        for x in range(x_window, pc.shape[1] - x_window, batch_size):\n",
    "            for y in range(y_window, pc.shape[0] - y_window, batch_size):\n",
    "                batch = pc[y - y_window:y + batch_size + y_window, x - x_window:x + batch_size + x_window]\n",
    "\n",
    "                points = cp.lib.stride_tricks.sliding_window_view(batch, (y_range, x_range))\n",
    "\n",
    "                height, width = points.shape[:2]\n",
    "                points = points.reshape(height, width, y_range * x_range)\n",
    "\n",
    "                points = cp.stack((\n",
    "                    cp.broadcast_to(valid_x, (height, width, y_range * x_range)),\n",
    "                    cp.broadcast_to(valid_y, (height, width, y_range * x_range)),\n",
    "                    points), axis=2)\n",
    "\n",
    "                mean_vals = cp.mean(points[:, :, 2, :], axis=2)\n",
    "                points[:, :, 2, :] -= mean_vals[..., None]\n",
    "\n",
    "                cov_matrices = cp.einsum('...ik,...jk->...ij', points, points) / (y_range * x_range - 1)\n",
    "                evals = cp.linalg.eigvalsh(cov_matrices)\n",
    "                e1 = evals[:, :, 0] \n",
    "                e2 = evals[:, :, 1] \n",
    "\n",
    "                eigvals[y - y_window:y + batch_size - y_window, x - x_window:x + batch_size - x_window] = e2 * e1\n",
    "\n",
    "        eigvals = cp.asnumpy(eigvals)\n",
    "\n",
    "        eigvals[y_bottom:,:] = 0\n",
    "        eigvals[:y_top,:] = 0\n",
    "        neighbours = [(-1, -1), (-1, 0), (-1, 1), (0, -1), (0, 1), (1, -1), (1, 0), (1, 1)]\n",
    "        strong_y, strong_x = np.where(eigvals >= s)\n",
    "        weak_values = (eigvals >= w) & (eigvals < s).astype(np.uint8) \n",
    "        return_array = np.zeros_like(eigvals, dtype=cp.uint8)\n",
    "        \n",
    "        cp.get_default_memory_pool().free_all_blocks()\n",
    "\n",
    "        queue = deque(zip(strong_y, strong_x))\n",
    "        while queue:\n",
    "            y, x = queue.popleft() \n",
    "            return_array[y, x] = 1\n",
    "            for dy, dx in neighbours:\n",
    "                ny, nx = y + dy, x + dx\n",
    "                if 0 <= ny < weak_values.shape[0] and 0 <= nx < weak_values.shape[1]:\n",
    "                    if weak_values[ny, nx]:\n",
    "                        weak_values[ny, nx] = 0 \n",
    "                        queue.append((ny, nx)) \n",
    "        del weak_values \n",
    "\n",
    "        self.PCA_mask = return_array\n",
    "\n",
    "    \n",
    "    \n",
    "    def _get_gradient(self):\n",
    "\n",
    "        array_z = cp.array(self.point_cloud, dtype=cp.float32)\n",
    "       \n",
    "        smooth_y = cp.array([[1.0, 2.0 , 1.0],[3.0, 6.0 , 3.0],[6.0, 12.0, 6.0 ],[9.0, 18.0, 9.0],[6.0 , 12.0 , 6.0],[3.0, 6.0, 3.0 ],[1.0, 2.0 , 1.0]])\n",
    "        smooth_y /= cp.sum(smooth_y)\n",
    "\n",
    "        for i in range(5):\n",
    "            array_z = cpconvolve(array_z, smooth_y)\n",
    "        \n",
    "        sobel_y =  cp.array([[  1,],\n",
    "                             [  2,],\n",
    "                             [  3,],\n",
    "                             [  0,],\n",
    "                             [ -3,],\n",
    "                             [ -2,],\n",
    "                             [ -1,]]) / 6\n",
    "           \n",
    "        sobel_x = sobel_y.T\n",
    "\n",
    "        x_grad_z = cp.abs(cpconvolve(array_z, sobel_y))\n",
    "        y_grad_z = cp.abs(cpconvolve(array_z, sobel_x))\n",
    "\n",
    "        x_grad_z = cp.abs(cpconvolve(x_grad_z, sobel_y))\n",
    "        y_grad_z = cp.abs(cpconvolve(y_grad_z, sobel_x))\n",
    "        magnitude = cp.sqrt(x_grad_z**2 + y_grad_z**2)\n",
    "\n",
    "        y_values = self.i_to_y_list\n",
    "\n",
    "        y_bottom = np.argmin(np.abs(y_values - self.window_size))\n",
    "        y_top = np.argmin(np.abs(y_values + self.window_size))\n",
    "\n",
    "        magnitude[:y_top, :] = 0\n",
    "        magnitude[y_bottom:, :] = 0\n",
    "\n",
    "        self.gradient = cp.asnumpy(magnitude)\n",
    "    \n",
    "    def _create_edge_array(self,  **kwargs):\n",
    "        for key, value in kwargs.items():\n",
    "            if value is not None and hasattr(self, key):\n",
    "                setattr(self, key, value)\n",
    "\n",
    "        if self.gradient is None:\n",
    "            self._get_gradient()\n",
    "        if self.PCA_mask is None:\n",
    "            self._create_PCA_mask()\n",
    "\n",
    "\n",
    "        y_values = self.i_to_y_list\n",
    "        neighbours = [(-1, 0), (0, -1), (0, 1), (1, 0)]\n",
    "    \n",
    "        result_array = np.zeros_like(self.gradient)\n",
    "\n",
    "        masked_gradient = self.gradient * self.PCA_mask \n",
    "        \n",
    "        strong_y, strong_x = np.where(masked_gradient >= self.strong_edge_threshold)\n",
    "        weak_edges = ((self.gradient >= self.weak_edge_threshold) & (masked_gradient < self.strong_edge_threshold)).astype(np.uint8) \n",
    "\n",
    "        queue = deque(zip(strong_y, strong_x))\n",
    "        while queue:\n",
    "            y, x = queue.popleft() \n",
    "            result_array[y, x] = 1\n",
    "            for dy, dx in neighbours:\n",
    "                ny, nx = y + dy, x + dx\n",
    "                if 0 <= ny < self.gradient.shape[0] and 0 <= nx < self.gradient.shape[1]:\n",
    "                    if weak_edges[ny, nx]:\n",
    "                        weak_edges[ny, nx] = 0 \n",
    "                        queue.append((ny, nx)) \n",
    "\n",
    "        kernel = cv2.getStructuringElement(cv2.MORPH_ELLIPSE, (9,9))\n",
    "        y_top = np.argmin(np.abs(y_values - self.window_size))\n",
    "        y_bottom = np.argmin(np.abs(y_values + self.window_size))\n",
    "        \n",
    "\n",
    "        result_array = cv2.morphologyEx(result_array, cv2.MORPH_CLOSE, kernel)\n",
    "        result_array[y_top, :] = 1\n",
    "        result_array[y_bottom, :] = 1\n",
    "\n",
    "        self.edge_array = np.where(result_array ==  1, 1 , np.nan)\n",
    "\n",
    "    def _get_props(self, distribution1, distribution2):\n",
    "            properties = []\n",
    "            return_properties = []\n",
    "\n",
    "            variance =  np.var(distribution1) *((10/self.window_size)**2)\n",
    "            skw = skew(distribution1)\n",
    "            kurt = kurtosis(distribution1)\n",
    "            mean = np.sqrt(np.mean(np.abs(distribution2)))\n",
    "            max = np.sqrt(np.max(np.abs(distribution2)))\n",
    "\n",
    "            \n",
    "            properties.append(variance)\n",
    "            properties.append(skw)\n",
    "            properties.append(kurt)\n",
    "\n",
    "            norm = np.linalg.norm(properties)\n",
    "            \n",
    "            if norm > 0:\n",
    "                properties = [x / norm for x in properties]\n",
    "\n",
    "            z = properties[0]\n",
    "\n",
    "            return_properties.append(mean)\n",
    "            return_properties.append(max)\n",
    "            return_properties.append(np.abs(properties[1]))\n",
    "            return_properties.append(np.arccos(z)/(np.pi/2))\n",
    "\n",
    "            return return_properties, np.uint8(properties[1] > 0)\n",
    "        \n",
    "    \n",
    "    def _load_DBSCAN_model(self):\n",
    "            if (self.tree is None) or (self.labels is None):\n",
    "                with open(self.DBSCAN_model_path, 'rb') as f:\n",
    "                    self.tree, self.labels = pickle.load(f)\n",
    "\n",
    "\n",
    "    def _define_sections(self, noise_threshold = 0.25,**kwargs):\n",
    "        for key, value in kwargs.items():\n",
    "            if value is not None and hasattr(self, key):\n",
    "                setattr(self, key, value)\n",
    "\n",
    "        self._load_DBSCAN_model()\n",
    "        self._create_edge_array()\n",
    "\n",
    "        convolved_point_cloud = convolve(self.point_cloud,np.array([[-1],[-2],[0],[2],[1]]))\n",
    "        neighbours = [(-1, 0), (0, -1), (0, 1), (1, 0)]\n",
    "        nan_mask = np.isnan(self.edge_array) \n",
    "        \n",
    "        self.labeled_x_values = np.zeros(self.point_cloud.shape[1], dtype=int)\n",
    "\n",
    "        for x in range(self.edge_array.shape[1]):\n",
    "            center_x_vals = []\n",
    "            avg_z_vals = {}\n",
    "            avg_cz_vals = {}\n",
    "            size = 0\n",
    "            if nan_mask[self.y_seed_point, x]: \n",
    "                queue = deque([(self.y_seed_point, x)])\n",
    "                while queue:\n",
    "                    y, x = queue.popleft()\n",
    "                    size += 1\n",
    "\n",
    "                    if y == self.y_seed_point:\n",
    "                        center_x_vals.append(x)\n",
    "\n",
    "                    if y not in avg_z_vals.keys():\n",
    "                        avg_z_vals[y] = []\n",
    "                        avg_cz_vals[y] = []\n",
    "\n",
    "                    avg_z_vals[y].append(self.point_cloud[y,x])\n",
    "                    avg_cz_vals[y].append(convolved_point_cloud[y,x])\n",
    "                    nan_mask[y, x] = False  \n",
    "\n",
    "                    neighbors_to_add = [\n",
    "                        (ny, nx) for dy, dx in neighbours\n",
    "                        if (0 <= (ny := y + dy) < self.edge_array.shape[0] and \n",
    "                            0 <= (nx := x + dx) < self.edge_array.shape[1] and \n",
    "                            nan_mask[ny, nx])  \n",
    "                    ]\n",
    "                    queue.extend(neighbors_to_add) \n",
    "                    for ny, nx in neighbors_to_add:\n",
    "                        nan_mask[ny, nx] = False\n",
    "            \n",
    "            if size > 5000:\n",
    "                avg_z_vals = [np.nanmedian(z_values) for z_values in avg_z_vals.values()]\n",
    "                avg_cz_vals = [np.nanmedian(z_values) for z_values in avg_cz_vals.values()]\n",
    "\n",
    "                v,b = self._get_props(avg_z_vals,avg_cz_vals)\n",
    "                closest_label = 0\n",
    "                if not np.any(np.isnan(v)):  \n",
    "                    dist, ind = self.tree.query([v], k=1)  \n",
    "\n",
    "                    if dist[0] <= noise_threshold: \n",
    "                        closest_label = self.labels[ind[0]] \n",
    "                        \n",
    "                        if closest_label == 2:\n",
    "                            closest_label += b\n",
    "                for x in center_x_vals:\n",
    "                    self.labeled_x_values[x] = closest_label\n",
    "\n",
    "    def _classify_rubble(self, x_window= 5, y_window=4, **kwargs):\n",
    "        for key, value in kwargs.items():\n",
    "            if value is not None and hasattr(self, key):\n",
    "                setattr(self, key, value)\n",
    "\n",
    "        pc = cp.array(self.point_cloud)\n",
    "        pc = pc[self.y_seed_point - y_window:self.y_seed_point + y_window + 1,:]\n",
    "\n",
    "        width = pc.shape[1]\n",
    "        y_range, x_range = 2 * y_window + 1, 2 * x_window + 1\n",
    "\n",
    "        x_n = cp.arange(-x_window, x_window + 1) * self.x_pixel_size\n",
    "        y_n = cp.arange(-y_window, y_window + 1) * self.y_pixel_size\n",
    "        valid_x = cp.repeat(x_n, y_range).flatten()\n",
    "        valid_y = cp.tile(y_n, x_range).flatten()\n",
    "\n",
    "        points = cp.lib.stride_tricks.sliding_window_view(\n",
    "            cp.pad(pc, ((0,0), (x_window,x_window)), mode='edge'), (y_range, x_range)\n",
    "        )\n",
    "\n",
    "        points = points.reshape(width, y_range*x_range)\n",
    "\n",
    "        points = cp.stack((\n",
    "            cp.broadcast_to(valid_x, (width, y_range*x_range)),\n",
    "            cp.broadcast_to(valid_y, (width, y_range*x_range)),\n",
    "            points), axis=2)\n",
    "        mean_vals = cp.mean(points[:,:,2], axis=(1), keepdims=True)\n",
    "        points[:,:,2] -= mean_vals\n",
    "\n",
    "        cov_matrices = cp.matmul(points.transpose(0,2,1), points) / (y_range * x_range - 1)\n",
    "\n",
    "        eigvals, eigvecs = cp.linalg.eigh(cov_matrices)\n",
    "\n",
    "        eigvecs = eigvecs[:, :, 0]\n",
    "\n",
    "        eigvals = eigvals[:,0]/(eigvals[:,0] + eigvals[:,1]  + eigvals[:,2]) \n",
    "        \n",
    "        x_offset = cp.abs(cp.arctan(eigvecs[:,0]/eigvecs[:,2]))\n",
    "        y_offset = cp.abs(cp.arctan(eigvecs[:,1]/eigvecs[:,2]))\n",
    "\n",
    "        results = {self.i_to_x_list[i]: [self.labeled_x_values[i],float(eigvals[i]),float(x_offset[i]),float(y_offset[i])] for i in range(len(self.i_to_x_list))}\n",
    "\n",
    "        cp.get_default_memory_pool().free_all_blocks()\n",
    " \n",
    "        self.rubble_classifications = results\n",
    "   \n",
    "    def _define_correction_windows(self, xrf_window_size=10,noise_threshold = 0.1, **kwargs):\n",
    "        for key, value in kwargs.items():\n",
    "            if value is not None and hasattr(self, key):\n",
    "                setattr(self, key, value)\n",
    "\n",
    "        self._define_sections(noise_threshold=noise_threshold)\n",
    "        self._classify_rubble()\n",
    "\n",
    "        windows = {}\n",
    "\n",
    "        for x_start in np.arange(0, np.nanmax(self.i_to_x_list), xrf_window_size):\n",
    "            values = [self.rubble_classifications[i] for i, x in zip(self.i_to_x_list, self.i_to_x_list) \n",
    "            if x_start <= x < x_start + xrf_window_size]\n",
    "            if values:\n",
    "                values = np.array(values)\n",
    "        \n",
    "                x_end = max(x for x in self.i_to_x_list if x_start <= x < x_start + xrf_window_size)\n",
    "                x_start = min(x for x in self.i_to_x_list if x_start <= x < x_start + xrf_window_size)\n",
    "            \n",
    "                \n",
    "                half_perc = np.sum(values[:,0] == 1) / len(values)\n",
    "                empty_perc = np.sum(values[:,0] == 2) / len(values)\n",
    "                full_perc = np.sum(values[:,0] == 3) / len(values)\n",
    "\n",
    "                rubble_perc = 1 - half_perc - empty_perc - full_perc\n",
    "\n",
    "                avg_var = np.nanmean(values[:, 1])\n",
    "                avg_x_offset = np.nanmean(values[:, 2])\n",
    "                avg_y_offset = np.nanmean(values[:, 3])\n",
    "\n",
    "                windows[(x_start, x_end)] = [half_perc, full_perc, empty_perc, rubble_perc, avg_var, avg_x_offset, avg_y_offset]\n",
    "\n",
    "        self.correction_windows = windows\n",
    "\n",
    "    def _save_correction_windows(self, xrf_window_size=10, noise_threshold = 0.1, **kwargs):\n",
    "        for key, value in kwargs.items():\n",
    "            if value is not None and hasattr(self, key):\n",
    "                setattr(self, key, value)\n",
    "\n",
    "        if self.correction_windows == None:\n",
    "            self._define_correction_windows(xrf_window_size, noise_threshold=noise_threshold)\n",
    "        \n",
    "        os.makedirs(self.file_path, exist_ok=True)\n",
    "        \n",
    "        file_path = os.path.join(self.file_path, 'rubble_classification.pkl')\n",
    "        \n",
    "        with open(file_path, 'wb') as f:\n",
    "            pickle.dump(self.correction_windows, f)\n",
    "\n",
    "    def _plot_correction_windows(self, width = 150, height = 7, dpi = 75, noise_threshold = 0.1, plot_point_cloud = False, xrf_window_size=10,**kwargs):\n",
    "        \n",
    "        for key, value in kwargs.items():\n",
    "            if value is not None and hasattr(self, key):\n",
    "                changed = True\n",
    "                setattr(self, key, value)\n",
    "\n",
    "        self._define_correction_windows(xrf_window_size=xrf_window_size, noise_threshold=noise_threshold)\n",
    "\n",
    "\n",
    "        fig, ax = plt.subplots(figsize=(width, height), dpi=dpi)\n",
    "\n",
    "        colormap = [\"green\", \"blue\", \"purple\", \"red\"]\n",
    "        cmap1 = plt.cm.cool  \n",
    "        cmap2 = plt.cm.cool\n",
    "\n",
    "        all_vars = []\n",
    "        x_angles = []\n",
    "        y_angles = []\n",
    "\n",
    "        for values in self.correction_windows.values():\n",
    "            var, x_angle, y_angle = values[4:7]\n",
    "            all_vars.append(var)\n",
    "            x_angles.append(x_angle)\n",
    "            y_angles.append(y_angle)\n",
    "\n",
    "        min_var = np.nanmin(all_vars)\n",
    "        max_var = np.nanmax(all_vars)\n",
    "        min_x_angle = np.nanmin(x_angles)\n",
    "        max_x_angle = np.nanmax(x_angles)\n",
    "        min_y_angle = np.nanmin(y_angles)\n",
    "        max_y_angle = np.nanmax(y_angles)\n",
    "\n",
    "        if plot_point_cloud:\n",
    "            display = self.point_cloud\n",
    "        else:\n",
    "            display = self.intensity_cloud\n",
    "        ax.imshow(cp.flipud(display), cmap=self.colourmap, interpolation='nearest', alpha=1, aspect= 'auto')\n",
    "\n",
    "        for (x_start, x_end), values in self.correction_windows.items():\n",
    "            half_perc, empty_perc, full_perc, rubble_perc = values[:4]\n",
    "\n",
    "            ratios = np.array([half_perc, empty_perc, full_perc, rubble_perc])\n",
    "            ratios /= ratios.sum()  \n",
    "\n",
    "            start_i = int(np.where(self.i_to_x_list == x_start)[0][0])\n",
    "            end_i = int(np.where(self.i_to_x_list == x_end)[0][0])\n",
    "            width = end_i - start_i + 1\n",
    "            bar_heights = ratios * 12  \n",
    "            bottoms = self.y_seed_point - 6 + np.insert(np.cumsum(bar_heights[:-1]), 0, 0)\n",
    "\n",
    "            for j in range(4):\n",
    "                ax.bar(start_i, height=bar_heights[j], width=width,\n",
    "                    bottom=bottoms[j], color=colormap[j], alpha=1, align = 'edge')\n",
    "\n",
    "            var, x_angle, y_angle = values[4:]\n",
    "            norm1 = plt.Normalize(vmin=min_var, vmax=max_var)\n",
    "            norm2 = plt.Normalize(vmin=min_x_angle, vmax=max_x_angle)\n",
    "            norm3 = plt.Normalize(vmin=min_y_angle, vmax=max_y_angle)\n",
    "            color1 = cmap1(norm1(var))\n",
    "            color2 = cmap2(norm2(x_angle))\n",
    "            color3 = cmap2(norm3(y_angle))\n",
    "            extra_heights = 7.5\n",
    "\n",
    "            ax.bar(start_i, height=extra_heights, width=width,\n",
    "                bottom=0, color=color1, align = 'edge')\n",
    "            ax.bar(start_i, height=extra_heights, width=width,\n",
    "                bottom=extra_heights, color=color2, align = 'edge')\n",
    "            ax.bar(start_i, height=extra_heights, width=width,\n",
    "                bottom=extra_heights*2, color=color3, align = 'edge')\n",
    "\n",
    "        ax.set_xlabel(\"X index\",fontsize = 20)\n",
    "        ax.set_ylabel(\"Y index\",fontsize = 20)\n",
    "        ax.set_xlim(0, display.shape[1])\n",
    "        ax.set_title(self.name, fontsize=35)\n",
    "\n",
    "        plt.show()\n",
    "\n",
    "    def _plot_gradient(self,width = 150, height = 7, dpi = 75, **kwargs):\n",
    "        changed = False\n",
    "        for key, value in kwargs.items():\n",
    "            if value is not None and hasattr(self, key):\n",
    "                changed = True\n",
    "                setattr(self, key, value)\n",
    "        \n",
    "        self._get_gradient()\n",
    "            \n",
    "        fig, ax = plt.subplots(figsize=(width, height), dpi=dpi)\n",
    "        ax.imshow(cp.flipud(self.gradient), cmap='nipy_spectral_r', interpolation='nearest', alpha = 1, aspect = 'auto')\n",
    "        ax.set_xlabel(\"X index\",fontsize = 20)\n",
    "        ax.set_ylabel(\"Y index\",fontsize = 20)\n",
    "        ax.set_title(self.name, fontsize=35)\n",
    "        plt.show()\n",
    "    \n",
    "    def _plot_edges(self,width = 150, height = 7, dpi = 75, **kwargs):\n",
    "        changed = False\n",
    "        for key, value in kwargs.items():\n",
    "            if value is not None and hasattr(self, key):\n",
    "                changed = True\n",
    "                setattr(self, key, value)\n",
    "\n",
    "        if self.edge_array is None or changed:\n",
    "            self._create_edge_array()\n",
    "            \n",
    "        fig, ax = plt.subplots(figsize=(width, height), dpi=dpi)\n",
    "        ax.imshow(cp.flipud(self.edge_array), cmap='nipy_spectral', interpolation='nearest', alpha = 1, aspect = 'auto')\n",
    "        ax.set_xlabel(\"X index\",fontsize = 20)\n",
    "        ax.set_ylabel(\"Y index\",fontsize = 20)\n",
    "        ax.set_title(self.name, fontsize=35)\n",
    "        plt.show()\n",
    "\n",
    "    def _plot_PCA_mask(self, width = 150, height = 7, dpi = 75, **kwargs):\n",
    "\n",
    "        changed = False\n",
    "\n",
    "        for key, value in kwargs.items():\n",
    "            if value is not None and hasattr(self, key):\n",
    "                changed = True\n",
    "                setattr(self, key, value)\n",
    "\n",
    "        if self.PCA_mask is None or changed:\n",
    "            self._create_PCA_mask()\n",
    "        fig, ax = plt.subplots(figsize=(width, height), dpi=dpi)\n",
    "        a = 1\n",
    "\n",
    "        ax.imshow(cp.flipud(self.PCA_mask), cmap='nipy_spectral', interpolation='nearest', alpha = a, aspect = 'auto')\n",
    "        ax.set_xlabel(\"X index\")\n",
    "        ax.set_ylabel(\"Y index\")\n",
    "        ax.set_title(self.name)\n",
    "        plt.show()\n",
    "\n",
    "    def _plot_sections(self,plot_point_cloud = False, plot_intensity_cloud = True, width = 150, height = 7, dpi = 75, **kwargs):\n",
    "\n",
    "        changed = False\n",
    "\n",
    "        for key, value in kwargs.items():\n",
    "            if value is not None and hasattr(self, key):\n",
    "                changed = True\n",
    "                setattr(self, key, value)\n",
    "\n",
    "        if self.edge_array is None or changed:\n",
    "            self._create_edge_array()\n",
    "        sections = self.edge_array.copy()\n",
    "    \n",
    "        neighbours = [(-1, 0), (0, -1), (0, 1), (1, 0)]  \n",
    "        nan_mask = np.isnan(sections)  \n",
    "\n",
    "        int = 2\n",
    "        for x in range(sections.shape[1]):\n",
    "            if nan_mask[self.y_seed_point, x]: \n",
    "                queue = deque([(self.y_seed_point, x)])\n",
    "                while queue:\n",
    "                    y, x = queue.popleft()\n",
    "                    sections[y, x] = int \n",
    "                    nan_mask[y, x] = False  \n",
    "                    neighbors_to_add = [(ny, nx) for dy, dx in neighbours\n",
    "                        if (0 <= (ny := y + dy) < sections.shape[0] and \n",
    "                            0 <= (nx := x + dx) < sections.shape[1] and nan_mask[ny, nx])]\n",
    "                    queue.extend(neighbors_to_add) \n",
    "                    for ny, nx in neighbors_to_add:\n",
    "                        nan_mask[ny, nx] = False \n",
    "            int += 1\n",
    "        \n",
    "        sections = np.where(sections > 1, sections, np.nan)\n",
    "\n",
    "        fig, ax = plt.subplots(figsize=(width, height), dpi=dpi)\n",
    "        a = 1\n",
    "        if plot_point_cloud:\n",
    "            ax.imshow(cp.flipud(self.point_cloud), cmap=self.colourmap, interpolation='nearest', alpha = 1, aspect= 'auto')\n",
    "            a = 0.8\n",
    "        if plot_intensity_cloud:\n",
    "            ax.imshow(cp.flipud(self.intensity_cloud), cmap=self.colourmap, interpolation='nearest', alpha = 0.8, aspect= 'auto')\n",
    "        ax.imshow(cp.flipud(sections), cmap='cool', interpolation='nearest', alpha = a, aspect= 'auto')\n",
    "        ax.set_xlabel(\"X index\")\n",
    "        ax.set_ylabel(\"Y index\")\n",
    "        ax.set_title(self.name)\n",
    "        plt.show()\n",
    "\n",
    "    def _view_point_cloud(self, intensity_cloud = False):\n",
    "        x = (list)(self.i_to_x_list) * len(self.i_to_y_list)\n",
    "        y = np.repeat(self.i_to_y_list, len(self.i_to_x_list))\n",
    "        if intensity_cloud:\n",
    "            z  = self.intensity_cloud.flatten()\n",
    "        else:\n",
    "            z = self.point_cloud.flatten()\n",
    "\n",
    "        pcd = o3d.geometry.PointCloud()\n",
    "        points = np.column_stack((x, y, -z))\n",
    "        pcd.points = o3d.utility.Vector3dVector(points)\n",
    "        \n",
    "        o3d.visualization.draw_geometries([pcd])\n",
    "\n",
    "    def _plot_point_cloud(self,width = 150, height = 7, dpi = 75, **kwargs):\n",
    "        for key, value in kwargs.items():\n",
    "            if value is not None and hasattr(self, key):\n",
    "                setattr(self, key, value)\n",
    "\n",
    "        fig, ax = plt.subplots(figsize=(width, height), dpi=dpi)\n",
    "        ax.imshow(cp.flipud(self.point_cloud), cmap=self.colourmap, interpolation='nearest', alpha = 1, aspect = 'auto')\n",
    "        ax.set_xlabel(\"X index\")\n",
    "        ax.set_ylabel(\"Y index\")\n",
    "        ax.set_title(self.name)\n",
    "        plt.show()\n",
    "\n",
    "    def _plot_intensity_cloud(self,width = 150, height = 7, dpi = 75, **kwargs):\n",
    "        for key, value in kwargs.items():\n",
    "            if value is not None and hasattr(self, key):\n",
    "                setattr(self, key, value)\n",
    "\n",
    "        fig, ax = plt.subplots(figsize=(width, height), dpi=dpi)\n",
    "        ax.imshow(cp.flipud(self.intensity_cloud), cmap=self.colourmap, interpolation='nearest', alpha = 1, aspect = 'auto')\n",
    "        ax.set_xlabel(\"X index\")\n",
    "        ax.set_ylabel(\"Y index\")\n",
    "        ax.set_title(self.name)\n",
    "        plt.show()\n",
    "\n",
    "    def _get_data_cube(self):\n",
    "        x = (list)(self.i_to_x_list) * len(self.i_to_y_list)\n",
    "        y = np.repeat(self.i_to_y_list, len(self.i_to_x_list))\n",
    "        z = self.point_cloud.flatten()\n",
    "\n",
    "        return np.column_stack((x, y, z))\n",
    "\n",
    "    def _save_to_las(self):\n",
    "        x = (list)(self.i_to_x_list) * len(self.i_to_y_list)\n",
    "        y = np.repeat(self.i_to_y_list, len(self.i_to_x_list))\n",
    "        z = self.point_cloud.flatten()\n",
    "\n",
    "        file_path = os.path.join(self.file_path, \"point_cloud_trimmed.las\")\n",
    "\n",
    "        header = laspy.LasHeader(point_format=1, version=\"1.2\") \n",
    "        las = laspy.LasData(header)\n",
    "\n",
    "        las.x = np.array(x)\n",
    "        las.y = np.array(y)\n",
    "        las.z = np.array(z)\n",
    "\n",
    "        las.write(file_path)\n",
    "\n",
    "    def _print_scan_limits(self, translated = True):\n",
    "        if translated:\n",
    "            data = self.original_cloud_limits\n",
    "            data[0] = data[0] * self.transformation_matrix[0,0] + self.transformation_matrix[0,3]\n",
    "            data[1] = data[1] * self.transformation_matrix[0,0] + self.transformation_matrix[0,3]\n",
    "            data[3] = data[3] * self.transformation_matrix[1,1] + self.transformation_matrix[1,3]\n",
    "            data[4] = data[4] * self.transformation_matrix[1,1] + self.transformation_matrix[1,3]\n",
    "            data[6] = data[6] * self.transformation_matrix[2,2] + self.transformation_matrix[1,3]\n",
    "            data[7] = data[7] * self.transformation_matrix[2,2] + self.transformation_matrix[2,3]\n",
    "            print(f\"limits in machine coordinates for {self.name}:\")\n",
    "        else:\n",
    "            data = self.original_cloud_limits\n",
    "            print(f\"limits in lidar coordinates for {self.name}:\")\n",
    "\n",
    "        print(f\" x value range: {data[0]}mm to {data[1]}mm, number of lines in the x direction: {data[2]}\")\n",
    "        print(f\" y value range: {data[3]}mm to {data[4]}mm, number of lines in the y direction: {data[5]}\")\n",
    "        print(f\" z value range: {data[6]}mm to {data[7]}mm, total number of points: {data[8]}\")\n",
    "        print(f\"pixel size: {self.x_pixel_size}mm in the x direction, {self.y_pixel_size}mm in the y direction\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "processors = []\n",
    "for i in range(5):\n",
    "    processors.append(ljx_processor(r\"C:\\Users\\eashenhurst\\Desktop\\local scans\\test_csv_core\\test 1\",\n",
    "                                    name = f\"scan 1 slot {i + 1}\", window_size= 17.5, y_shift =70*i,\n",
    "                                    strong_PCA_threshold = 0.15, weak_PCA_threshold = 0.025, strong_edge_threshold = 0.25, weak_edge_threshold = 0.075,\n",
    "                                    x_stop = 1225, box_length = 800))\n",
    "for i in range(5):\n",
    "    processors.append(ljx_processor(r\"C:\\Users\\eashenhurst\\Desktop\\local scans\\test_csv_core\\hyperspectral lights off\",\n",
    "                                    name = f\"scan 2 slot {i + 1}\", window_size= 17.5, y_shift =70*i,\n",
    "                                    strong_PCA_threshold = 0.15, weak_PCA_threshold = 0.025, strong_edge_threshold = 0.25, weak_edge_threshold = 0.075,\n",
    "                                    x_stop = 1500, box_length = 800))\n",
    "for i in range(5):\n",
    "    processors.append(ljx_processor(r\"C:\\Users\\eashenhurst\\Desktop\\local scans\\test_csv_core\\hyperspectral lights on\",\n",
    "                                    name = f\"scan 3 slot {i + 1}\", window_size= 17.5, y_shift =70*i,\n",
    "                                    strong_PCA_threshold = 0.15, weak_PCA_threshold = 0.025, strong_edge_threshold = 0.25, weak_edge_threshold = 0.075,\n",
    "                                    x_stop = 1350, box_length = 800))\n",
    "    \n",
    "print(f\"{len(processors)} ljx processors built\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for LP in processors:\n",
    "   LP._plot_correction_windows(dpi = 25)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "LP_env",
   "language": "python",
   "name": "lp_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
