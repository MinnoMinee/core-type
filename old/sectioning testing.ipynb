{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import gc\n",
    "import matplotlib.pyplot    as plt\n",
    "import numpy                as np\n",
    "import matplotlib.patches   as mpatches\n",
    "import plotly.graph_objects as go\n",
    "import networkx             as nx\n",
    "import cupy                 as cp\n",
    "from scipy.stats       import skew, kurtosis, mode\n",
    "from sklearn.cluster   import DBSCAN\n",
    "from scipy.ndimage     import convolve, generic_filter\n",
    "from cupyx.scipy.ndimage import convolve as cpconvolve\n",
    "from cupyx.scipy.ndimage import binary_dilation\n",
    "from scipy.signal import convolve2d\n",
    "from collections import deque\n",
    "from scipy.interpolate import interp1d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#point_cloud_indices\n",
    "label, heights, convolved_heights, intensity, x_to_i, i_to_x, y_to_i, i_to_y, sectioned = 0,1,2,3,4,5,6,7,8\n",
    "\n",
    "window_height = 15"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gc.collect()\n",
    "cp.get_default_memory_pool().free_all_blocks()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#File Parser\n",
    "\n",
    "class FileParser:\n",
    "    def __init__(self, root_dir):\n",
    "        self.root_dir = root_dir\n",
    "        self.box_folders = []\n",
    "\n",
    "    def find_folders(self):\n",
    "        for root, dirs, files in os.walk(self.root_dir):\n",
    "                for dir_name in dirs:\n",
    "                    if dir_name.startswith(\"Box\"):\n",
    "                        #for i in range(5,16):\n",
    "                        #adaptive_z_folder = os.path.join(root, dir_name, \"AdaptiveZ_10mm\")\n",
    "                            adaptive_z_folder = os.path.join(root, dir_name, f\"AdaptiveZ_10mm\")\n",
    "\n",
    "                            if os.path.isdir(adaptive_z_folder): \n",
    "                                for part_folder in os.listdir(adaptive_z_folder):\n",
    "                                    full_part_path = os.path.join(adaptive_z_folder, part_folder)\n",
    "                                    if os.path.isdir(full_part_path) and \"Part\" in part_folder:\n",
    "                                        component_parameters_path = None\n",
    "                                        lidar2xrf_path = None\n",
    "                                        bpc_path = None\n",
    "                                        real_dbg_path = None\n",
    "                                        lidar_times_path = None\n",
    "                                        for file_name in os.listdir(full_part_path):\n",
    "                                            if file_name.endswith(\".component_parameters.txt\"):\n",
    "                                                component_parameters_path = os.path.join(full_part_path, file_name)\n",
    "                                            elif file_name.endswith(\".lidar2xrf\"):\n",
    "                                                lidar2xrf_path = os.path.join(full_part_path, file_name)\n",
    "                                            elif file_name.endswith(\".bpc\"):\n",
    "                                                bpc_path = os.path.join(full_part_path, file_name)\n",
    "                                            elif file_name.endswith(\"_intensity.png\"):\n",
    "                                                intensity_path = os.path.join(full_part_path, file_name)\n",
    "                                            elif file_name.endswith(\"real.dbg\"):\n",
    "                                                real_dbg_path = os.path.join(full_part_path, file_name)\n",
    "                                            elif file_name.endswith(\".dbg\"):\n",
    "                                                lidar_times_path = os.path.join(full_part_path, file_name)\n",
    "\n",
    "                                        self.box_folders.append((f\"{part_folder} 10mm\",component_parameters_path, lidar2xrf_path, bpc_path, intensity_path, real_dbg_path, lidar_times_path))\n",
    "\n",
    "    def get_box_folders(self):\n",
    "        self.find_folders()\n",
    "        return self.box_folders\n",
    "\n",
    "parser = FileParser(r\"C:\\Users\\eashenhurst\\Desktop\\local macassa\")\n",
    "paths_list = parser.get_box_folders()\n",
    "\n",
    "for name, component_parameters_path, lidar2xrf_path, bpc_path, intensity_path, real_dbg_path, lidar_times_path  in paths_list:\n",
    "    print(f\"Part: {name}\")\n",
    "    if component_parameters_path:\n",
    "        print(f\"  Component Parameters: {component_parameters_path}\")\n",
    "    if lidar2xrf_path:\n",
    "        print(f\"  LIDAR to XRF: {lidar2xrf_path}\")\n",
    "    if bpc_path:\n",
    "        print(f\"  BPC File: {bpc_path}\")\n",
    "    if intensity_path:\n",
    "        print(f\"  Intensity File: {intensity_path}\")\n",
    "    if lidar_times_path:\n",
    "        print(f\"  lidar time stamps file: {lidar_times_path}\")\n",
    "    if real_dbg_path:\n",
    "        print(f\"  real dbg file: {real_dbg_path}\")\n",
    "\n",
    "\n",
    "class BasicParser:\n",
    "    def __init__(self, root_dir):\n",
    "        self.root_dir = root_dir\n",
    "        self.box_folders = []\n",
    "\n",
    "    def find_folders(self):\n",
    "        for root, dirs, files in os.walk(self.root_dir):\n",
    "                for dir_name in dirs:\n",
    "                    if dir_name.startswith(\"Core\"):\n",
    "                        folder = os.path.join(root,dir_name)\n",
    "                      \n",
    "                        if os.path.isdir(folder) and \"0\" in folder:\n",
    "                            component_parameters_path = None\n",
    "                            lidar2xrf_path = None\n",
    "                            bpc_path = None\n",
    "                            intensity_path = None\n",
    "                            real_dbg_path = None\n",
    "                            lidar_times_path = None\n",
    "                            for file_name in os.listdir(folder):\n",
    "                                if file_name.endswith(\".component_parameters.txt\"):\n",
    "                                    component_parameters_path = os.path.join(folder, file_name)\n",
    "                                elif file_name.endswith(\".lidar2xrf\"):\n",
    "                                    lidar2xrf_path = os.path.join(folder, file_name)\n",
    "                                elif file_name.endswith(\".bpc\"):\n",
    "                                    bpc_path = os.path.join(folder, file_name)\n",
    "                                elif file_name.endswith(\"_intensity.png\"):\n",
    "                                    intensity_path = os.path.join(folder, file_name)\n",
    "                                elif file_name.endswith(\"real.dbg\"):\n",
    "                                    real_dbg_path = os.path.join(folder, file_name)\n",
    "                                elif file_name.endswith(\".dbg\"):\n",
    "                                    lidar_times_path = os.path.join(folder, file_name)\n",
    "\n",
    "                            self.box_folders.append((folder,component_parameters_path, lidar2xrf_path, bpc_path, intensity_path, real_dbg_path, lidar_times_path))\n",
    "\n",
    "\n",
    "    def get_box_folders(self):\n",
    "        self.find_folders()\n",
    "        return self.box_folders\n",
    "\n",
    "\n",
    "\n",
    "parser = BasicParser(r\"\\\\192.168.1.100\\CoreScan3-2\\Acquisitions\\RnD\\XRF 2.0\\same core scans\\AI21-TarcoreDoubleScans old xrf head\\AI21-XRF1.0\")\n",
    "paths_list = parser.get_box_folders()\n",
    "\n",
    "for name, component_parameters_path, lidar2xrf_path, bpc_path, intensity_path, real_dbg_path, lidar_times_path  in paths_list:\n",
    "    print(f\"Part: {name}\")\n",
    "    if component_parameters_path:\n",
    "        print(f\"  Component Parameters: {component_parameters_path}\")\n",
    "    if lidar2xrf_path:\n",
    "        print(f\"  LIDAR to XRF: {lidar2xrf_path}\")\n",
    "    if bpc_path:\n",
    "        print(f\"  BPC File: {bpc_path}\")\n",
    "    if intensity_path:\n",
    "        print(f\"  Intensity File: {intensity_path}\")\n",
    "    if lidar_times_path:\n",
    "        print(f\"  lidar time stamps file: {lidar_times_path}\")\n",
    "    if real_dbg_path:\n",
    "        print(f\"  real dbg file: {real_dbg_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_vectors(data, y_span=10):\n",
    "    vectors = {}\n",
    "    \n",
    "    for point_cloud in data:\n",
    "        \n",
    "        name = point_cloud[0]\n",
    "        cloud = point_cloud[1]\n",
    "        \n",
    "        i_to_x = point_cloud[3]\n",
    "        y_to_i = point_cloud[4]\n",
    "        \n",
    "        y_indices = [y_to_i[value] for value in y_to_i.keys() if abs(value) <= y_span]\n",
    "\n",
    "        for i in range(len(cloud[0])):\n",
    "            x = i_to_x[i]\n",
    "            distribution = []\n",
    "            for j in y_indices:\n",
    "                distribution.append(cloud[j][i])\n",
    "            properties = get_props(distribution)\n",
    "            if not (np.any(np.isnan(properties))):\n",
    "                vectors[(name, x)] = properties\n",
    "\n",
    "    return vectors\n",
    "\n",
    "def get_vectors_combined(data1, data2, x_values_dict, y_span=10):\n",
    "    vectors = {}   \n",
    "\n",
    "    for point_cloud,convolved_cloud in zip(data1,data2):\n",
    "        \n",
    "        name = point_cloud[0]\n",
    "        x_values = x_values_dict[name]\n",
    "        cloud = point_cloud[1]\n",
    "        convolved_cloud = convolved_cloud[1]\n",
    "        \n",
    "        x_to_i = point_cloud[2]\n",
    "        y_to_i = point_cloud[4]\n",
    "        \n",
    "        y_indices = [y_to_i[value] for value in y_to_i.keys() if abs(value) <= y_span]\n",
    "\n",
    "        for x in x_values:\n",
    "            i = x_to_i[x]\n",
    "            distribution = []\n",
    "            convolved_distribution = []\n",
    "            for j in y_indices:\n",
    "                distribution.append(cloud[j][i])\n",
    "                convolved_distribution.append(convolved_cloud[j][i])\n",
    "            properties = get_props(distribution)\n",
    "            convolved_properties = get_props_convolved(convolved_distribution)\n",
    "            vector = convolved_properties + properties\n",
    "            if not (np.any(np.isnan(vector))):\n",
    "                vectors[(name, x)] = vector\n",
    "\n",
    "    return vectors\n",
    "\n",
    "def get_props_convolved(distribution):\n",
    "    properties = []\n",
    "\n",
    "    mean = np.sqrt(np.mean(distribution))\n",
    "    max = np.sqrt(np.max(distribution))\n",
    "\n",
    "    variance =  np.var(distribution)\n",
    "    skw = skew(distribution)\n",
    "    kurt = kurtosis(distribution)\n",
    "\n",
    "    \n",
    "    properties.append(variance)\n",
    "    properties.append(skw)\n",
    "    properties.append(kurt)\n",
    "    \n",
    "\n",
    "    norm = np.linalg.norm(properties)\n",
    "    \n",
    "    if norm > 0:\n",
    "        properties = [x / norm for x in properties]\n",
    "    \n",
    "\n",
    "    properties.append(mean)\n",
    "    properties.append(max)\n",
    "\n",
    "    z = properties[0]\n",
    "    y = properties[1]\n",
    "    x = properties[2]\n",
    "\n",
    "    properties.append((np.arctan2(y,x) + (2 * np.pi)) % (2 * np.pi))\n",
    "    properties.append(np.arctan(z)/(np.pi/2))\n",
    "\n",
    "\n",
    "    return properties\n",
    "\n",
    "def get_props(distribution):\n",
    "    properties = []\n",
    "\n",
    "    variance =  np.var(distribution)\n",
    "    skw = skew(distribution)\n",
    "    kurt = kurtosis(distribution)\n",
    "\n",
    "    \n",
    "    properties.append(variance)\n",
    "    properties.append(skw)\n",
    "    properties.append(kurt)\n",
    "\n",
    "    norm = np.linalg.norm(properties)\n",
    "    \n",
    "    if norm > 0:\n",
    "        properties = [x / norm for x in properties]\n",
    "\n",
    "    z = properties[0]\n",
    "\n",
    "    properties.append(np.arccos(z)/(np.pi/2))\n",
    "\n",
    "    return properties\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def interpolate_x(table_file,lidar_file):\n",
    "    with open(table_file) as file:\n",
    "        lines = file.readlines()\n",
    "\n",
    "        positions = []\n",
    "        table_timestamps = []\n",
    "\n",
    "        char = '-'\n",
    "\n",
    "        for line in lines:\n",
    "            if (\"+\") in line:\n",
    "                char = '+'\n",
    "            time = line.split('T')[1]\n",
    "            x = float(line.split(',')[0])\n",
    "            parts = time.split(':')\n",
    "            t = float(parts[0]) * 3600 + float(parts[1]) * 60 + float(parts[2].split(char)[0]) \n",
    "            positions.append(x)\n",
    "            table_timestamps.append(t)\n",
    "\n",
    "    ordered_positions = []\n",
    "    ordered_timestamps = []\n",
    "\n",
    "    decreasing = (positions[-1] - positions[0]) < 0 \n",
    "\n",
    "    if decreasing:\n",
    "        for i in range(len(positions)-1):\n",
    "            if positions[i + 1] < positions[i]:\n",
    "                ordered_positions.append(positions[i])\n",
    "                ordered_timestamps.append(table_timestamps[i])\n",
    "    else:\n",
    "         for i in range(len(positions)-1):\n",
    "            if positions[i + 1] > positions[i]:\n",
    "                ordered_positions.append(positions[i])\n",
    "                ordered_timestamps.append(table_timestamps[i])\n",
    "\n",
    "\n",
    "    with open(lidar_file) as file:\n",
    "        lines = file.readlines()\n",
    "\n",
    "        lidar_timestamps = []\n",
    "\n",
    "        time = lines[0].split('T')[1]\n",
    "        parts = time.split(':')\n",
    "        min_t = float(parts[1]) * 60  + float(parts[0]) * 3600 + float(parts[2].split(char)[0]) \n",
    "\n",
    "        for line in lines:\n",
    "            time = line.split('T')[1]\n",
    "            parts = time.split(':')\n",
    "            t = float(parts[0]) * 3600 + float(parts[1]) * 60 + float(parts[2].split(char)[0]) - min_t\n",
    "            lidar_timestamps.append(t)\n",
    "\n",
    "\n",
    "    lidar_timestamps = np.array(lidar_timestamps)\n",
    "    ordered_timestamps = np.array(ordered_timestamps)[::-1]\n",
    "    ordered_timestamps -= min_t\n",
    "    ordered_positions = ordered_positions[::-1]\n",
    "\n",
    "    ordered_timestamps = np.concatenate([ordered_timestamps[:2], ordered_timestamps[-2:]])\n",
    "    ordered_positions = np.concatenate([ordered_positions[:2], ordered_positions[-2:]])\n",
    "\n",
    "    interp_func = interp1d(ordered_timestamps, ordered_positions, kind=\"linear\", fill_value=(ordered_positions[-1], ordered_positions[0]), bounds_error=False) \n",
    "\n",
    "    interpolated = interp_func(lidar_timestamps)\n",
    "            \n",
    "    return interpolated\n",
    "\n",
    "def get_point_cloud(paths, y_window = window_height + 5, upsample_ratio = 2):\n",
    "    print(\"loading\",end = \"... \")\n",
    "\n",
    "    x_start = 50000\n",
    "    x_stop = 0\n",
    "    y_offset = 0\n",
    "    with open(paths[1]) as file:\n",
    "            lines = file.readlines()\n",
    "            for line in lines:\n",
    "                if \"XRAY_DPP[Acquisition]#0.X.Start:\" in line:\n",
    "                    x_start = (float)(line.split(\"XRAY_DPP[Acquisition]#0.X.Start:\")[1].strip())\n",
    "                if \"XRAY_DPP[Acquisition]#0.X.Stop:\" in line:\n",
    "                    x_stop = (float)(line.split(\"XRAY_DPP[Acquisition]#0.X.Stop:\")[1].strip())\n",
    "                if \"XRAY_DPP[Acquisition]#0.Y.Start:\" in line:\n",
    "                    y_offset = (float)(line.split(\"XRAY_DPP[Acquisition]#0.Y.Start:\")[1].strip())\n",
    "                    print(f\"y_offset: {y_offset}\")\n",
    "\n",
    "    with open(paths[2]) as file:\n",
    "        lines = file.readlines()\n",
    "        transformation_matrix = np.array([list(map(float, line.strip().split(\",\"))) for line in lines])\n",
    "\n",
    "    imread = lambda fn: cv2.imread(fn, cv2.IMREAD_ANYDEPTH)\n",
    "    \n",
    "    point_cloud  = np.fromfile(paths[3], dtype=np.float32).reshape(-1, 3) \n",
    "\n",
    "    interpolated_x = interpolate_x(paths[5],paths[6])\n",
    "    interpolated_x = np.repeat(interpolated_x, len(np.unique(point_cloud[:, 1])))\n",
    "\n",
    "    intensity_map = imread(paths[4])\n",
    "    \n",
    "    print(f\"{paths[0]} loaded, {point_cloud.shape[0]} points\")\n",
    "    print(\"trimming\",end = \"... \")\n",
    "    \n",
    "    intensity_values = np.reshape(intensity_map, (-1, 1))\n",
    "    print(np.nanmax(intensity_values))\n",
    "    intensity_cloud = np.hstack((point_cloud[:,:2], intensity_values))\n",
    "\n",
    "    point_cloud = (np.hstack((point_cloud, np.ones((point_cloud.shape[0], 1)))) @ transformation_matrix.T)[:,:3]\n",
    "    intensity_cloud = (np.hstack((intensity_cloud, np.ones((intensity_cloud.shape[0], 1)))) @ transformation_matrix.T)[:,:3]\n",
    "\n",
    "    mask = (point_cloud[:,0] <= x_start) & (point_cloud[:,0] >= x_stop) & ((np.abs(point_cloud[:,1])) <= y_window)\n",
    "    point_cloud = point_cloud[mask]\n",
    "    intensity_cloud = intensity_cloud[mask]\n",
    "\n",
    "    min_intensity = np.nanmax(intensity_cloud[:,2])\n",
    "    min_z = np.nanmax(point_cloud[:,2])\n",
    "    \n",
    "    print(f\"trimmed to {point_cloud.shape[0]} points\")\n",
    "\n",
    "    print(\"converting to arrays\",end = \"... \")\n",
    "\n",
    "    minimum_x = point_cloud[np.argmin(np.abs(point_cloud[:,0] - x_stop)),0]\n",
    "\n",
    "    point_cloud[:,0] -= minimum_x\n",
    "    intensity_cloud[:,0] -= minimum_x\n",
    "    \n",
    "    x_values = np.unique(point_cloud[:,0])\n",
    "    y_values = np.unique(point_cloud[:,1]) \n",
    "\n",
    "    x_range = len(x_values)\n",
    "\n",
    "    if upsample_ratio > 1:\n",
    "        index_step = (np.nanmedian(np.diff(x_values))) / upsample_ratio \n",
    "        index_steps = np.arange(int(round(np.nanmax(x_values)/index_step))+1) * index_step\n",
    "\n",
    "        x_range = len(index_steps)\n",
    "        x_value_dict = {x: np.argmin(np.abs(index_steps - x)) for x in x_values}\n",
    "        known_indices = list(x_value_dict.values())\n",
    "        known_x_values = np.array(list(x_value_dict.keys()), dtype=float)\n",
    "        all_indices = np.arange(x_range)\n",
    "\n",
    "        interp_func = interp1d(known_indices, known_x_values, kind=\"linear\", fill_value=\"extrapolate\")\n",
    "        x_values = interp_func(all_indices)\n",
    "    \n",
    "    x_value_dict = {x: index for index,x in enumerate(x_values)}\n",
    "    y_value_dict = {y: index for index,y in enumerate(y_values)}\n",
    "\n",
    "    point_array = np.full((len(y_values), x_range),np.nan)\n",
    "    intensity_array = np.full((len(y_values), x_range),np.nan)\n",
    "    point_dictionary = {(row[0],row[1]): (index, row[2]) for index,row in enumerate(point_cloud)}\n",
    "    intensity_dictionary = {(row[0],row[1]): (index, row[2]) for index,row in enumerate(intensity_cloud)}\n",
    "\n",
    "    for x in range (x_range):\n",
    "        for y in range (len(y_values)):\n",
    "            x_val = x_values[x]\n",
    "            y_val = y_values[y]\n",
    "\n",
    "            point_z = point_dictionary.get((x_val,y_val))\n",
    "            intensity_z = intensity_dictionary.get((x_val,y_val))\n",
    "\n",
    "            if point_z is not None:\n",
    "                point_array[y,x] = point_z[1]\n",
    "            else:\n",
    "                point_array[y,x] = min_z\n",
    "            if intensity_z is not None:\n",
    "                intensity_array[y,x] = intensity_z[1]\n",
    "            else:\n",
    "                intensity_array[y,x] = min_intensity\n",
    "\n",
    "    print(f\"arrays built\")\n",
    "    if upsample_ratio > 1:\n",
    "        print(\"upsampling\",end = \"... \")\n",
    "\n",
    "        for y in range(len(y_values)):\n",
    "\n",
    "            interpolated_z_values= []\n",
    "            interpolated_i_values = []\n",
    "\n",
    "            for dy in [-1,0,1]:\n",
    "                y_dy = y + dy\n",
    "                if (y_dy >= 0) & (y_dy < len(y_values)):\n",
    "                    known_z = point_array[y_dy,known_indices]\n",
    "                    known_i = intensity_array[y_dy,known_indices]\n",
    "                    known_x = x_values[known_indices]\n",
    "                    mask = ~np.isnan(known_z)\n",
    "                    z_interp = interp1d(known_x[mask], known_z[mask], kind='linear', fill_value=\"extrapolate\")\n",
    "                    i_interp = interp1d(known_x[mask], known_i[mask], kind='linear', fill_value=\"extrapolate\")\n",
    "\n",
    "                    interpolated_z_values.append(z_interp(x_values))\n",
    "                    interpolated_i_values.append(i_interp(x_values))\n",
    "\n",
    "            point_array[y, :] = np.mean(interpolated_z_values, axis=0)\n",
    "            intensity_array[y, :] = np.mean(interpolated_i_values, axis=0)\n",
    "    \n",
    "    kernel_y = np.array([[-1],[-2],[0],[2],[1]])\n",
    "    convolved_array = np.abs(convolve(point_array,kernel_y))\n",
    "\n",
    "    print(f\"upsampled to {point_array.size} points\")\n",
    "    print(f\"{paths[0]} finished \\n\")\n",
    "\n",
    "    return [paths[0],point_array, convolved_array, intensity_array, x_value_dict, x_values, y_value_dict, y_values]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Get the point clouds\n",
    "point_clouds = []\n",
    "\n",
    "for paths in paths_list: \n",
    "    if None not in paths:\n",
    "        point_clouds.append(get_point_cloud(paths, y_window = 15,upsample_ratio=4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(150, 7 * len(point_clouds)), dpi=150)  \n",
    "gs = fig.add_gridspec(len(point_clouds) * 2, 1, hspace=0.6)  \n",
    "\n",
    "for (i, point_cloud) in enumerate(point_clouds):\n",
    "    name = point_cloud[0]\n",
    "    cloud_1 = point_cloud[1]\n",
    "    cloud_2 = point_cloud[3]\n",
    "    \n",
    "\n",
    "    ax = fig.add_subplot(gs[i * 2, 0])\n",
    "    ax.imshow(np.flipud(cloud_1), cmap='jet', interpolation='nearest', alpha = 1)    \n",
    "    ax.set_xlabel(\"X index\")\n",
    "    ax.set_ylabel(\"Y index\")\n",
    "    ax.set_title(f\"Point Cloud: {name}\", fontsize = 30 ) \n",
    "\n",
    "    ax = fig.add_subplot(gs[i* 2 + 1, 0])\n",
    "    ax.imshow(np.flipud(cloud_2), cmap='binary', interpolation='nearest', alpha = 1)    \n",
    "    ax.set_xlabel(\"X index\")\n",
    "    ax.set_ylabel(\"Y index\") \n",
    "\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#kernels\n",
    "gauss =  cp.array([\n",
    "    [1,  4,  7,  4,  1],\n",
    "    [4, 16, 26, 16,  4],\n",
    "    [7, 26, 41, 26,  7],\n",
    "    [4, 16, 26, 16,  4],\n",
    "    [1,  4,  7,  4,  1]\n",
    "]) / 273\n",
    "\n",
    "gauss_y =  cp.array([\n",
    "    [1],\n",
    "    [4],\n",
    "    [7],\n",
    "    [4],\n",
    "    [1]\n",
    "]) / 17\n",
    "sobel_x = cp.array([\n",
    "    [ 0.5, 1.25,  0.0,  -1.25, -0.5],\n",
    "    [   1,  2.5,  0.0,   -2.5,   -1],\n",
    "    [ 0.5, 1.25,  0.0,  -1.25, -0.5]\n",
    "]) / 7\n",
    "simple_x = cp.array([\n",
    "    [-1,0,1]\n",
    "]) \n",
    "\n",
    "simple_y = cp.array([\n",
    "    [-1],\n",
    "    [0],\n",
    "    [1]\n",
    "]) \n",
    "\n",
    "\n",
    "sobel_x_2 = cp.array([\n",
    "    [1.25, 0.5, 0.0, -0.5,  -1.25],\n",
    "    [ 2.5,   1, 0.0,   -1,   -2.5],\n",
    "    [1.25, 0.5, 0.0, -0.5,  -1.25]\n",
    "]) / 7\n",
    "\n",
    "sobel_y = cp.array([\n",
    "        [-20.75,],\n",
    "        [ -11.6,],\n",
    "        [ -6.27,],\n",
    "        [    -2,],\n",
    "        [     0,],\n",
    "        [     2,],\n",
    "        [  6.27,],\n",
    "        [  11.6,],\n",
    "        [ 20.75,]\n",
    "])\n",
    "sobel_x = sobel_y.T\n",
    "#sobel_y = cp.array([ \n",
    "#        [  0.5,   1,   0.5,],\n",
    "#        [ 1.25,  2.5, 1.25,],\n",
    "#        [    0,    0,    0,],\n",
    "#        [-1.25, -2.5,-1.25,],\n",
    "#        [ -0.5,   -1, -0.5,],\n",
    "#]) /10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def PCA_curvature(data, y_window=5, x_window=4):\n",
    "    array = cp.array(data[1], dtype=cp.float32)\n",
    "    array = cpconvolve(array,gauss)\n",
    "\n",
    "    y_values = data[7]\n",
    "\n",
    "    y_bottom = np.argmin(np.abs(y_values - 10))\n",
    "    y_top = np.argmin(np.abs(y_values + 10))\n",
    "\n",
    "    height, width = array.shape\n",
    "    y_range, x_range = 2 * y_window + 1, 2 * x_window + 1\n",
    "\n",
    "    x_n = cp.arange(-x_window, x_window + 1) \n",
    "    y_n = cp.arange(-y_window, y_window + 1)\n",
    "    valid_x = cp.repeat(x_n, y_range).flatten()\n",
    "    valid_y = cp.tile(y_n, x_range).flatten()\n",
    "\n",
    "    points = cp.lib.stride_tricks.sliding_window_view(\n",
    "        cp.pad(array, ((y_window,y_window), (x_window,x_window)), mode='edge'), (y_range, x_range)\n",
    "    )\n",
    "    del array\n",
    "\n",
    "    points = points.reshape(height,width, y_range*x_range)\n",
    "    \n",
    "    points = cp.stack((\n",
    "        cp.broadcast_to(valid_x, (height,width, y_range*x_range)),\n",
    "        cp.broadcast_to(valid_y, (height,width, y_range*x_range)),\n",
    "        points), axis=2)\n",
    "    mean_vals = cp.mean(points[:,:,2,:], axis=(2), keepdims=True)\n",
    "    points[:,:,2,:] -= mean_vals\n",
    "\n",
    "    cov_matrices = cp.matmul(points, points.transpose(0, 1, 3, 2)) / (points.shape[3] - 1)\n",
    "    del points \n",
    "\n",
    "    a, b, c, d, e, f, g, h, i = (\n",
    "        cov_matrices[:, :, 0, 0], cov_matrices[:, :, 0, 1], cov_matrices[:, :, 0, 2],\n",
    "        cov_matrices[:, :, 1, 0], cov_matrices[:, :, 1, 1], cov_matrices[:, :, 1, 2],\n",
    "        cov_matrices[:, :, 2, 0], cov_matrices[:, :, 2, 1], cov_matrices[:, :, 2, 2]\n",
    "    )\n",
    "\n",
    "    p1 = b**2 + c**2 + f**2\n",
    "    q = (a + e + i) / 3\n",
    "    p2 = (a - q)**2 + (e - q)**2 + (i - q)**2 + 2 * p1\n",
    "    p = cp.sqrt(p2 / 6)\n",
    "    \n",
    "    B = (cov_matrices - cp.eye(3, dtype=cp.float32) * q[:, :, None, None]) / p[:, :, None, None]\n",
    "    r = cp.linalg.det(B) / 2\n",
    "    phi = cp.arccos(cp.clip(r, -1, 1)) / 3\n",
    "\n",
    "    eigvals_3 = q + 2 * p * cp.cos(phi)\n",
    "    eigvals_2 = q + 2 * p * cp.cos(phi + (2 * cp.pi / 3))\n",
    "    eigvals_1 = 3 * q - eigvals_3 - eigvals_2  \n",
    "\n",
    "    print(np.nanmean(eigvals_1))\n",
    "    print(np.nanmedian(eigvals_2))\n",
    "    print(np.nanmedian(eigvals_3))\n",
    "    \n",
    "    curvature_array_1 = (eigvals_1 > 5.052).astype(cp.float32)\n",
    "    curvature_array_2 = (eigvals_2 > 5.00075).astype(cp.float32)\n",
    "    curvature_array_3 = (eigvals_3 > 5.1059).astype(cp.float32)\n",
    "\n",
    "    mask = cp.asnumpy(curvature_array_1 + curvature_array_2 + curvature_array_3)\n",
    "\n",
    "    mask[:y_top, :] = 0\n",
    "    mask[y_bottom:, :] = 0\n",
    "    \n",
    "    neighbours = [(-1, -1), (-1, 0), (-1, 1), (0, -1), (0, 1), (1, -1), (1, 0), (1, 1)]\n",
    "\n",
    "    strong_y, strong_x = np.where(mask > 1)\n",
    "    weak_mask = (mask == 1).astype(np.uint8) \n",
    "    Hyst_mask = np.zeros_like(mask, dtype=cp.uint8)\n",
    "\n",
    "    queue = deque(zip(strong_y, strong_x))\n",
    "    while queue:\n",
    "        y, x = queue.popleft() \n",
    "        Hyst_mask[y, x] = 4 - mask[y, x]\n",
    "        for dy, dx in neighbours:\n",
    "            ny, nx = y + dy, x + dx\n",
    "            if 0 <= ny < mask.shape[0] and 0 <= nx < mask.shape[1]:\n",
    "                if weak_mask[ny, nx]:\n",
    "                    weak_mask[ny, nx] = 0 \n",
    "                    queue.append((ny, nx)) \n",
    "   \n",
    "    return [cp.asnumpy(eigvals_1),cp.asnumpy(eigvals_2),cp.asnumpy(eigvals_3)]\n",
    "\n",
    "\n",
    "def PCA_eig2(data, y_window=5, x_window=4, s = 0.001, w = 0.0005):\n",
    "    array = cp.array(data[heights], dtype=cp.float32)\n",
    "    y_values = data[i_to_y]\n",
    "    height, width = array.shape\n",
    "    y_range, x_range = 2 * y_window + 1, 2 * x_window + 1\n",
    "\n",
    "    y_bottom = np.argmin(np.abs(y_values - window_height))\n",
    "    y_top = np.argmin(np.abs(y_values + window_height))\n",
    "\n",
    "    x_n = cp.arange(-x_window, x_window + 1) /4\n",
    "    y_n = cp.arange(-y_window, y_window + 1) /4.5\n",
    "    valid_x = cp.repeat(x_n, y_range).flatten()\n",
    "    valid_y = cp.tile(y_n, x_range).flatten()\n",
    "\n",
    "    points = cp.lib.stride_tricks.sliding_window_view(\n",
    "        cp.pad(array, ((y_window,y_window), (x_window,x_window)), mode='edge'), (y_range, x_range)\n",
    "    )\n",
    "    del array\n",
    "\n",
    "    points = points.reshape(height,width, y_range*x_range)\n",
    "    \n",
    "    points = cp.stack((\n",
    "        cp.broadcast_to(valid_x, (height,width, y_range*x_range)),\n",
    "        cp.broadcast_to(valid_y, (height,width, y_range*x_range)),\n",
    "        points), axis=2)\n",
    "    mean_vals = cp.mean(points[:,:,2,:], axis=(2), keepdims=True)\n",
    "    points[:,:,2,:] -= mean_vals\n",
    "\n",
    "    cov_matrices = cp.matmul(points, points.transpose(0, 1, 3, 2)) / (points.shape[3] - 1)\n",
    "    del points \n",
    "\n",
    "    a, b, c, d, e, f, g, h, i = (\n",
    "        cov_matrices[:, :, 0, 0], cov_matrices[:, :, 0, 1], cov_matrices[:, :, 0, 2],\n",
    "        cov_matrices[:, :, 1, 0], cov_matrices[:, :, 1, 1], cov_matrices[:, :, 1, 2],\n",
    "        cov_matrices[:, :, 2, 0], cov_matrices[:, :, 2, 1], cov_matrices[:, :, 2, 2]\n",
    "    )\n",
    "\n",
    "    p1 = b**2 + c**2 + f**2\n",
    "    q = (a + e + i) / 3\n",
    "    p2 = (a - q)**2 + (e - q)**2 + (i - q)**2 + 2 * p1\n",
    "    p = cp.sqrt(p2 / 6)\n",
    "    \n",
    "    B = (cov_matrices - cp.eye(3, dtype=cp.float32) * q[:, :, None, None]) / p[:, :, None, None]\n",
    "    r = cp.linalg.det(B) / 2\n",
    "    phi = cp.arccos(cp.clip(r, -1, 1)) / 3\n",
    "    del cov_matrices\n",
    "\n",
    "    eigvals_2 = q + 2 * p * cp.cos(phi + (2 * cp.pi / 3))\n",
    "    eigvals_2 = cp.asnumpy(eigvals_2)\n",
    "    eigvals_2[:y_top, :] = 0\n",
    "    eigvals_2[y_bottom:, :] = 0\n",
    "\n",
    "    neighbours = [(-1, -1), (-1, 0), (-1, 1), (0, -1), (0, 1), (1, -1), (1, 0), (1, 1)]\n",
    "    strong_y, strong_x = np.where(eigvals_2 >= s)\n",
    "    weak_values = (eigvals_2 >= w) & (eigvals_2 < s).astype(np.uint8) \n",
    "    return_array = np.zeros_like(eigvals_2, dtype=cp.uint8)\n",
    "    \n",
    "    cp.get_default_memory_pool().free_all_blocks()\n",
    "\n",
    "    queue = deque(zip(strong_y, strong_x))\n",
    "    while queue:\n",
    "        y, x = queue.popleft() \n",
    "        return_array[y, x] = 1\n",
    "        for dy, dx in neighbours:\n",
    "            ny, nx = y + dy, x + dx\n",
    "            if 0 <= ny < weak_values.shape[0] and 0 <= nx < weak_values.shape[1]:\n",
    "                if weak_values[ny, nx]:\n",
    "                    weak_values[ny, nx] = 0 \n",
    "                    queue.append((ny, nx)) \n",
    "    del weak_values \n",
    "\n",
    "    return [return_array, eigvals_2]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_gradient_NMS(data):\n",
    "    array_i = cp.array(np.log(np.abs(data[intensity])), dtype=cp.float32)\n",
    "    array_z = cp.array(data[heights], dtype=cp.float32)\n",
    "    y_values = data[i_to_y]\n",
    "\n",
    "    y_grad_i = cp.abs(cpconvolve(array_i, sobel_y))\n",
    "    x_grad_i = cp.abs(cpconvolve(array_i, sobel_x))\n",
    "    magnitude_i = cp.sqrt(x_grad_i**2 + y_grad_i**2)\n",
    "    y_grad_i = cp.abs(cpconvolve(array_i, sobel_y))\n",
    "    magnitude_i = cp.sqrt(x_grad_i**2 + y_grad_i**2)\n",
    "\n",
    "    x_grad_z = cp.abs(cpconvolve(array_z, sobel_y))\n",
    "    y_grad_z = cp.abs(cpconvolve(array_z, sobel_x))\n",
    "    magnitude_z = cp.sqrt(x_grad_z**2 + y_grad_z**2)\n",
    "    y_grad_z = cp.abs(cpconvolve(magnitude_z, sobel_x))\n",
    "    magnitude_z = cp.sqrt(x_grad_z**2 + y_grad_z**2)\n",
    "\n",
    "\n",
    "    magnitude = cp.sqrt(magnitude_i * magnitude_z)\n",
    "    magnitude = magnitude_z\n",
    "\n",
    "    y_bottom = np.argmin(np.abs(y_values - window_height))\n",
    "    y_top = np.argmin(np.abs(y_values + window_height))\n",
    "\n",
    "    magnitude[:y_top, :] = 0\n",
    "    magnitude[y_bottom:, :] = 0\n",
    "    \n",
    "    return cp.asnumpy(magnitude)\n",
    "\n",
    "\n",
    "def mask_canny_2(data,y_window=9, x_window=2, s = 100, w = 25, s_e = 0.0175, w_e = 0.0065):\n",
    "    mask = PCA_eig2(data, y_window, x_window, s = s_e, w = w_e)[0]\n",
    "    NMS_magnitude = get_gradient_NMS(data)\n",
    "\n",
    "    y_values = data[7]\n",
    "    neighbours = [(-1, 0), (0, -1), (0, 1), (1, 0)]\n",
    "   \n",
    "    return_array = np.zeros_like(NMS_magnitude)\n",
    "\n",
    "    NMS_array_masked = NMS_magnitude * mask \n",
    "    \n",
    "    strong_y, strong_x = np.where(NMS_array_masked >= s)\n",
    "    weak_edges = (NMS_magnitude >= w) & (NMS_array_masked < s).astype(np.uint8) \n",
    "\n",
    "    queue = deque(zip(strong_y, strong_x))\n",
    "    while queue:\n",
    "        y, x = queue.popleft() \n",
    "        return_array[y, x] = 1\n",
    "        for dy, dx in neighbours:\n",
    "            ny, nx = y + dy, x + dx\n",
    "            if 0 <= ny < mask.shape[0] and 0 <= nx < mask.shape[1]:\n",
    "                if weak_edges[ny, nx]:\n",
    "                    weak_edges[ny, nx] = 0 \n",
    "                    queue.append((ny, nx)) \n",
    "\n",
    "    kernel = cv2.getStructuringElement(cv2.MORPH_ELLIPSE, (8,18))\n",
    "    y_top = np.argmin(np.abs(y_values - 10))\n",
    "    y_bottom = np.argmin(np.abs(y_values + 10))\n",
    "    y_seed_point = np.argmin(np.abs(y_values))\n",
    "    \n",
    "\n",
    "    closed = cv2.morphologyEx(return_array, cv2.MORPH_CLOSE, kernel)\n",
    "    closed[y_top, :] = 1\n",
    "    closed[y_bottom, :] = 1\n",
    "\n",
    "    return [np.where(closed ==  1, 1 , np.nan), y_seed_point]\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gradients = []\n",
    "\n",
    "for point_cloud in point_clouds:\n",
    "    gradients.append([get_gradient_NMS(point_cloud)])\n",
    "    gc.collect()\n",
    "    cp.get_default_memory_pool().free_all_blocks()\n",
    "    print(f\"done {point_cloud[0]}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(70, 3 * len(point_clouds)), dpi=75)  \n",
    "gs = fig.add_gridspec(len(point_clouds), 1, hspace=0.0025)  \n",
    "\n",
    "for (i, edge_array), (i2, point_cloud) in zip(enumerate(gradients), enumerate(point_clouds)):\n",
    "    \n",
    "        ax = fig.add_subplot(gs[i,0]) \n",
    "        ax.imshow(cp.flipud(edge_array[0]), cmap='nipy_spectral', interpolation='nearest', alpha = 1)\n",
    "        ax.set_xlabel(\"X index\")\n",
    "        ax.set_ylabel(\"Y index\")\n",
    "        ax.set_title(f\"Point Cloud: {point_cloud[0]}\", fontsize=40)\n",
    "\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eig_2 = []\n",
    "\n",
    "for point_cloud in point_clouds:\n",
    "    eig_2.append(PCA_eig2(point_cloud, y_window=9, x_window=2, s = 0.0175, w = 0.0065))\n",
    "    gc.collect()\n",
    "    cp.get_default_memory_pool().free_all_blocks()\n",
    "    print(f\"done {point_cloud[0]}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(70,6 * len(point_clouds)), dpi=75)  \n",
    "gs = fig.add_gridspec(len(point_clouds * 2), 1, hspace=0.125\n",
    "                      )  \n",
    "\n",
    "for (i, edge_array), (i2, point_cloud) in zip(enumerate(eig_2), enumerate(point_clouds)):\n",
    "    i = i*2\n",
    "    for j in range(2):\n",
    "        ax = fig.add_subplot(gs[i + j, 0])\n",
    "        ax.imshow(cp.flipud(edge_array[j]), cmap='nipy_spectral', interpolation='nearest', alpha = 1)\n",
    "        ax.set_xlabel(\"X index\")\n",
    "        ax.set_ylabel(\"Y index\")\n",
    "        ax.set_title(f\"Point Cloud: {point_cloud[0]}\", fontsize=40)\n",
    "\n",
    "   \n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "masked_canny = []\n",
    "\n",
    "for point_cloud in point_clouds:\n",
    "    masked_canny.append([mask_canny_2(point_cloud,s = 150, w = 75, y_window=9, x_window=2, s_e = 0.025, w_e = 0.0175)])\n",
    "    print(f\"done {point_cloud[0]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(70, 3 * len(point_clouds)), dpi=100)  \n",
    "gs = fig.add_gridspec(len(point_clouds), 1, hspace=0.025)  \n",
    "\n",
    "for (i, edge_array), (i2, point_cloud) in zip(enumerate(masked_canny), enumerate(point_clouds)):\n",
    "\n",
    "    ax = fig.add_subplot(gs[i, 0])\n",
    "\n",
    "    #ax.imshow(cp.flipud(point_cloud[1]), cmap='nipy_spectral', interpolation='nearest', alpha = 0.75) \n",
    "    ax.imshow(cp.flipud(edge_array[0][0]), cmap='nipy_spectral', interpolation='nearest', alpha = 1)\n",
    "\n",
    "    ax.set_xlabel(\"X index\")\n",
    "    ax.set_ylabel(\"Y index\")\n",
    "    ax.set_title(f\"Point Cloud: {point_cloud[0]}\", fontsize=40)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import open3d as o3d\n",
    "\n",
    "\n",
    "#point_cloud = [row for row in point_clouds if row[0] == '\\\\192.168.1.100\\CoreScan3-2\\Acquisitions\\RnD\\XRF 2.0\\same core scans\\AI21-TarcoreDoubleScans old xrf head\\AI21-XRF1.0\\Core_025_Box_001_of_003_Part_1_of_2'][0]\n",
    "point_cloud = point_clouds[1]\n",
    "x = (list)(point_cloud[5]) * len(point_cloud[7])\n",
    "y = np.repeat(point_cloud[7], len(point_cloud[5]))\n",
    "\n",
    "\n",
    "\n",
    "array_z = point_cloud[1]\n",
    "z = array_z.flatten()\n",
    "array_i = point_cloud[3]\n",
    "i = array_i.flatten()\n",
    "\n",
    "pcd = o3d.geometry.PointCloud()\n",
    "\n",
    "points = np.column_stack((x, y, -z))\n",
    "pcd.points = o3d.utility.Vector3dVector(points)\n",
    "\n",
    "o3d.visualization.draw_geometries([pcd])\n",
    "\n",
    "x = np.diff(np.unique(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fill_sections(edge_array):\n",
    "    edges1 = edge_array[0]\n",
    "    seed_index = edge_array[1]\n",
    "    edges = edges1.copy() \n",
    "\n",
    "    sections = []\n",
    "    neighbours = [(-1, 0), (0, -1), (0, 1), (1, 0)]  \n",
    "    \n",
    "    nan_mask = np.isnan(edges)  \n",
    "    int = 2\n",
    "\n",
    "    for x in range(edges.shape[1]):\n",
    "        section = []\n",
    "        \n",
    "        if nan_mask[seed_index, x]: \n",
    "            queue = deque([(seed_index, x)])\n",
    "\n",
    "            while queue:\n",
    "                y, x = queue.popleft()\n",
    "                section.append((y, x))\n",
    "                edges[y, x] = int \n",
    "                nan_mask[y, x] = False  \n",
    "                \n",
    "                neighbors_to_add = [\n",
    "                    (ny, nx) for dy, dx in neighbours\n",
    "                    if (0 <= (ny := y + dy) < edges.shape[0] and \n",
    "                        0 <= (nx := x + dx) < edges.shape[1] and \n",
    "                        nan_mask[ny, nx])  \n",
    "                ]\n",
    "\n",
    "                queue.extend(neighbors_to_add) \n",
    "                for ny, nx in neighbors_to_add:\n",
    "                    nan_mask[ny, nx] = False \n",
    "                    \n",
    "        sections.append(section)\n",
    "        int += 1\n",
    "\n",
    "    edges = np.where(edges > 1, edges, np.nan)\n",
    "    return [sections, edges]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "for point_cloud in point_clouds:\n",
    "    edges = mask_canny_2(point_cloud,s = 150, w = 75, y_window=9, x_window=2, s_e = 0.025, w_e = 0.0175)\n",
    "    sections = fill_sections(edges)\n",
    "    if len(point_cloud) > sectioned:\n",
    "    \n",
    "        point_cloud[sectioned] = sections\n",
    "    else:\n",
    "        point_cloud.append(sections)\n",
    "    print(f\"done {point_cloud[0]} .\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(70, 3*len(point_clouds)), dpi=100) \n",
    "gs = fig.add_gridspec(len(point_clouds), 1, hspace=0.025)  \n",
    "\n",
    "\n",
    "for i,sections in enumerate(point_clouds):\n",
    "   ax = fig.add_subplot(gs[i, 0])\n",
    "   ax.imshow(cp.flipud(sections[8][1]), cmap='nipy_spectral', interpolation='nearest', alpha = 0.75) \n",
    "   ax.set_xlabel(\"X index\")\n",
    "   ax.set_ylabel(\"Y index\")\n",
    "   ax.set_title(sections[0],fontsize = 20)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "new_env2",
   "language": "python",
   "name": "new_env2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
