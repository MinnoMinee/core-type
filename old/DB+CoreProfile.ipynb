{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "from scipy.stats import skew, kurtosis, mode\n",
    "from scipy.spatial import KDTree\n",
    "from sklearn.cluster import DBSCAN\n",
    "from ipywidgets import interact\n",
    "import matplotlib.patches as mpatches\n",
    "import plotly.graph_objects as go\n",
    "from scipy.ndimage import convolve\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_parts(directory_path, str = \"AdaptiveZ_10mm\"):\n",
    "    parts_paths = []\n",
    "\n",
    "    for root, dirs, files in os.walk(directory_path):\n",
    "        for folder in dirs:\n",
    "            folder = os.path.join(root,folder)\n",
    "            if (str in folder) and folder.endswith(\"_4\"):\n",
    "                parts_paths.append(folder)\n",
    "    parts_paths.sort(reverse=True)\n",
    "    return parts_paths\n",
    "\n",
    "\n",
    "base_path = r\"\\\\192.168.1.100\\CoreScan3-2\\Acquisitions\\RnD\\XRF\\CH\\Macassa_clearance\"\n",
    "\n",
    "paths = find_parts(base_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_point_cloud(file_path):\n",
    "    coords_file = os.path.join(file_path, '.component_parameters.txt')\n",
    "    with open(coords_file) as file:\n",
    "            lines = file.readlines()\n",
    "                \n",
    "            for line in lines:\n",
    "                if \"XRAY_DPP[Acquisition]#0.Y.Start:\" in line:\n",
    "                    y_offset = (float)(line.split(\"XRAY_DPP[Acquisition]#0.Y.Start:\")[1].strip())\n",
    "                elif \"XRAY_DPP[Acquisition]#0.X.Start:\" in line:\n",
    "                    x_start = (float)(line.split(\"XRAY_DPP[Acquisition]#0.X.Start:\")[1].strip())\n",
    "                elif \"XRAY_DPP[Acquisition]#0.X.Stop:\" in line:\n",
    "                    x_stop = (float)(line.split(\"XRAY_DPP[Acquisition]#0.X.Stop:\")[1].strip())\n",
    "\n",
    "\n",
    "    point_cloud = []\n",
    "\n",
    "    if os.path.isdir(file_path):\n",
    "        lidar_files = [fn for fn in os.listdir(\n",
    "            file_path) if fn.endswith('.bpc')]\n",
    "        if any(lidar_files):\n",
    "            lidar_filename = file_path + os.sep + lidar_files[0]\n",
    "\n",
    "    data = np.fromfile(lidar_filename, dtype=np.float32)\n",
    "    point_cloud = data.reshape(-1, 3)  # to xyz\n",
    "\n",
    "    ff = ~np.isnan(point_cloud).any(axis=1)\n",
    "    point_cloud = point_cloud[ff, ...]\n",
    "\n",
    "    #point_cloud[:, 1] = point_cloud[:, 1] - float(y_offset)\n",
    "\n",
    "    print(f\"{file_path} is loaded. \\n# of point {point_cloud.shape[0]}\")\n",
    "\n",
    "\n",
    "    matrix_file = (os.path.join(file_path, \".XRAY_DPP_001.lidar2xrf\"))\n",
    "    with open(matrix_file, 'r') as file:\n",
    "        lines = file.readlines()\n",
    "\n",
    "    transformation_matrix = np.array([list(map(float, line.strip().split(\",\"))) for line in lines])\n",
    "\n",
    "    num_points = point_cloud.shape[0]\n",
    "\n",
    "    homogeneous_points = np.hstack((point_cloud, np.ones((num_points, 1))))\n",
    "    transformed_points = homogeneous_points @ transformation_matrix.T\n",
    "    point_cloud = transformed_points[:, :3]\n",
    "\n",
    "\n",
    "    def trim_cloud(data):\n",
    "        data = data[data[:, 2] > 0]\n",
    "        data = data[\n",
    "            (data[:,0] >= x_stop) & \n",
    "            (data[:,0] <= x_start) \n",
    "            ]\n",
    "        return data\n",
    "    \n",
    "  \n",
    "    def trim_y(data, y_span=16):\n",
    "        data = data[(data[:,1] >= -y_span) & (data[:,1] <= y_span)]\n",
    "        return data\n",
    "    \n",
    "    \n",
    "    \n",
    "    point_cloud = trim_cloud(point_cloud)\n",
    "    point_cloud = trim_y(point_cloud)\n",
    "    return point_cloud, x_start, x_stop\n",
    "\n",
    "\n",
    "def join_y_values(data):\n",
    "        y_vals = np.sort(np.unique(data[:,1]))\n",
    "        print(len(y_vals))\n",
    "        unique_y = []\n",
    "        previous_value = y_vals[0]\n",
    "        unique_y.append(previous_value)\n",
    "        tolerance = 1e-1\n",
    "    \n",
    "        for value in y_vals[1:]:\n",
    "            if abs(value - previous_value) > tolerance:  \n",
    "                unique_y.append(value)  \n",
    "                previous_value = value\n",
    "        print(len(unique_y))\n",
    "        \n",
    "        data[:,1] = [unique_y[np.argmin(np.abs(unique_y - y))] for y in data[:,1]]\n",
    "        return data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "point_clouds = []\n",
    "\n",
    "x_offset = 0\n",
    "\n",
    "for path in paths:\n",
    "    temp_cloud, x_start, x_stop = get_point_cloud(path)\n",
    "    x_offset -= x_stop\n",
    "    temp_cloud[:,0] += x_offset\n",
    "    x_offset += x_start\n",
    "    point_clouds.append(temp_cloud)\n",
    "   \n",
    "point_cloud = np.vstack(point_clouds)\n",
    "x_points = np.unique(point_cloud[:,0])\n",
    "print(f\"total # of point {point_cloud.shape[0]}\")\n",
    "\n",
    "point_tree = KDTree(point_cloud[:,:2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def join_y_values(data):\n",
    "        y_vals = np.sort(np.unique(point_cloud[:,1]))\n",
    "        print(len(y_vals))\n",
    "        unique_y = []\n",
    "        previous_value = y_vals[0]\n",
    "        unique_y.append(previous_value)\n",
    "        tolerance = 1e-1\n",
    "    \n",
    "        for value in y_vals[1:]:\n",
    "            if abs(value - previous_value) > tolerance:  \n",
    "                unique_y.append(value)  \n",
    "                previous_value = value\n",
    "        print(len(unique_y))\n",
    "        \n",
    "        data[:,1] = [unique_y[np.argmin(np.abs(unique_y - y))] for y in data[:,1]]\n",
    "        return data\n",
    "\n",
    "\n",
    "point_cloud = join_y_values(point_cloud)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_vectors(data1, data2, x_vals, y_span=10):\n",
    "    vectors = {}\n",
    "    for x in x_vals:\n",
    "        distribution = get_distribution(data1,data2,[x, 0], y_span) \n",
    "        properties = get_props(distribution)\n",
    "        if not np.any(np.isnan(properties)):\n",
    "            vectors[x] = properties\n",
    "    return vectors\n",
    "\n",
    "def get_vectors2(data1, data2, x_vals, y_span=12):\n",
    "    vectors = {}\n",
    "    for x in x_vals:\n",
    "        profile = get_profile(data1,data2,[x, 0], y_span) \n",
    "        properties = get_profile_props(profile)\n",
    "        if not np.any(np.isnan(properties)):\n",
    "            vectors[x] = properties\n",
    "    return vectors\n",
    "\n",
    "def get_vectors3(data1, data2, data3, x_vals, y_span=12):\n",
    "    vectors = {}\n",
    "    for x in x_vals:\n",
    "        profile = get_profile(data1,data3,[x, 0], y_span) \n",
    "        properties = (get_profile_props(profile))\n",
    "        distribution = get_distribution(data2,data3,[x, 0], y_span) \n",
    "        properties = np.hstack((properties, get_props(distribution)))\n",
    "        if not np.any(np.isnan(properties)):\n",
    "            vectors[x] = properties\n",
    "    return vectors\n",
    "\n",
    "\n",
    "def get_distribution(data1, data2, point=(0, 0), y_span=12):\n",
    "    search_radius = y_span\n",
    "\n",
    "    indices = data2.query_ball_point(point, search_radius)\n",
    "\n",
    "    result_points = data1[indices]\n",
    "\n",
    "    filtered_points = result_points[\n",
    "        (result_points[:, 0] == point[0]) &\n",
    "        (result_points[:, 1] >= point[1] - y_span) & (result_points[:, 1] <= point[1] + y_span)\n",
    "    ]\n",
    "\n",
    "    return filtered_points[:, 2]\n",
    "\n",
    "\n",
    "def get_profile(data1, data2, point=(0, 0), y_span=12):\n",
    "    search_radius = y_span\n",
    "\n",
    "    indices = data2.query_ball_point(point, search_radius)\n",
    "\n",
    "    result_points = data1[indices]\n",
    "\n",
    "    filtered_points = result_points[\n",
    "        (result_points[:, 0] == point[0]) &\n",
    "        (result_points[:, 1] >= point[1] - y_span) & (result_points[:, 1] <= point[1] + y_span)\n",
    "    ]\n",
    "\n",
    "    y_vals = {}\n",
    "\n",
    "    for y in range(len(filtered_points[:,1])):\n",
    "        if filtered_points[y,1] not in y_vals:\n",
    "            y_vals[filtered_points[y,1]] = []\n",
    "        y_vals[filtered_points[y,1]].append(filtered_points[y,2])\n",
    "    \n",
    "\n",
    "    return y_vals\n",
    "\n",
    "\n",
    "def get_props(distribution):\n",
    "    properties = []\n",
    "\n",
    "    mean = np.mean(distribution)\n",
    "    variance =  np.var(distribution)\n",
    "    skw = skew(distribution)\n",
    "    kurt = kurtosis(distribution)\n",
    "\n",
    "    \n",
    "    properties.append(variance)\n",
    "    properties.append(skw)\n",
    "    properties.append(kurt)\n",
    "\n",
    "    norm = np.sum(x**2 for x in properties)**0.5\n",
    "    \n",
    "    properties = [x / norm for x in properties]\n",
    "\n",
    "    \n",
    "    properties.append(mean)\n",
    "\n",
    "    z = properties[0]\n",
    "    y = properties[1]\n",
    "    x = properties[2]\n",
    "\n",
    "    roe = np.sqrt(x**2 + y**2 + z**2)\n",
    "    properties.append((np.atan2(y,x) + (2 * np.pi)) % (2 * np.pi))\n",
    "    properties.append(np.acos(z/roe)/(np.pi/2))\n",
    "    #properties.append((np.atan2(np.log(z + 1),y)))\n",
    "\n",
    "    \n",
    "    return properties\n",
    "\n",
    "\n",
    "def get_profile_props(profile):\n",
    "    if profile:\n",
    "        y = np.array(sorted(profile.keys()))\n",
    "        z = np.array([profile[y_val] for y_val in y]).flatten()\n",
    "\n",
    "        dy = np.gradient(y)\n",
    "        dz = np.gradient(z)\n",
    "        d2y = np.gradient(dy)\n",
    "        d2z = np.gradient(dz)\n",
    "\n",
    "        curvature = np.abs(dy * d2z - dz * d2y) / (dy**2 + dz**2)**(3/2)\n",
    "\n",
    "        vec = []\n",
    "        #vec.append(np.mean(curvature))\n",
    "        #vec.append(np.log(np.max(np.abs(curvature))))\n",
    "        vec.append(np.var(curvature))\n",
    "\n",
    "\n",
    "        vec.append((float)(kurtosis(curvature)))\n",
    "\n",
    "        vec = np.array(vec)\n",
    "        mag = np.sqrt(np.sum(vec**2))\n",
    "        \n",
    "        if mag > 0:\n",
    "            vec = vec/mag  \n",
    "\n",
    "        return list(vec)\n",
    "    else:\n",
    "        return []\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 0 = variance, 1 = skew, 2 = kurtosis, 3 = mean, 4 = azumithol, 5 = polar\n",
    "properties = [1,5] \n",
    "#cluster size, sample size, metric, epsilon, alpha, max eps\n",
    "parameters = [50, 'chebyshev', 0.054]\n",
    "\n",
    "fig = plt.figure(figsize=(100,3))\n",
    "\n",
    "downsampled_indices = np.random.choice(point_cloud.shape[0], size=150000, replace=False)\n",
    "\n",
    "x_downsampled = point_cloud[downsampled_indices, 0]\n",
    "y_downsampled = point_cloud[downsampled_indices, 1]\n",
    "z_downsampled = point_cloud[downsampled_indices, 2]\n",
    "\n",
    "gs = fig.add_gridspec(2, 2, hspace = 0.8, wspace = 0.3, width_ratios = [8,1] )\n",
    "\n",
    "ax_scatter = fig.add_subplot(gs[0,0])\n",
    "ax_scatter.scatter(\n",
    "x_downsampled,\n",
    "y_downsampled,\n",
    "c=z_downsampled,\n",
    "cmap='binary_r',  \n",
    "s = 0.25\n",
    ")\n",
    "\n",
    "ax_scatter.set_title('LIDAR data heatmap')\n",
    "ax_scatter.set_xlabel('X-axis')\n",
    "ax_scatter.set_ylabel('Y-axis')\n",
    "\n",
    "v_dict = get_vectors(point_cloud,point_tree,x_points, y_span = 10)\n",
    "v_array = np.array(list(v_dict.values()))\n",
    "x_values = list(v_dict.keys())\n",
    "\n",
    "dbscan = DBSCAN(min_samples = parameters[0], \n",
    "                metric = parameters[1], \n",
    "                eps = parameters[2],\n",
    "                n_jobs = -1)\n",
    "\n",
    "labels = dbscan.fit_predict(v_array[:, properties])\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "defined_indices = np.where(np.logical_or(labels == 0, labels == 2))[0]\n",
    "\n",
    "core_type_dictionary = {x: labels[i] for i,x in enumerate(v_dict.keys())}\n",
    "\n",
    "\n",
    "semi_defined_indices = np.where(labels == 1)[0]\n",
    "\n",
    "core_points = [v_dict[x] for i, x in enumerate(v_dict.keys()) if i in defined_indices and i in dbscan.core_sample_indices_]\n",
    "core_points = np.array(core_points)[:, [1, 5]]\n",
    "core_points_labels = labels[[i for i in defined_indices if i in dbscan.core_sample_indices_]]\n",
    "\n",
    "colors = list(f\"C{label + 1}\" if (label == 0 or label == 2) else (0,0,0,0) for label in labels)\n",
    "\n",
    "bar_plot = fig.add_subplot(gs[1,0])\n",
    "\n",
    "bar_plot.bar(x_values, height=1,width = 2, color=colors, edgecolor=\"none\")\n",
    "\n",
    "bar_plot.set_title(\"Core Type by X-position\")\n",
    "bar_plot.set_xlabel(\"X-Value\")\n",
    "bar_plot.legend(title=\"Core Type\", bbox_to_anchor=(1,2), loc=\"upper left\")\n",
    "bar_plot.set_yticks([])\n",
    "\n",
    "ax = fig.add_subplot(gs[1,1])\n",
    "\n",
    "\n",
    "\n",
    "x_vals = [v_dict[x][1] for x in v_dict.keys()]\n",
    "y_vals = [v_dict[x][5] for x in v_dict.keys()]\n",
    "\n",
    "ax.scatter(x_vals, y_vals, color=colors, s=1)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convolved_data(data,kernels):\n",
    "    x_values = np.unique(data[:,0])\n",
    "    y_values = np.unique(data[:,1])\n",
    "    array = np.zeros((len(y_values), len(x_values)))\n",
    "    map = {(row[0],row[1]): (index, row[2]) for index,row in enumerate(data)}\n",
    "\n",
    "    for x in range (len(x_values)):\n",
    "        for y in range (len(y_values)):\n",
    "            x_val = x_values[x]\n",
    "            y_val = y_values[y]\n",
    "            z = map.get((x_val,y_val))\n",
    "            if z is not None:\n",
    "                array[y][x] = z[1]\n",
    "\n",
    "    result_array = np.zeros((len(y_values), len(x_values)))\n",
    "    \n",
    "    for kernel in kernels:\n",
    "        result_array += np.abs(convolve(array,kernel))\n",
    "\n",
    "    return_data = data.copy()\n",
    "\n",
    "    for x in range (len(x_values)):\n",
    "        for y in range (len(y_values)):\n",
    "            x_val = x_values[x]\n",
    "            y_val = y_values[y]\n",
    "            index = map.get((x_val,y_val))\n",
    "            if index is not None:\n",
    "                return_data[index[0],2] = result_array[y][x]\n",
    "    return return_data\n",
    "\n",
    "def canny(data):\n",
    "    sobel_x = np.array([\n",
    "        [-1, 0, 1],\n",
    "        [-2, 0, 2],\n",
    "        [-1, 0, 1]\n",
    "    ])\n",
    "    sobel_y = np.array([\n",
    "        [ 1, 2, 1],\n",
    "        [ 0, 0, 0],\n",
    "        [-1,-2,-1]\n",
    "    ])\n",
    "    angs = np.array([0, np.pi/4, np.pi/2, 3*np.pi/4])\n",
    "\n",
    "    x_values = np.unique(data[:,0])\n",
    "    y_values = np.unique(data[:,1])\n",
    "    array = np.zeros((len(y_values), len(x_values)))\n",
    "    map = {(row[0],row[1]): (index, row[2]) for index,row in enumerate(data)}\n",
    "\n",
    "    for x in range (len(x_values)):\n",
    "        for y in range (len(y_values)):\n",
    "            x_val = x_values[x]\n",
    "            y_val = y_values[y]\n",
    "            z = map.get((x_val,y_val))\n",
    "            if z is not None:\n",
    "                array[y][x] = z[1]\n",
    "\n",
    "    y_grad = np.zeros((len(y_values), len(x_values)))\n",
    "    x_grad = np.zeros((len(y_values), len(x_values)))\n",
    "    NMS_array = np.zeros(array.shape, dtype=object)\n",
    "\n",
    "    \n",
    "    y_grad = convolve(array,sobel_y)\n",
    "    x_grad = convolve(array,sobel_x)\n",
    "\n",
    "\n",
    "    for x in range (len(x_values)):\n",
    "        for y in range (len(y_values)):\n",
    "            Gx = x_grad[y][x]\n",
    "            Gy = y_grad[y][x]\n",
    "\n",
    "            Gtheta  = np.atan2(Gy,Gx) % np.pi\n",
    "            \n",
    "            theta = np.argmin(np.abs(Gtheta - angs))\n",
    "\n",
    "            NMS_array[y][x] = tuple((np.sqrt(Gx**2 + Gy**2),theta))\n",
    "\n",
    "    return_data = data.copy()\n",
    "    \n",
    "    for x in range (1,len(x_values) - 1):\n",
    "        for y in range (1,len(y_values) - 1):\n",
    "            index = map.get((x_values[x],y_values[y]))\n",
    "            if index is not None:\n",
    "                i = index[0]\n",
    "                mag = (NMS_array[y][x])[0]\n",
    "                ang = (NMS_array[y][x])[1]\n",
    "                \n",
    "                if (ang == 0):\n",
    "                    n1 = (NMS_array[y][x + 1])[0]\n",
    "                    n2 = (NMS_array[y][x - 1])[0]\n",
    "                if (ang == 1):\n",
    "                    n1 = (NMS_array[y - 1][x - 1])[0]\n",
    "                    n2 = (NMS_array[y + 1][x + 1])[0]\n",
    "                if (ang == 2):\n",
    "                    n1 = (NMS_array[y + 1][x])[0]\n",
    "                    n2 = (NMS_array[y - 1][x])[0]\n",
    "                if (ang == 3):\n",
    "                    n1 = (NMS_array[y - 1][x + 1])[0]\n",
    "                    n2 = (NMS_array[y + 1][x - 1])[0]\n",
    "                if mag >= n1 and mag >= n2:\n",
    "                    return_data[i,2] = mag\n",
    "                else:\n",
    "                    return_data[i,2] = 0\n",
    "\n",
    "\n",
    "    return_data[:, 2] = np.where(return_data[:, 2] <= 50, return_data[:, 2], 50)\n",
    "    \n",
    "    return return_data \n",
    "\n",
    "\n",
    "kernels = []\n",
    "\n",
    "smooth_kernels = []\n",
    "\n",
    "#kernels.append(np.array([[1],[0],[0],[0],\n",
    "#                         [-4],[0],[0],[0],\n",
    "#                         [6],[0],[0],[0],\n",
    "#                         [-4],[0],[0],[0],\n",
    "#                         [1]]))\n",
    "\n",
    "\n",
    "kernels.append(np.array([[-1],[-2],[0],[2],[1]]))\n",
    "smooth_kernels.append(np.array([\n",
    "    [1,2,1],\n",
    "    [2,4,2],\n",
    "    [1,2,1]\n",
    "]))\n",
    "\n",
    "\n",
    "#kernels.append(np.array([[1,-4,6,-4,1]]))\n",
    "#\n",
    "#smooth_kernels.append(np.array([[1,1,1,1,1]]))\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#point_cloud_convolved = convolved_data(point_cloud,smooth_kernels)\n",
    "\n",
    "point_cloud_convolved = canny(convolved_data(point_cloud,smooth_kernels))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "downsampled_indices = np.random.choice(point_cloud.shape[0], size=1000000, replace=False)\n",
    "x_downsampled = point_cloud[downsampled_indices, 0]\n",
    "y_downsampled = point_cloud[downsampled_indices, 1]\n",
    "z_downsampled = point_cloud[downsampled_indices, 2]\n",
    "\n",
    "x_downsampled2 = point_cloud_convolved[:, 0]\n",
    "y_downsampled2 = point_cloud_convolved[:, 1]\n",
    "z_downsampled2 = point_cloud_convolved[:, 2]\n",
    "\n",
    "\n",
    "fig, axs = plt.subplots(2, 2, figsize=(150, 6), gridspec_kw={'width_ratios': [1, 0.05]}, dpi = 300)\n",
    "\n",
    "sc1 = axs[0, 0].scatter(\n",
    "    x_downsampled, y_downsampled, c=z_downsampled, cmap='viridis', s=0.3\n",
    ")\n",
    "axs[0, 0].set_title('LIDAR data heatmap')\n",
    "axs[0, 0].set_xlabel('X-axis')\n",
    "axs[0, 0].set_ylabel('Y-axis')\n",
    "\n",
    "cbar1 = fig.colorbar(sc1, cax=axs[0, 1])\n",
    "cbar1.set_label('Z Value')\n",
    "\n",
    "axs[0, 0].set_xticks(list(range(0, 31001, 1000)))  \n",
    "\n",
    "axs[0, 0].set_xticklabels(list(range(0, 31001, 1000)), rotation=70)\n",
    "\n",
    "sc2 = axs[1, 0].scatter(\n",
    "    x_downsampled2, y_downsampled2, c=z_downsampled2, cmap='viridis_r', s=0.3\n",
    ")\n",
    "axs[1, 0].set_title('LIDAR data heatmap, convolved')\n",
    "axs[1, 0].set_xlabel('X-axis')\n",
    "axs[1, 0].set_ylabel('Y-axis')\n",
    "\n",
    "cbar2 = fig.colorbar(sc2, cax=axs[1, 1])\n",
    "cbar2.set_label('Z Value')\n",
    "axs[1, 0].set_xticks(list(range(0, 31001, 1000)))\n",
    "\n",
    "axs[1, 0].set_xticklabels(list(range(0, 31001, 1000)), rotation=70)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_values = [x for i, x in enumerate(v_dict.keys()) if i not in defined_indices]\n",
    "indices = [i for i, x in enumerate(v_dict.keys()) if i not in defined_indices]\n",
    "\n",
    "profiles = {x: get_profile(point_cloud, point_tree, (x, 0)) for x in x_values}\n",
    "\n",
    "\n",
    "\n",
    "def view_profile(x_position=1000):\n",
    "   \n",
    "    fig = plt.figure(figsize=(19, 3))\n",
    "    plt.ion()\n",
    "    gs = fig.add_gridspec(2, 1, hspace=0.8, wspace=0.3)\n",
    "    ax = fig.add_subplot(gs[0, 0])\n",
    "\n",
    "    ax.bar(x_values, height=1, width=1, color=\"black\")\n",
    "    x_value = x_values[np.argmin(np.abs(np.array(x_values) - x_position))]\n",
    "    ax.axvline(x=x_value, color=\"r\")\n",
    "    prof = fig.add_subplot(gs[1, 0])\n",
    "    profile = profiles[x_value]\n",
    "    y_values = list(profile.keys())\n",
    "    z_values = list(profile.values())\n",
    "    prof.scatter(y_values, z_values, s=1)\n",
    "    print(get_profile_props(profile))\n",
    "    plt.show()\n",
    "\n",
    "interact(view_profile, x_position=(0, (np.max(x_values))))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_values = [x for i, x in enumerate(v_dict.keys()) if i not in defined_indices]\n",
    "indices = [i for i, x in enumerate(v_dict.keys()) if i not in defined_indices]\n",
    "\n",
    "profiles2 = {x: get_profile(point_cloud_convolved, point_tree, (x, 0)) for x in x_values}\n",
    "\n",
    "def view_profile(x_position=1000):\n",
    "    fig = plt.figure(figsize=(19, 3))\n",
    "    gs = fig.add_gridspec(2, 1, hspace=0.8, wspace=0.3)\n",
    "    ax = fig.add_subplot(gs[0, 0])\n",
    "\n",
    "    ax.bar(x_values, height=1, width=1, color=\"black\")\n",
    "    x_value = x_values[np.argmin(np.abs(np.array(x_values) - x_position))]\n",
    "    ax.axvline(x=x_value, color=\"r\")\n",
    "    prof = fig.add_subplot(gs[1, 0])\n",
    "    profile = profiles2[x_value]\n",
    "    y_values = list(profile.keys())\n",
    "    z_values = list(profile.values())\n",
    "    prof.scatter(y_values, z_values, s=1)\n",
    "    print(get_profile_props(profile))\n",
    "    plt.show()\n",
    "\n",
    "interact(view_profile, x_position=(0, (np.max(x_values))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_values = [x for i, x in enumerate(v_dict.keys()) if i not in defined_indices]\n",
    "\n",
    "#x_values = np.unique(point_cloud[:,0])\n",
    "\n",
    "#v_dict2 = get_vectors2(point_cloud,point_tree,x_values)\n",
    "\n",
    "v_dict2 = get_vectors(point_cloud_convolved,point_tree,x_values)\n",
    "\n",
    "\n",
    "\n",
    "#\n",
    "dimensions = [1,2,3,4,5]\n",
    "\n",
    "hdbscan_refined = DBSCAN(min_samples = 25,\n",
    "                             metric = \"chebyshev\",\n",
    "                             eps= 1.3,\n",
    "                             n_jobs=-1)\n",
    "\n",
    "labels = hdbscan_refined.fit_predict(np.array(list(v_dict2.values()))[:,dimensions])\n",
    "\n",
    "core_type_dictionary.update({x: labels[i] + 4 for i,x in enumerate(v_dict2.keys())})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(60,3))\n",
    "\n",
    "gs = fig.add_gridspec(2, 1 )\n",
    "\n",
    "\n",
    "colors = [f\"C{label}\"  if label >= 0 else (0,0,0,0)  for label in labels]\n",
    "\n",
    "bar_plot = fig.add_subplot(gs[1,0])\n",
    "\n",
    "ax = fig.add_subplot(gs[0,0])\n",
    "\n",
    "x_vals = [x for x in v_dict2.keys()]\n",
    "y_vals = [v_dict2[x][0] for x in v_dict2.keys()]\n",
    "\n",
    "ax.scatter(x_vals, y_vals,color = colors, s=1)\n",
    "\n",
    "\n",
    "ax.set_xticks(list(range(0, 33001, 1000)))  \n",
    "\n",
    "ax.set_xticklabels(list(range(0, 33001, 1000)), rotation=70)\n",
    "\n",
    "legend_labels = np.unique(labels)\n",
    "legend_colors = [f\"C{label}\"  if label >= 0 else (0,0,0,0) for label in legend_labels]\n",
    "legend_handles = [mpatches.Patch(color=color, label=label) for label, color in zip(legend_labels, legend_colors)]\n",
    "\n",
    "bar_plot.bar(x_values, height=1.5, width=2, color=colors, edgecolor=\"none\")\n",
    "\n",
    "bar_plot.legend(handles=legend_handles, title=\"Core Type\", bbox_to_anchor=(1,1), loc=\"upper left\")\n",
    "\n",
    "bar_plot.set_title(\"Core Type by X-position\")\n",
    "bar_plot.set_xlabel(\"X-Value\")\n",
    "bar_plot.set_yticks([])\n",
    "bar_plot.set_xticks(list(range(0, 31001, 1000)))  \n",
    "\n",
    "bar_plot.set_xticklabels(list(range(0, 31001, 1000)), rotation=70)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(150,3), dpi = 500)\n",
    "\n",
    "core_types = list(core_type_dictionary.values())\n",
    "x_positions = list(core_type_dictionary.keys())\n",
    "\n",
    "colors2 = [f\"C{type}\" if type >= 0  else (0,0,0,0) for type in core_types]\n",
    "\n",
    "ax = fig.add_subplot(111)\n",
    "\n",
    "\n",
    "ax.bar(x_positions, height=32, width= 1, color=colors2, edgecolor=\"none\", bottom = -16)\n",
    "ax.scatter( point_cloud[:, 0], point_cloud[:, 1], c=point_cloud[:, 2], cmap='binary', s=0.08, alpha = 0.4)\n",
    "\n",
    "\n",
    "legend_labels2 = np.unique(core_types)\n",
    "legend_colors2 = [f\"C{label}\" if label >= 0 else (0,0,0,0)  for label in legend_labels2 ]\n",
    "legend_handles2 = [mpatches.Patch(color=color, label=label) for label, color in zip(legend_labels2, legend_colors2)]\n",
    "\n",
    "ax.set_xticks(list(range(0, 31001, 500)))\n",
    "ax.set_xticklabels(list(range(0, 31001, 500)), rotation=70)\n",
    "ax.legend(handles=legend_handles2, title=\"Core Type\", bbox_to_anchor=(1,1), loc=\"upper left\")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectors = np.array(list(v_dict2.values()))\n",
    "x = vectors[:,5]\n",
    "y = vectors[:,2]\n",
    "z = vectors[:,4]\n",
    "\n",
    "\n",
    "fig = go.Figure(data=[go.Scatter3d(\n",
    "    x=x, y=y, z=z,\n",
    "    mode='markers',\n",
    "    marker=dict(size=1.3, color=labels, opacity=1),\n",
    ")])\n",
    "\n",
    "fig.update_layout(\n",
    "    title=\"3D Scatter of Vectors by Core Type\",\n",
    "    scene=dict(\n",
    "        xaxis_title=\"0\",\n",
    "        yaxis_title=\"1\",\n",
    "        zaxis_title=\"2\",\n",
    "        camera=dict(projection=dict(type=\"orthographic\"))\n",
    "    ),\n",
    "    width=1000,\n",
    "    height=1000\n",
    ")\n",
    "\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "paths2 = find_parts(base_path, \"Box1\\AdaptiveZ_10mm\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "point_clouds = []\n",
    "\n",
    "x_offset = 0\n",
    "\n",
    "for path in paths2:\n",
    "    temp_cloud, x_start, x_stop = get_point_cloud(path)\n",
    "    x_offset -= x_stop\n",
    "    temp_cloud[:,0] += x_offset\n",
    "    x_offset += x_start\n",
    "    point_clouds.append(temp_cloud)\n",
    "   \n",
    "point_cloud2 = np.vstack(point_clouds)\n",
    "x_values = np.unique(point_cloud2[:,0])\n",
    "\n",
    "print(f\"total # of point {point_cloud.shape[0]}\")\n",
    "\n",
    "point_tree2 = KDTree(point_cloud2[:,:2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "c_points = core_points\n",
    "c_type = core_points_labels\n",
    "\n",
    "type_dict = {i: c_type[i] for i in range(len(c_points))}\n",
    "\n",
    "tree2 = KDTree(c_points)\n",
    "\n",
    "v_dict = get_vectors(point_cloud2,point_tree2,x_values)\n",
    "\n",
    "indices = [tree2.query([v[1], v[5]], k=1, distance_upper_bound=0.1)[1] for v in v_dict.values()]\n",
    "\n",
    "labels = np.array([type_dict[index] if index != len(c_points) else -1 for index in indices])\n",
    "\n",
    "prediction = {x: label for x, label in zip(v_dict.keys(), labels)}\n",
    "\n",
    "x_vals = [v_dict[x][1] for x in v_dict.keys()]\n",
    "y_vals = [v_dict[x][5] for x in v_dict.keys()]\n",
    "colors = [f\"C{prediction[x] + 2}\" if prediction[x] >= 0 else \"black\" for x in v_dict.keys()]\n",
    "\n",
    "\n",
    "\n",
    "fig = plt.figure(figsize=(19,3))\n",
    "\n",
    "downsampled_indices = np.random.choice(point_cloud2.shape[0], size=50000, replace=False)\n",
    "\n",
    "x_downsampled = point_cloud2[downsampled_indices, 0]\n",
    "y_downsampled = point_cloud2[downsampled_indices, 1]\n",
    "z_downsampled = point_cloud2[downsampled_indices, 2]\n",
    "\n",
    "\n",
    "gs = fig.add_gridspec(2, 2, hspace = 0.5, wspace = 0.2, width_ratios = [9,1] )\n",
    "\n",
    "ax_scatter = fig.add_subplot(gs[0,0])\n",
    "ax_scatter.scatter(\n",
    "    x_downsampled,\n",
    "    y_downsampled,\n",
    "    c=z_downsampled,\n",
    "    cmap='viridis',\n",
    "    s = 1\n",
    ")\n",
    "\n",
    "ax_scatter.set_title('LIDAR data heatmap')\n",
    "ax_scatter.set_xlabel('X-axis')\n",
    "ax_scatter.set_ylabel('Y-axis')\n",
    "  \n",
    "bar_plot = fig.add_subplot(gs[1,0])\n",
    "\n",
    "bar_plot.bar(v_dict.keys(), height=1, width=1, color=colors, edgecolor=\"none\")\n",
    "\n",
    "bar_plot.set_title(\"Core Type by X-position\")\n",
    "bar_plot.set_xlabel(\"X-Value\")\n",
    "bar_plot.set_yticks([])\n",
    "\n",
    "ax = fig.add_subplot(gs[:,1])\n",
    "\n",
    "ax.scatter(x_vals, y_vals, color=colors, s=1)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
