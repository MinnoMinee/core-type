{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import gc\n",
    "import matplotlib.pyplot    as plt\n",
    "import numpy                as np\n",
    "import matplotlib.patches   as mpatches\n",
    "import plotly.graph_objects as go\n",
    "import networkx             as nx\n",
    "from scipy.stats       import skew, kurtosis, mode\n",
    "from sklearn.cluster   import DBSCAN\n",
    "from scipy.ndimage     import convolve, generic_filter\n",
    "from scipy.signal import convolve2d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FileParser:\n",
    "    def __init__(self, root_dir):\n",
    "        self.root_dir = root_dir\n",
    "        self.box_folders = []\n",
    "\n",
    "    def find_folders(self):\n",
    "        for root, dirs, files in os.walk(self.root_dir):\n",
    "                for dir_name in dirs:\n",
    "                    if dir_name.startswith(\"Box\"):\n",
    "                        adaptive_z_folder = os.path.join(root, dir_name, \"AdaptiveZ_10mm\")\n",
    "\n",
    "                        if os.path.isdir(adaptive_z_folder): \n",
    "                            for part_folder in os.listdir(adaptive_z_folder):\n",
    "                                full_part_path = os.path.join(adaptive_z_folder, part_folder)\n",
    "                                if os.path.isdir(full_part_path) and \"Part\" in part_folder:\n",
    "                                    component_parameters_path = None\n",
    "                                    lidar2xrf_path = None\n",
    "                                    bpc_path = None\n",
    "                                    for file_name in os.listdir(full_part_path):\n",
    "                                        if file_name.endswith(\".component_parameters.txt\"):\n",
    "                                            component_parameters_path = os.path.join(full_part_path, file_name)\n",
    "                                        elif file_name.endswith(\".lidar2xrf\"):\n",
    "                                            lidar2xrf_path = os.path.join(full_part_path, file_name)\n",
    "                                        elif file_name.endswith(\".bpc\"):\n",
    "                                            bpc_path = os.path.join(full_part_path, file_name)\n",
    "                                        elif file_name.endswith(\"_intensity.png\"):\n",
    "                                            intensity_path = os.path.join(full_part_path, file_name)\n",
    "\n",
    "                                    self.box_folders.append((part_folder,component_parameters_path, lidar2xrf_path, bpc_path, intensity_path))\n",
    "\n",
    "    def get_box_folders(self):\n",
    "        self.find_folders()\n",
    "        return self.box_folders\n",
    "\n",
    "\n",
    "parser = FileParser(r\"\\\\192.168.1.100\\CoreScan3-2\\Acquisitions\\RnD\\XRF\\CH\\Macassa_clearance\")\n",
    "paths_list = parser.get_box_folders()\n",
    "\n",
    "for name, component_parameters_path, lidar2xrf_path, bpc_path, intensity_path in paths_list:\n",
    "    print(f\"Part: {name}\")\n",
    "    if component_parameters_path:\n",
    "        print(f\"  Component Parameters: {component_parameters_path}\")\n",
    "    if lidar2xrf_path:\n",
    "        print(f\"  LIDAR to XRF: {lidar2xrf_path}\")\n",
    "    if bpc_path:\n",
    "        print(f\"  BPC File: {bpc_path}\")\n",
    "    if intensity_path:\n",
    "        print(f\"  Intensity File: {intensity_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_vectors(data, y_span=10):\n",
    "    vectors = {}\n",
    "    \n",
    "    for point_cloud in data:\n",
    "        \n",
    "        name = point_cloud[0]\n",
    "        cloud = point_cloud[1]\n",
    "        \n",
    "        i_to_x = point_cloud[3]\n",
    "        y_to_i = point_cloud[4]\n",
    "        \n",
    "        y_indices = [y_to_i[value] for value in y_to_i.keys() if abs(value) <= y_span]\n",
    "\n",
    "        for i in range(len(cloud[0])):\n",
    "            x = i_to_x[i]\n",
    "            distribution = []\n",
    "            for j in y_indices:\n",
    "                distribution.append(cloud[j][i])\n",
    "            properties = get_props(distribution)\n",
    "            if not (np.any(np.isnan(properties))):\n",
    "                vectors[(name, x)] = properties\n",
    "\n",
    "    return vectors\n",
    "\n",
    "def get_vectors_combined(data1, data2, x_values_dict, y_span=10):\n",
    "    vectors = {}   \n",
    "\n",
    "    for point_cloud,convolved_cloud in zip(data1,data2):\n",
    "        \n",
    "        name = point_cloud[0]\n",
    "        x_values = x_values_dict[name]\n",
    "        cloud = point_cloud[1]\n",
    "        convolved_cloud = convolved_cloud[1]\n",
    "        \n",
    "        x_to_i = point_cloud[2]\n",
    "        y_to_i = point_cloud[4]\n",
    "        \n",
    "        y_indices = [y_to_i[value] for value in y_to_i.keys() if abs(value) <= y_span]\n",
    "\n",
    "        for x in x_values:\n",
    "            i = x_to_i[x]\n",
    "            distribution = []\n",
    "            convolved_distribution = []\n",
    "            for j in y_indices:\n",
    "                distribution.append(cloud[j][i])\n",
    "                convolved_distribution.append(convolved_cloud[j][i])\n",
    "            properties = get_props(distribution)\n",
    "            convolved_properties = get_props_convolved(convolved_distribution)\n",
    "            vector = convolved_properties + properties\n",
    "            if not (np.any(np.isnan(vector))):\n",
    "                vectors[(name, x)] = vector\n",
    "\n",
    "    return vectors\n",
    "\n",
    "def get_props_convolved(distribution):\n",
    "    properties = []\n",
    "\n",
    "    mean = np.sqrt(np.mean(distribution))\n",
    "    max = np.sqrt(np.max(distribution))\n",
    "\n",
    "    variance =  np.var(distribution)\n",
    "    skw = skew(distribution)\n",
    "    kurt = kurtosis(distribution)\n",
    "\n",
    "    \n",
    "    properties.append(variance)\n",
    "    properties.append(skw)\n",
    "    properties.append(kurt)\n",
    "    \n",
    "\n",
    "    norm = np.linalg.norm(properties)\n",
    "    \n",
    "    if norm > 0:\n",
    "        properties = [x / norm for x in properties]\n",
    "    \n",
    "\n",
    "    properties.append(mean)\n",
    "    properties.append(max)\n",
    "\n",
    "    z = properties[0]\n",
    "    y = properties[1]\n",
    "    x = properties[2]\n",
    "\n",
    "    properties.append((np.arctan2(y,x) + (2 * np.pi)) % (2 * np.pi))\n",
    "    properties.append(np.arctan(z)/(np.pi/2))\n",
    "\n",
    "\n",
    "    return properties\n",
    "\n",
    "def get_props(distribution):\n",
    "    properties = []\n",
    "\n",
    "    variance =  np.var(distribution)\n",
    "    skw = skew(distribution)\n",
    "    kurt = kurtosis(distribution)\n",
    "\n",
    "    \n",
    "    properties.append(variance)\n",
    "    properties.append(skw)\n",
    "    properties.append(kurt)\n",
    "\n",
    "    norm = np.linalg.norm(properties)\n",
    "    \n",
    "    if norm > 0:\n",
    "        properties = [x / norm for x in properties]\n",
    "\n",
    "    z = properties[0]\n",
    "\n",
    "    properties.append(np.arccos(z)/(np.pi/2))\n",
    "\n",
    "    return properties\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_point_cloud(paths, y_window = 25, upsample_ratio = 4):\n",
    "\n",
    "    with open(paths[1]) as file:\n",
    "            lines = file.readlines()\n",
    "            for line in lines:\n",
    "                if \"XRAY_DPP[Acquisition]#0.X.Start:\" in line:\n",
    "                    x_start = (float)(line.split(\"XRAY_DPP[Acquisition]#0.X.Start:\")[1].strip())\n",
    "                if \"XRAY_DPP[Acquisition]#0.X.Stop:\" in line:\n",
    "                    x_stop = (float)(line.split(\"XRAY_DPP[Acquisition]#0.X.Stop:\")[1].strip())\n",
    "\n",
    "    with open(paths[2]) as file:\n",
    "        lines = file.readlines()\n",
    "        transformation_matrix = np.array([list(map(float, line.strip().split(\",\"))) for line in lines])\n",
    "\n",
    "    imread = lambda fn: cv2.imread(fn, cv2.IMREAD_ANYDEPTH)\n",
    "    \n",
    "    point_cloud  = np.fromfile(paths[3], dtype=np.float32).reshape(-1, 3) \n",
    "    intensity_map = imread(paths[4])\n",
    "    \n",
    "    print(f\"{paths[0]} is loaded. \\n# of points {point_cloud.shape[0]}\")\n",
    "    \n",
    "    intensity_values = np.reshape(intensity_map, (-1, 1))\n",
    "    intensity_cloud = np.hstack((point_cloud[:,:2], intensity_values))\n",
    "\n",
    "    point_cloud = (np.hstack((point_cloud, np.ones((point_cloud.shape[0], 1)))) @ transformation_matrix.T)[:,:3]\n",
    "    intensity_cloud = (np.hstack((intensity_cloud, np.ones((intensity_cloud.shape[0], 1)))) @ transformation_matrix.T)[:,:3]\n",
    "\n",
    "    mask = (point_cloud[:,0] <= x_start) & (point_cloud[:,0] >= x_stop) & (np.abs(point_cloud[:,1]) <= y_window)\n",
    "    point_cloud = point_cloud[mask]\n",
    "    intensity_cloud = intensity_cloud[mask]\n",
    "\n",
    "    min_intensity = np.nanmax(intensity_cloud[:,2])\n",
    "    min_z = np.nanmax(point_cloud[:,2])\n",
    "    \n",
    "    print(f\"trimmed to {point_cloud.shape[0]} points\")\n",
    "\n",
    "    minimum_x = point_cloud[np.argmin(np.abs(point_cloud[:,0] - x_stop)),0]\n",
    "    point_cloud[:,0] -= minimum_x\n",
    "    intensity_cloud[:,0] -= minimum_x\n",
    "\n",
    "    x_values = np.unique(point_cloud[:,0])\n",
    "    y_values = np.unique(point_cloud[:,1])\n",
    "\n",
    "    index_ratio = (1/np.median(np.diff(x_values))) * upsample_ratio \n",
    "    x_range = (int)(np.max(x_values) * index_ratio) + 1\n",
    "\n",
    "    y_value_dict = {y: index for index,y in enumerate(y_values)}\n",
    "    x_value_dict = {x: int(x*index_ratio) for x in x_values}\n",
    "\n",
    "    known_indices = np.array(list(x_value_dict.values()), dtype=int)\n",
    "    known_x_values = np.array(list(x_value_dict.keys()), dtype=float)\n",
    "    all_indices = np.arange(x_range)\n",
    "\n",
    "    x_values = np.array(np.interp(all_indices,known_indices,known_x_values))\n",
    "\n",
    "    x_value_dict = {x: index for index,x in enumerate(x_values)}\n",
    "    \n",
    "    point_array = np.full((len(y_values), x_range),np.nan)\n",
    "    intensity_array = np.full((len(y_values), x_range),np.nan)\n",
    "\n",
    "    point_dictionary = {(row[0],row[1]): (index, row[2]) for index,row in enumerate(point_cloud)}\n",
    "    intensity_dictionary = {(row[0],row[1]): (index, row[2]) for index,row in enumerate(intensity_cloud)}\n",
    "\n",
    "    for x in range (x_range):\n",
    "        for y in range (len(y_values)):\n",
    "            x_val = x_values[x]\n",
    "            y_val = y_values[y]\n",
    "\n",
    "            point_z = point_dictionary.get((x_val,y_val))\n",
    "            intensity_z = intensity_dictionary.get((x_val,y_val))\n",
    "\n",
    "            if point_z is not None:\n",
    "                point_array[y,x] = point_z[1]\n",
    "            else:\n",
    "                point_array[y,x] = min_z\n",
    "            if intensity_z is not None:\n",
    "                intensity_array[y,x] = intensity_z[1]\n",
    "            else:\n",
    "                intensity_array[y,x] = min_intensity\n",
    "\n",
    "    print(f\"arrays built\")\n",
    "\n",
    "    for y in range(1,len(y_values)-1):\n",
    "        interpolated_z_values= []\n",
    "        interpolated_i_values = []\n",
    "\n",
    "        for dy in [-1,0,1]:\n",
    "            y_dy = y + dy\n",
    "            known_z = point_array[y_dy,known_indices]\n",
    "\n",
    "            known_i = intensity_array[y_dy,known_indices]\n",
    "            known_x = x_values[known_indices]\n",
    "            mask = ~np.isnan(known_z)\n",
    "\n",
    "            interpolated_z_values.append(np.interp(x_values, known_x[mask], known_z[mask]))\n",
    "            interpolated_i_values.append(np.interp(x_values, known_x[mask], known_i[mask]))\n",
    "        \n",
    "        point_array[y, :] = np.mean(interpolated_z_values, axis=0) \n",
    "        intensity_array[y, :] = np.mean(interpolated_i_values, axis=0) \n",
    "\n",
    "    print(f\"upsampled to {point_array.size} points\")\n",
    "    print(f\"{paths[0]} finished \\n\")\n",
    "\n",
    "    return [paths[0],point_array, x_value_dict, x_values, y_value_dict, y_values, intensity_array]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Get the point clouds\n",
    "point_clouds = []\n",
    "\n",
    "for paths in paths_list:\n",
    "    if None not in paths:\n",
    "        point_clouds.append(get_point_cloud(paths, y_window = 16))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(150, 7 * len(point_clouds)), dpi=150)  \n",
    "gs = fig.add_gridspec(len(point_clouds) * 2, 1, hspace=0.6)  \n",
    "\n",
    "for (i, point_cloud) in enumerate(point_clouds):\n",
    "    name = point_cloud[0]\n",
    "    cloud_1 = point_cloud[1]\n",
    "    cloud_2 = point_cloud[6]\n",
    "    \n",
    "\n",
    "    ax = fig.add_subplot(gs[i * 2, 0])\n",
    "    ax.imshow(np.flipud(cloud_1), cmap='jet', interpolation='nearest', alpha = 1)    \n",
    "    ax.set_xlabel(\"X index\")\n",
    "    ax.set_ylabel(\"Y index\")\n",
    "    ax.set_title(f\"Point Cloud: {name}\", fontsize = 30 ) \n",
    "\n",
    "    ax = fig.add_subplot(gs[i* 2 + 1, 0])\n",
    "    ax.imshow(np.flipud(cloud_2), cmap='binary', interpolation='nearest', alpha = 1)    \n",
    "    ax.set_xlabel(\"X index\")\n",
    "    ax.set_ylabel(\"Y index\") \n",
    "\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create convolved copys of the point_clouds\n",
    "\n",
    "convolved_clouds = []\n",
    "canny_clouds = []\n",
    "\n",
    "kernel_s = np.array([[1,2,1],[2,4,2],[1,2,1]])\n",
    "kernel_y = np.array([[-1],[-2],[0],[2],[1]])\n",
    "kernel_x = np.array([[-1,-2,0,2,1]])\n",
    "\n",
    "\n",
    "for point_cloud in point_clouds:\n",
    "    convolved_cloud = np.abs(convolve(point_cloud[1],kernel_y))\n",
    "    convolved_clouds.append([point_cloud[0],convolved_cloud,point_cloud[2],point_cloud[3],point_cloud[4],point_cloud[5]])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#get vectors for initial clustering\n",
    "\n",
    "v_dict = get_vectors(point_clouds, y_span = 10)\n",
    "v_array = np.array(list(v_dict.values()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#inital clustering\n",
    "dimensions = [1,3] \n",
    "\n",
    "dbscan = DBSCAN(min_samples = 125,\n",
    "                metric = 'chebyshev', \n",
    "                eps = 0.035,\n",
    "                n_jobs = -1) \n",
    "\n",
    "labels1 = dbscan.fit_predict(v_array[:,dimensions])\n",
    "\n",
    "label_dictionary = {key: label for key,label in zip(v_dict.keys(),labels1)}\n",
    "\n",
    "secondary_cluster_indices = np.where(labels1 == 1)[0]\n",
    "key_list = list(v_dict.keys())\n",
    "secondary_keys = [key_list[i] for i in secondary_cluster_indices]\n",
    "\n",
    "secondary_x_values = {}\n",
    "\n",
    "for name, x in secondary_keys:\n",
    "    if name not in secondary_x_values:\n",
    "        secondary_x_values[name] = []\n",
    "    secondary_x_values[name].append(x)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#initial clustering plot\n",
    "fig = plt.figure(figsize=(10,4), dpi = 300)\n",
    "\n",
    "colors = [f\"C{label}\"  if label >= 0 else (0,1,1,1)  for label in labels1]\n",
    "\n",
    "gs = fig.add_gridspec(1, 1 )\n",
    "ax = fig.add_subplot(gs[0,0])\n",
    "\n",
    "x_vals = [v_dict[x][1] for x in v_dict.keys()]\n",
    "y_vals = [v_dict[x][3] for x in v_dict.keys()]\n",
    "ax.set_xlabel(\"skew\")\n",
    "ax.set_ylabel(\"Azimuthal angle\")\n",
    "\n",
    "\n",
    "ax.scatter(x_vals, y_vals, color=colors, s=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#getting convolved vectors from undefined indices\n",
    "print(secondary_keys)\n",
    "v_dict_convolved = get_vectors_combined(point_clouds,convolved_clouds,secondary_x_values, y_span = 10)\n",
    "v_array_convolved = np.array(list(v_dict_convolved.values()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#secondary clustering\n",
    "dimensions = [3,4,8,10]\n",
    "hdbscan_refined = DBSCAN(min_samples = 140,\n",
    "                             metric = \"chebyshev\",\n",
    "                             eps= 0.065,\n",
    "                             n_jobs=-1)\n",
    "\n",
    "labels2 = hdbscan_refined.fit_predict(v_array_convolved[:,dimensions])\n",
    "\n",
    "label_dictionary.update({key: 1 if label == 0 else -1 for key,label in zip(v_dict_convolved.keys(),labels2)})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#secondary clustering plot\n",
    "vectors = np.array(list(v_dict_convolved.values()))\n",
    "x = vectors[:,4]\n",
    "y = vectors[:,10]\n",
    "z = vectors[:,3]\n",
    "\n",
    "\n",
    "fig = go.Figure(data=[go.Scatter3d(\n",
    "    x=x, y=y, z=z,\n",
    "    mode='markers',\n",
    "    marker=dict(size=1.3, color=labels2, opacity=1),\n",
    ")])\n",
    "\n",
    "fig.update_layout(\n",
    "    title=\"3D Scatter of Vectors\",\n",
    "    scene=dict(\n",
    "        xaxis_title=\"mean\",\n",
    "        yaxis_title=\"skew\",\n",
    "        zaxis_title=\"azimuthal angle\",\n",
    "        camera=dict(projection=dict(type=\"orthographic\"))\n",
    "    ),\n",
    "    width=1000,\n",
    "    height=1000\n",
    ")\n",
    "\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#clustering results\n",
    "fig = plt.figure(figsize=(135, 5 * len(point_clouds)), dpi=75)  \n",
    "gs = fig.add_gridspec(len(point_clouds), 1, hspace=0.2)  \n",
    "\n",
    "label_colors = {\n",
    "    -1: \"C0\",\n",
    "    0: \"C1\",\n",
    "    1: \"C2\",\n",
    "    2: \"C3\",\n",
    "    3: (0,0,0,1) \n",
    "}\n",
    "\n",
    "for i, point_cloud in enumerate(point_clouds):\n",
    "    name = point_cloud[0]\n",
    "    cloud = point_cloud[1]\n",
    "    x_to_i = point_cloud[2]\n",
    "    x_vals = point_cloud[3]\n",
    "    y_vals = point_cloud[5]\n",
    "\n",
    "    labels = [label_dictionary.get((name, x), 3) for x in x_vals]\n",
    "    colors = [label_colors[label] if label in [-1, 0, 1, 2] else label_colors[3] for label in labels ]\n",
    "\n",
    "    ax = fig.add_subplot(gs[i, 0])\n",
    "\n",
    "    ax.imshow(cloud, cmap='binary_r', interpolation='nearest', \n",
    "              extent=[min(x_vals), max(x_vals), min(y_vals), max(y_vals)], \n",
    "              origin='lower') \n",
    "\n",
    "    ax.bar(x_vals, height=20, bottom=-10, color=colors, width=1, alpha=0.45)\n",
    "\n",
    "    ax.set_xticks(x_vals[::100])  \n",
    "    ax.set_xticklabels([f\"{x:.2f}\" for x in x_vals[::100]])\n",
    "\n",
    "    ax.set_yticks(y_vals[::25])\n",
    "    ax.set_yticklabels([f\"{y:.2f}\" for y in y_vals[::25]])\n",
    "\n",
    "    ax.set_xlabel(\"X Coordinate\")\n",
    "    ax.set_ylabel(\"Y Coordinate\")\n",
    "    ax.set_title(f\"Point Cloud: {name}\", fontsize=20)\n",
    "\n",
    "legend_patches = [mpatches.Patch(color=color, label=f\"Label {label}\") for label, color in label_colors.items()]\n",
    "fig.legend(handles=legend_patches, loc=\"upper center\", bbox_to_anchor=(0.5, 0.91), ncol=16, fontsize=40)\n",
    "\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (new_env2)",
   "language": "python",
   "name": "new_env2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
