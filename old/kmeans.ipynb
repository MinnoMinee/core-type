{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib qt\n",
    " \n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "import hdbscan\n",
    "from scipy.stats import skew, kurtosis, mode\n",
    "from scipy.spatial import KDTree\n",
    "from scipy.ndimage import convolve\n",
    "from sklearn.cluster import KMeans,DBSCAN\n",
    "from sklearn.cluster import AgglomerativeClustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_parts(directory_path):\n",
    "    parts_paths = []\n",
    "\n",
    "    for root, dirs, files in os.walk(directory_path):\n",
    "        for folder in dirs:\n",
    "            folder = os.path.join(root,folder)\n",
    "            if (\"Box14\\AdaptiveZ_10mm\" in folder) and folder.endswith(\"_4\"):\n",
    "                parts_paths.append(folder)\n",
    "    parts_paths.sort(reverse=True)\n",
    "    return parts_paths\n",
    "\n",
    "base_path = r\"\\\\192.168.1.100\\CoreScan3-2\\Acquisitions\\RnD\\XRF\\CH\\Macassa_clearance\"\n",
    "\n",
    "paths = find_parts(base_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def get_point_cloud(file_path):\n",
    "    coords_file = os.path.join(file_path, '.component_parameters.txt')\n",
    "    with open(coords_file) as file:\n",
    "            lines = file.readlines()\n",
    "                \n",
    "            for line in lines:\n",
    "                if \"XRAY_DPP[Acquisition]#0.Y.Start:\" in line:\n",
    "                    y_offset = (float)(line.split(\"XRAY_DPP[Acquisition]#0.Y.Start:\")[1].strip())\n",
    "                elif \"XRAY_DPP[Acquisition]#0.X.Start:\" in line:\n",
    "                    x_start = (float)(line.split(\"XRAY_DPP[Acquisition]#0.X.Start:\")[1].strip())\n",
    "                elif \"XRAY_DPP[Acquisition]#0.X.Stop:\" in line:\n",
    "                    x_stop = (float)(line.split(\"XRAY_DPP[Acquisition]#0.X.Stop:\")[1].strip())\n",
    "\n",
    "\n",
    "    point_cloud = []\n",
    "\n",
    "    if os.path.isdir(file_path):\n",
    "        lidar_files = [fn for fn in os.listdir(\n",
    "            file_path) if fn.endswith('.bpc')]\n",
    "        if any(lidar_files):\n",
    "            lidar_filename = file_path + os.sep + lidar_files[0]\n",
    "\n",
    "    data = np.fromfile(lidar_filename, dtype=np.float32)\n",
    "    point_cloud = data.reshape(-1, 3)  # to xyz\n",
    "\n",
    "    ff = ~np.isnan(point_cloud).any(axis=1)\n",
    "    point_cloud = point_cloud[ff, ...]\n",
    "\n",
    "    point_cloud[:, 1] = point_cloud[:, 1] - float(y_offset)\n",
    "\n",
    "    print(f\"{file_path} is loaded. \\n# of point {point_cloud.shape[0]}\")\n",
    "\n",
    "\n",
    "    matrix_file = (os.path.join(file_path, \".XRAY_DPP_001.lidar2xrf\"))\n",
    "    with open(matrix_file, 'r') as file:\n",
    "        lines = file.readlines()\n",
    "\n",
    "    transformation_matrix = np.array([list(map(float, line.strip().split(\",\"))) for line in lines])\n",
    "\n",
    "    num_points = point_cloud.shape[0]\n",
    "\n",
    "    homogeneous_points = np.hstack((point_cloud, np.ones((num_points, 1))))\n",
    "    transformed_points = homogeneous_points @ transformation_matrix.T\n",
    "    point_cloud = transformed_points[:, :3]\n",
    "\n",
    "\n",
    "    def trim_cloud(data):\n",
    "        floor = mode(data[:, 2])[0] - 10\n",
    "        print(floor)\n",
    "        data[:,2] = floor - data[:, 2] \n",
    "        data = data[data[:, 2] > 0]\n",
    "        data = data[\n",
    "        (data[:,0] >= x_stop) & \n",
    "        (data[:,0] <= x_start) \n",
    "        ]\n",
    "        return data\n",
    "    \n",
    "    def remove_y_offset(data):\n",
    "        data[:, 1] -= y_offset\n",
    "        return data \n",
    "\n",
    "    point_cloud = trim_cloud(point_cloud)\n",
    "    point_cloud = remove_y_offset(point_cloud)\n",
    "    return point_cloud, x_start, x_stop\n",
    "\n",
    "\n",
    "def convolved_data(data,kernel):\n",
    "    x_values = np.unique(data[:,0])\n",
    "    y_values = np.unique(data[:,1])\n",
    "    array = [[None for _ in range(len(y_values))] for _ in range(len(x_values))]\n",
    "    map = {(row[0],row[1]): (index, row[2]) for index,row in enumerate(data)}\n",
    "\n",
    "    for x in range (len(x_values)):\n",
    "        for y in range (len(y_values)):\n",
    "            x_val = x_values[x]\n",
    "            y_val = y_values[y]\n",
    "            z = map.get((x_val,y_val))\n",
    "            if z is not None:\n",
    "                array[x][y] = z[1]\n",
    "            else:\n",
    "                array[x][y] = 0\n",
    "    \n",
    "    array = convolve(array,kernel, mode = 'reflect')\n",
    "\n",
    "    data2 = data.copy()\n",
    "\n",
    "    for x in range (len(x_values)):\n",
    "        for y in range (len(y_values)):\n",
    "            x_val = x_values[x]\n",
    "            y_val = y_values[y]\n",
    "            index = map.get((x_val,y_val))\n",
    "            if index is not None:\n",
    "                data2[index[0],2] = array[x][y]\n",
    "    \n",
    "    return data2\n",
    "\n",
    "def trim_y(data, y_span=20):\n",
    "   data = data[(data[:,1] >= -y_span) & (data[:,1] <= y_span)]\n",
    "   return data\n",
    "\n",
    "    \n",
    "\n",
    "\n",
    "\n",
    "    \n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "point_clouds = []\n",
    "x_offset = 0\n",
    "for path in paths:\n",
    "    temp_cloud, x_start, x_stop = get_point_cloud(path)\n",
    "    x_offset -= x_stop\n",
    "    temp_cloud[:,0] += x_offset\n",
    "    x_offset += x_start\n",
    "    point_clouds.append(temp_cloud)\n",
    "   \n",
    "point_cloud = np.vstack(point_clouds)\n",
    "point_cloud = trim_y(point_cloud,20)\n",
    "\n",
    "plot_cloud = point_cloud.copy()\n",
    "print(f\"total # of point {point_cloud.shape[0]}\")\n",
    "print(len(np.unique(point_cloud[:,0])))\n",
    "\n",
    "point_tree = KDTree(point_cloud[:,:2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kernel = np.array([\n",
    "    [1,  0,  0,  -1,  0,   0,   1],\n",
    "    [0, -2,  0,   0,  0,  -2,   0],\n",
    "    [0,  0,  1,   0, -1,   0,   0],\n",
    "    [-1, 0,  0,   4,  0,   0,  -1],\n",
    "    [0,  0, -1,   0,  1,   0,   0],\n",
    "    [0, -2,  0,   0,  0,  -2,   0],\n",
    "    [1,  0,  0,  -1,  0,   0,   1]\n",
    "])\n",
    "\n",
    "point_cloud = convolved_data(plot_cloud, kernel)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_vectors(x_span = 1, y_span = 12, step = 1,y_index = 0):\n",
    "    vectors = {}\n",
    "    x_values = np.unique(point_cloud[:, 0])\n",
    "    y = y_index\n",
    "    x = x_values.min()\n",
    "    while(x < x_values.max()):\n",
    "        distribution = get_distribution([x, y], x_span, y_span) \n",
    "        properties = get_props(distribution)\n",
    "        if not np.any(np.isnan(properties)):\n",
    "            vectors[x] = properties\n",
    "        x += step\n",
    "    return vectors\n",
    "\n",
    "\n",
    "def get_distribution(point=[0, 0], x_span=10, y_span=15):\n",
    "    search_radius = max(x_span, y_span)\n",
    "\n",
    "    indices = point_tree.query_ball_point(point, search_radius)\n",
    "\n",
    "    result_points = point_cloud[indices]\n",
    "\n",
    "    filtered_points = result_points[\n",
    "        (result_points[:, 0] >= point[0] - x_span) & (result_points[:, 0] <= point[0] + x_span) &\n",
    "        (result_points[:, 1] >= point[1] - y_span) & (result_points[:, 1] <= point[1] + y_span)\n",
    "    ]\n",
    "\n",
    "    return filtered_points[:, 2]\n",
    "\n",
    "\n",
    "def get_distribution_vs_y(point=[0, 0], x_span=10, y_span=15):\n",
    "    search_radius = max(x_span, y_span)\n",
    "\n",
    "    indices = point_tree.query_ball_point(point, search_radius)\n",
    "\n",
    "    result_points = point_cloud[indices]\n",
    "\n",
    "    filtered_points = result_points[\n",
    "        (result_points[:, 0] >= point[0] - x_span) & (result_points[:, 0] <= point[0] + x_span) &\n",
    "        (result_points[:, 1] >= point[1] - y_span) & (result_points[:, 1] <= point[1] + y_span)\n",
    "    ]\n",
    "\n",
    "    y_vals = {}\n",
    "\n",
    "    for y in range(len(filtered_points[:,1])):\n",
    "        if filtered_points[y,1] not in y_vals:\n",
    "            y_vals[filtered_points[y,1]] = []\n",
    "        y_vals[filtered_points[y,1]].append(filtered_points[y,2])\n",
    "\n",
    "    return y_vals\n",
    "\n",
    "\n",
    "def get_props(distribution):\n",
    "    properties = []\n",
    "\n",
    "    mean = np.mean(distribution)\n",
    "    variance =  np.var(distribution)\n",
    "    skw = skew(distribution)\n",
    "    kurt = kurtosis(distribution)\n",
    "\n",
    "    \n",
    "    properties.append(variance)\n",
    "    properties.append(skw)\n",
    "    properties.append(kurt)\n",
    "\n",
    "    norm = np.sum(x**2 for x in properties)**0.5\n",
    "    \n",
    "    properties = [x / norm for x in properties]\n",
    "\n",
    "    \n",
    "    properties.append(mean)\n",
    "\n",
    "    z = properties[0]\n",
    "    y = properties[1]\n",
    "    x = properties[2]\n",
    "\n",
    "    roe = np.sqrt(x**2 + y**2 + z**2)\n",
    "    properties.append((np.atan2(y,x) + (2 * np.pi)) % (2 * np.pi))\n",
    "    properties.append(np.acos(z/roe))\n",
    "\n",
    "    \n",
    "    return properties\n",
    "\n",
    "def polar_props(properties):\n",
    "    z = properties[0]\n",
    "    y = properties[1]\n",
    "    x = properties[2]\n",
    "\n",
    "    roe = np.sqrt(x**2 + y**2 + z**2)\n",
    "    polar = np.acos(z/roe)\n",
    "    azimuthal = (np.atan2(y,x) + (2 * np.pi)) % (2 * np.pi)\n",
    "   \n",
    "\n",
    "    return [azimuthal,polar]\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "vectors = get_vectors(x_span = 1, y_span = 13, step = 1,y_index = 0).values()\n",
    "\n",
    "\n",
    "\n",
    "x_vals = [v[0] for v in vectors]\n",
    "y_vals = [v[1] for v in vectors]\n",
    "z_vals = [v[2] for v in vectors]\n",
    "\n",
    "fig = plt.figure()\n",
    "ax = fig.add_subplot(111, projection='3d')\n",
    "\n",
    "ax.scatter(x_vals, y_vals, z_vals, color='r', label='End Points', s= 0.2)\n",
    "\n",
    "\n",
    "\n",
    "ax.set_xlabel('variance')\n",
    "ax.set_ylabel('skew')\n",
    "ax.set_zlabel('kurt')\n",
    "\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "x_span = 1\n",
    "y_span = 16\n",
    "step = 1\n",
    "n_clusters = 3\n",
    "cluster_size = 100\n",
    "samples = None\n",
    "met = 'correlation'\n",
    "eps = 1.0\n",
    "a = 1.0\n",
    "\n",
    "fig = plt.figure(figsize=(20,5))\n",
    "point_cloud_copy = plot_cloud[(plot_cloud[:,1] >= 0 - y_span) & (plot_cloud[:,1] <= y_span)]\n",
    "\n",
    "downsampled_indices = np.random.choice(point_cloud_copy.shape[0], size=100000, replace=False)\n",
    "\n",
    "x = point_cloud_copy[:, 0] \n",
    "y = point_cloud_copy[:, 1] \n",
    "z = point_cloud_copy[:, 2] \n",
    "\n",
    "x_downsampled = x[downsampled_indices]\n",
    "y_downsampled = y[downsampled_indices]\n",
    "z_downsampled = z[downsampled_indices]\n",
    "\n",
    "x2 = point_cloud[:, 0] \n",
    "y2 = point_cloud[:, 1] \n",
    "z2 = point_cloud[:, 2] \n",
    "\n",
    "downsampled_indices = np.random.choice(point_cloud.shape[0], size=100000, replace=False)\n",
    "\n",
    "x2_downsampled = x2[downsampled_indices]\n",
    "y2_downsampled = y2[downsampled_indices]\n",
    "z2_downsampled = z2[downsampled_indices]\n",
    "\n",
    " \n",
    "\n",
    "gs = fig.add_gridspec(4, 1, hspace = 2)\n",
    "\n",
    "ax_scatter = fig.add_subplot(gs[1,0])\n",
    "ax_scatter.scatter(\n",
    "    x_downsampled,\n",
    "    y_downsampled,\n",
    "    c=z_downsampled,\n",
    "    cmap='viridis',  \n",
    "    s = 1\n",
    ")\n",
    "\n",
    "ax_scatter.set_title('LIDAR data heatmap')\n",
    "ax_scatter.set_xlabel('X-axis')\n",
    "ax_scatter.set_ylabel('Y-axis')\n",
    "ax_scatter.set_yticks([])\n",
    "\n",
    "ax_scatter2 = fig.add_subplot(gs[0,0])\n",
    "ax_scatter2.scatter(\n",
    "    x2_downsampled,\n",
    "    y2_downsampled,\n",
    "    c=z2_downsampled,\n",
    "    cmap='viridis',  \n",
    "    s = 1\n",
    ")\n",
    "\n",
    "ax_scatter2.set_title('transformed LIDAR data heatmap')\n",
    "ax_scatter2.set_xlabel('X-axis')\n",
    "ax_scatter2.set_ylabel('Y-axis')\n",
    "ax_scatter2.set_yticks([])\n",
    "\n",
    "\n",
    "\n",
    "v_dict = get_vectors(x_span,y_span,step)\n",
    "\n",
    "polar_vectors = []\n",
    "for vec in (v_dict.values()):\n",
    "    vec = (polar_props(vec))\n",
    "\n",
    "kmeans = AgglomerativeClustering(n_clusters)\n",
    "kmeans.fit(list(v_dict.values()))\n",
    "\n",
    "\n",
    "labels = kmeans.labels_\n",
    "x_values = list(v_dict.keys())\n",
    "\n",
    "\n",
    "bar_plot1 = fig.add_subplot(gs[2,0])\n",
    "added_labels = set()\n",
    "\n",
    "for x, core_type in zip(x_values, labels):\n",
    "    label = f\"Core Type {core_type}\" if core_type not in added_labels else None\n",
    "    if label:\n",
    "        added_labels.add(core_type)\n",
    "    bar_plot1.bar(x, height=1, width=step, color=f\"C{core_type**2}\", edgecolor=\"none\", label=label)\n",
    "\n",
    "\n",
    "bar_plot1.set_title(\"Core Type by X-position\")\n",
    "bar_plot1.set_xlabel(\"X-Value\")\n",
    "bar_plot1.legend(title=\"Core Type\", bbox_to_anchor=(1,3), loc=\"upper left\")\n",
    "bar_plot1.set_yticks([])\n",
    "\n",
    "dbscan = hdbscan.HDBSCAN(min_cluster_size = cluster_size,\n",
    "                         min_samples = samples, \n",
    "                         metric = met, \n",
    "                         cluster_selection_epsilon= eps,\n",
    "                         alpha = a,\n",
    "                         core_dist_n_jobs= -1)\n",
    "\n",
    "\n",
    "labels = dbscan.fit_predict(list(v_dict.values()))\n",
    "\n",
    "\n",
    "bar_plot2 = fig.add_subplot(gs[3,0])\n",
    "added_labels = set()\n",
    "\n",
    "for x, core_type in zip(x_values, labels):\n",
    "    label = f\"Core Type {core_type}\" if core_type not in added_labels else None\n",
    "    if label:\n",
    "        added_labels.add(core_type)\n",
    "    bar_plot2.bar(x, height=1, width=step, color=f\"C{core_type+2}\", edgecolor=\"none\", label=label)\n",
    "\n",
    "\n",
    "bar_plot2.set_title(\"Core Type by X-position\")\n",
    "bar_plot2.set_xlabel(\"X-Value\")\n",
    "bar_plot2.legend(title=\"Core Type\", bbox_to_anchor=(1,2), loc=\"upper left\")\n",
    "bar_plot2.set_yticks([])\n",
    "plt.show()\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "x_span = 3.5\n",
    "y_span = 12\n",
    "step = 1\n",
    "\n",
    "parameters = [ ]\n",
    "#cluster size, sample size, metric, epsilon, alpha\n",
    "parameters.append([50, 15, 'euclidean', 0.1, 0.2])\n",
    "parameters.append([50, 15, 'euclidean', 0.1, 0.4])\n",
    "parameters.append([50, 15, 'manhattan', 0.1, 0.2])\n",
    "parameters.append([50, 15, 'manhattan', 0.1, 0.4])\n",
    "parameters.append([50, 15, 'euclidean', 0.1, 0.8])\n",
    "parameters.append([50, 15, 'euclidean', 0.1, 1.6])\n",
    "parameters.append([50, 15, 'manhattan', 0.1, 0.8])\n",
    "parameters.append([50, 15, 'manhattan', 0.1, 1.6])\n",
    "\n",
    "\n",
    "fig = plt.figure(figsize=(16,9))\n",
    "point_cloud_copy = plot_cloud[(plot_cloud[:,1] >= 0 - y_span) & (plot_cloud[:,1] <= y_span)]\n",
    "\n",
    "downsampled_indices = np.random.choice(point_cloud_copy.shape[0], size=100000, replace=False)\n",
    "\n",
    "x = point_cloud_copy[:, 0] \n",
    "y = point_cloud_copy[:, 1] \n",
    "z = point_cloud_copy[:, 2] \n",
    "\n",
    "x_downsampled = x[downsampled_indices]\n",
    "y_downsampled = y[downsampled_indices]\n",
    "z_downsampled = z[downsampled_indices]\n",
    "\n",
    "\n",
    "gs = fig.add_gridspec(len(parameters)+1, 1, hspace = 5)\n",
    "\n",
    "ax_scatter = fig.add_subplot(gs[0,0])\n",
    "ax_scatter.scatter(\n",
    "    x_downsampled,\n",
    "    y_downsampled,\n",
    "    c=z_downsampled,\n",
    "    cmap='viridis',  \n",
    "    s = 1\n",
    ")\n",
    "\n",
    "ax_scatter.set_title('LIDAR data heatmap')\n",
    "ax_scatter.set_xlabel('X-axis')\n",
    "ax_scatter.set_ylabel('Y-axis')\n",
    "\n",
    "\n",
    "\n",
    "v_dict = get_vectors(x_span,y_span,step)\n",
    "\n",
    "for key, vec in v_dict.items():\n",
    "    v_dict[key] = polar_props(vec)\n",
    "\n",
    "count = 0\n",
    "\n",
    "for param in parameters:\n",
    "    count += 1\n",
    "    dbscan = hdbscan.HDBSCAN(min_cluster_size = param[0],\n",
    "                            min_samples = param[1], \n",
    "                            metric = param[2], \n",
    "                            cluster_selection_epsilon= param[3],\n",
    "                            alpha = param[4],\n",
    "                            core_dist_n_jobs= 4)\n",
    "\n",
    "\n",
    "    labels = dbscan.fit_predict(list(v_dict.values()))\n",
    "\n",
    "\n",
    "    bar_plot = fig.add_subplot(gs[count,0])\n",
    "    added_labels = set()\n",
    "\n",
    "    for x, core_type in zip(x_values, labels):\n",
    "        label = f\"Core Type {core_type}\" if core_type not in added_labels else None\n",
    "        if label:\n",
    "            added_labels.add(core_type)\n",
    "        bar_plot.bar(x, height=1, width=step, color=f\"C{core_type+2}\", edgecolor=\"none\", label=label)\n",
    "\n",
    "\n",
    "    bar_plot.set_title(\"Core Type by X-position\")\n",
    "    bar_plot.set_xlabel(\"X-Value\")\n",
    "    bar_plot.legend(title=\"Core Type\", bbox_to_anchor=(1,2), loc=\"upper left\")\n",
    "    bar_plot.set_yticks([])\n",
    "plt.show()\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "x_span = 1\n",
    "y_span = 12\n",
    "step = 1\n",
    "\n",
    "\n",
    "#cluster size, sample size, metric, epsilon, alpha\n",
    "param = [10, 20, 'euclidean', 0.1, 0.5]\n",
    "\n",
    "\n",
    "fig = plt.figure()\n",
    "ax = fig.add_subplot(111, projection='3d')\n",
    "v_dict = get_vectors(x_span, y_span, step)\n",
    "added_labels = set()\n",
    "\n",
    "\n",
    "dbscan = hdbscan.HDBSCAN(min_cluster_size=param[0],\n",
    "                         min_samples=param[1], \n",
    "                         metric=param[2], \n",
    "                         cluster_selection_epsilon=param[3],\n",
    "                         alpha=param[4],\n",
    "                         core_dist_n_jobs=4)\n",
    "\n",
    "labels = dbscan.fit_predict(list(v_dict.values()))\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "for vec, label in zip(v_dict.values(), labels):\n",
    "    color = f\"C{label + 2}\" if label >= 0 else \"gray\"\n",
    "\n",
    "    ax.scatter(vec[4], vec[5], 0, color=color, s=1)\n",
    "\n",
    "ax.set_title(\"3D Scatter of Vectors by Core Type\", pad=20)\n",
    "ax.set_xlabel('azimuthal')\n",
    "ax.set_ylabel('polar')\n",
    "ax.set_zlabel('mean')\n",
    "\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
