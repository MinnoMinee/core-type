{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import matplotlib.pyplot    as plt\n",
    "import numpy                as np\n",
    "import matplotlib.patches   as mpatches\n",
    "import plotly.graph_objects as go\n",
    "from   scipy.stats      import skew, kurtosis, mode\n",
    "from   scipy.spatial    import KDTree\n",
    "from   sklearn.cluster  import DBSCAN\n",
    "from   scipy.ndimage    import convolve\n",
    "from   collections      import Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FileParser:\n",
    "    def __init__(self, root_dir):\n",
    "        self.root_dir = root_dir\n",
    "        self.box_folders = []\n",
    "\n",
    "    def find_folders(self):\n",
    "        for root, dirs, files in os.walk(self.root_dir):\n",
    "                for dir_name in dirs:\n",
    "                    if dir_name.startswith(\"Box\"):\n",
    "                        adaptive_z_folder = os.path.join(root, dir_name, \"AdaptiveZ_10mm\")\n",
    "\n",
    "                        if os.path.isdir(adaptive_z_folder): \n",
    "                            for part_folder in os.listdir(adaptive_z_folder):\n",
    "                                full_part_path = os.path.join(adaptive_z_folder, part_folder)\n",
    "                                if os.path.isdir(full_part_path) and \"Core_000_Box_009_of_020_Part_4_of_4\" in part_folder:\n",
    "                                    component_parameters_path = None\n",
    "                                    lidar2xrf_path = None\n",
    "                                    bpc_path = None\n",
    "                                    for file_name in os.listdir(full_part_path):\n",
    "                                        if file_name.endswith(\".component_parameters.txt\"):\n",
    "                                            component_parameters_path = os.path.join(full_part_path, file_name)\n",
    "                                        elif file_name.endswith(\".lidar2xrf\"):\n",
    "                                            lidar2xrf_path = os.path.join(full_part_path, file_name)\n",
    "                                        elif file_name.endswith(\".bpc\"):\n",
    "                                            bpc_path = os.path.join(full_part_path, file_name)\n",
    "\n",
    "                                    self.box_folders.append((part_folder,component_parameters_path, lidar2xrf_path, bpc_path))\n",
    "\n",
    "    def get_box_folders(self):\n",
    "        self.find_folders()\n",
    "        return self.box_folders\n",
    "\n",
    "\n",
    "parser = FileParser(r\"\\\\192.168.217.101\\GeologicAI\\Acquisitions\\AEM-FGM\\UDH3143B\")\n",
    "paths_list = parser.get_box_folders()\n",
    "\n",
    "for name, component_parameters_path, lidar2xrf_path, bpc_path in paths_list:\n",
    "    print(f\"Part: {name}\")\n",
    "    if component_parameters_path:\n",
    "        print(f\"  Component Parameters: {component_parameters_path}\")\n",
    "    if lidar2xrf_path:\n",
    "        print(f\"  LIDAR to XRF: {lidar2xrf_path}\")\n",
    "    if bpc_path:\n",
    "        print(f\"  BPC File: {bpc_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_vectors(data, y_span=10):\n",
    "    vectors = {}\n",
    "    \n",
    "    for point_cloud in data:\n",
    "        \n",
    "        name = point_cloud[0]\n",
    "        cloud = point_cloud[1]\n",
    "        \n",
    "        i_to_x = point_cloud[3]\n",
    "        y_to_i = point_cloud[4]\n",
    "        \n",
    "        y_indices = [y_to_i[value] for value in y_to_i.keys() if abs(value) <= y_span]\n",
    "\n",
    "        for i in range(len(cloud[0])):\n",
    "            x = i_to_x[i]\n",
    "            distribution = []\n",
    "            for j in y_indices:\n",
    "                distribution.append(cloud[j][i])\n",
    "            properties = get_props(distribution)\n",
    "            if not (np.any(np.isnan(properties))):\n",
    "                vectors[(name, x)] = properties\n",
    "\n",
    "    return vectors\n",
    "\n",
    "def get_vectors_combined(data1, data2, x_values_dict, y_span=10):\n",
    "    vectors = {}   \n",
    "\n",
    "    for point_cloud,convolved_cloud in zip(data1,data2):\n",
    "        \n",
    "        name = point_cloud[0]\n",
    "        x_values = x_values_dict[name]\n",
    "        cloud = point_cloud[1]\n",
    "        convolved_cloud = convolved_cloud[1]\n",
    "        \n",
    "        x_to_i = point_cloud[2]\n",
    "        y_to_i = point_cloud[4]\n",
    "        \n",
    "        y_indices = [y_to_i[value] for value in y_to_i.keys() if abs(value) <= y_span]\n",
    "\n",
    "        for x in x_values:\n",
    "            i = x_to_i[x]\n",
    "            distribution = []\n",
    "            convolved_distribution = []\n",
    "            for j in y_indices:\n",
    "                distribution.append(cloud[j][i])\n",
    "                convolved_distribution.append(convolved_cloud[j][i])\n",
    "            properties = get_props(distribution)\n",
    "            convolved_properties = get_props_convolved(convolved_distribution)\n",
    "            vector = convolved_properties + properties\n",
    "            if not (np.any(np.isnan(properties))):\n",
    "                vectors[(name, x)] = vector\n",
    "\n",
    "    return vectors\n",
    "\n",
    "def get_props_convolved(distribution):\n",
    "    properties = []\n",
    "\n",
    "    mean = np.sqrt(np.mean(distribution))\n",
    "    max = np.sqrt(np.max(distribution))\n",
    "\n",
    "    variance =  np.var(distribution)\n",
    "    skw = skew(distribution)\n",
    "    kurt = kurtosis(distribution)\n",
    "\n",
    "    \n",
    "    properties.append(variance)\n",
    "    properties.append(skw)\n",
    "    properties.append(kurt)\n",
    "    \n",
    "\n",
    "    norm = np.linalg.norm(properties)\n",
    "    \n",
    "    if norm > 0:\n",
    "        properties = [x / norm for x in properties]\n",
    "    \n",
    "\n",
    "    properties.append(mean)\n",
    "    properties.append(max)\n",
    "\n",
    "    z = properties[0]\n",
    "    y = properties[1]\n",
    "    x = properties[2]\n",
    "\n",
    "    properties.append((np.atan2(y,x) + (2 * np.pi)) % (2 * np.pi))\n",
    "    properties.append(np.atan(z)/(np.pi/2))\n",
    "\n",
    "\n",
    "    return properties\n",
    "\n",
    "def get_props(distribution):\n",
    "    properties = []\n",
    "\n",
    "    variance =  np.var(distribution)\n",
    "    skw = skew(distribution)\n",
    "    kurt = kurtosis(distribution)\n",
    "\n",
    "    \n",
    "    properties.append(variance)\n",
    "    properties.append(skw)\n",
    "    properties.append(kurt)\n",
    "\n",
    "    norm = np.linalg.norm(properties)\n",
    "    \n",
    "    if norm > 0:\n",
    "        properties = [x / norm for x in properties]\n",
    "\n",
    "    z = properties[0]\n",
    "\n",
    "    properties.append(np.acos(z)/(np.pi/2))\n",
    "\n",
    "    return properties\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_point_cloud(paths, y_window = 25):\n",
    "\n",
    "    with open(paths[1]) as file:\n",
    "            lines = file.readlines()\n",
    "            for line in lines:\n",
    "                if \"XRAY_DPP[Acquisition]#0.X.Start:\" in line:\n",
    "                    x_start = (float)(line.split(\"XRAY_DPP[Acquisition]#0.X.Start:\")[1].strip())\n",
    "                if \"XRAY_DPP[Acquisition]#0.X.Stop:\" in line:\n",
    "                    x_stop = (float)(line.split(\"XRAY_DPP[Acquisition]#0.X.Stop:\")[1].strip())\n",
    "\n",
    "    with open(paths[2]) as file:\n",
    "        lines = file.readlines()\n",
    "        transformation_matrix = np.array([list(map(float, line.strip().split(\",\"))) for line in lines])\n",
    "\n",
    "    point_cloud  = np.fromfile(paths[3], dtype=np.float32).reshape(-1, 3) \n",
    "\n",
    "    ff = ~np.isnan(point_cloud).any(axis=1)\n",
    "    point_cloud = point_cloud[ff, ...]\n",
    "\n",
    "\n",
    "    print(f\"{paths[0]} is loaded. \\n# of point {point_cloud.shape[0]}\")\n",
    "\n",
    "    point_cloud = (np.hstack((point_cloud, np.ones((point_cloud.shape[0], 1)))) @ transformation_matrix.T)[:,:3]\n",
    "\n",
    "    mask = (point_cloud[:,0] <= x_start) & (point_cloud[:,0] >= x_stop) & (np.abs(point_cloud[:,1]) <= y_window)\n",
    "    point_cloud = point_cloud[mask]\n",
    "\n",
    "    print(f\"reduced to {point_cloud.shape[0]} points \\n\")\n",
    "\n",
    "    x_values = np.unique(point_cloud[:,0])\n",
    "    y_values = np.unique(point_cloud[:,1])\n",
    "\n",
    "    y_value_dict = {y: index for index,y in enumerate(y_values)}\n",
    "    x_value_dict = {x: index for index,x in enumerate(x_values)}\n",
    "\n",
    "    array = np.full((len(y_values), len(x_values)),np.nan)\n",
    "    point_dictionary = {(row[0],row[1]): (index, row[2]) for index,row in enumerate(point_cloud)}\n",
    "\n",
    "    for x in range (len(x_values)):\n",
    "        for y in range (len(y_values)):\n",
    "            x_val = x_values[x]\n",
    "            y_val = y_values[y]\n",
    "            z = point_dictionary.get((x_val,y_val))\n",
    "            if z is not None:\n",
    "                array[y][x] = z[1]\n",
    "\n",
    "\n",
    "\n",
    "    return [paths[0],array, x_value_dict, x_values, y_value_dict, y_values]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def canny(data, weak_threshold  = 1,strong_threshold = 2):\n",
    "    array = data[1]\n",
    "    y_values = data[5]\n",
    "\n",
    "    sobel_x = np.array([\n",
    "        [-32, 0, 32]\n",
    "    ])\n",
    "\n",
    "    gauss =  np.array([\n",
    "    [1,  4,  7,  4,  1],\n",
    "    [4, 16, 26, 16,  4],\n",
    "    [7, 26, 41, 26,  7],\n",
    "    [4, 16, 26, 16,  4],\n",
    "    [1,  4,  7,  4,  1]\n",
    "    ]) / 273\n",
    "\n",
    "    sobel_y = np.array([\n",
    "        [-1,-2,-1],\n",
    "        [-2,-4,-2],\n",
    "        [-3,-6,-3],\n",
    "        [-2,-4,-2],\n",
    "        [ 0, 0, 0],\n",
    "        [ 2, 4, 2],\n",
    "        [ 3, 6, 3],\n",
    "        [ 2, 4, 2],\n",
    "        [ 1, 2, 1]\n",
    "    ])\n",
    "    angs = np.array([0, np.pi/4, np.pi/2, 3*np.pi/4])\n",
    "    neighbours_1 = [[0,1,0,-1],[-1,-1,1,1],[1,0,-1,0],[-1,1,1,-1]]\n",
    "    neighbours_2 = [(-1, -1), (-1, 0), (-1, 1), (0, -1), (0, 1), (1, -1), (1, 0), (1, 1)]\n",
    "\n",
    "    array = convolve(array, gauss)\n",
    "    y_grad = convolve(array, sobel_y)\n",
    "    x_grad = convolve(array, sobel_x)\n",
    "\n",
    "    magnitude = np.sqrt(x_grad**2 + y_grad**2)\n",
    "    Gtheta = np.arctan2(y_grad, x_grad) % np.pi\n",
    "    theta_indices = np.argmin(np.abs(Gtheta[:, :, None] - angs), axis=2)\n",
    "\n",
    "    NMS_array = np.zeros(array.shape)\n",
    "    for y in range(1, array.shape[0] - 1):\n",
    "        for x in range(1, array.shape[1] - 1):\n",
    "            mag = magnitude[y, x]\n",
    "            angle = theta_indices[y, x]\n",
    "\n",
    "            add = neighbours_1[angle]\n",
    "            n1, n2 = magnitude[y + add[0], x + add[1]], magnitude[y + add[2], x + add[3]]\n",
    "            \n",
    "\n",
    "            if mag >= n1 and mag >= n2:\n",
    "                NMS_array[y, x] = mag\n",
    "\n",
    "    strong_edges = (NMS_array >= strong_threshold).astype(np.uint8) \n",
    "    weak_edges = ((NMS_array >= weak_threshold) & (NMS_array < strong_threshold)).astype(np.uint8)  \n",
    "    return_array = np.full_like(NMS_array, np.nan, dtype=np.float64)\n",
    "\n",
    "    strong_y, strong_x = np.where(strong_edges == 1)\n",
    "    \n",
    "    \n",
    "    while strong_y.size > 0:\n",
    "        y, x = strong_y[0], strong_x[0]\n",
    "        strong_y, strong_x = np.delete(strong_y, 0), np.delete(strong_x, 0)\n",
    "        return_array[y, x] = 1\n",
    "\n",
    "        for dy, dx in neighbours_2:\n",
    "            ny, nx = y + dy, x + dx\n",
    "            if 0 <= ny < return_array.shape[0] and 0 <= nx < return_array.shape[1]:\n",
    "                if weak_edges[ny, nx] == 1:\n",
    "                    weak_edges[ny, nx] = 0  \n",
    "                    strong_y = np.append(strong_y, ny)\n",
    "                    strong_x = np.append(strong_x, nx)\n",
    "\n",
    "    y_top = np.argmin(np.abs(y_values - 10))\n",
    "    y_bottom = np.argmin(np.abs(y_values + 10))\n",
    "\n",
    "\n",
    "    return_array[y_top, :] = 1\n",
    "    return_array[y_bottom, :] = 1\n",
    "  \n",
    "\n",
    "    return return_array\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Get the point clouds\n",
    "point_clouds = []\n",
    "\n",
    "for paths in paths_list:\n",
    "    if None not in paths:\n",
    "        point_cloud = get_point_cloud(paths)\n",
    "        point_clouds.append(point_cloud)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create convolved copys of the point_clouds\n",
    "\n",
    "convolved_clouds = []\n",
    "canny_clouds = []\n",
    "\n",
    "kernel_s = np.array([[1,2,1],[2,4,2],[1,2,1]])\n",
    "kernel_y = np.array([[-1],[-2],[0],[2],[1]])\n",
    "kernel_x = np.array([[-1,-2,0,2,1]])\n",
    "\n",
    "\n",
    "for point_cloud in point_clouds:\n",
    "    convolved_cloud = np.abs(convolve(point_cloud[1],kernel_y))\n",
    "    convolved_clouds.append([point_cloud[0],convolved_cloud,point_cloud[2],point_cloud[3],point_cloud[4],point_cloud[5]])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Get the point clouds\n",
    "point_clouds = []\n",
    "\n",
    "for paths in paths_list:\n",
    "    if None not in paths:\n",
    "        point_cloud = get_point_cloud(paths)\n",
    "        point_clouds.append(point_cloud)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create convolved copys of the point_clouds\n",
    "\n",
    "convolved_clouds = []\n",
    "canny_clouds = []\n",
    "\n",
    "kernel_s = np.array([[1,2,1],[2,4,2],[1,2,1]])\n",
    "kernel_y = np.array([[-1],[-2],[0],[2],[1]])\n",
    "kernel_x = np.array([[-1,-2,0,2,1]])\n",
    "\n",
    "\n",
    "for point_cloud in point_clouds:\n",
    "    convolved_cloud = np.abs(convolve(point_cloud[1],kernel_y))\n",
    "    convolved_clouds.append([point_cloud[0],convolved_cloud,point_cloud[2],point_cloud[3],point_cloud[4],point_cloud[5]])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#get vectors for initial clustering\n",
    "\n",
    "v_dict = get_vectors(point_clouds, y_span = 10)\n",
    "v_array = np.array(list(v_dict.values()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#inital clustering\n",
    "dimensions = [1,3] \n",
    "\n",
    "dbscan = DBSCAN(min_samples = 50,\n",
    "                metric = 'chebyshev', \n",
    "                eps = 0.054,\n",
    "                n_jobs = -1) \n",
    "\n",
    "labels1 = dbscan.fit_predict(v_array[:,dimensions])\n",
    "\n",
    "label_dictionary = {key: label for key,label in zip(v_dict.keys(),labels1)}\n",
    "\n",
    "secondary_cluster_indices = np.where(labels1 == 1)[0]\n",
    "key_list = list(v_dict.keys())\n",
    "secondary_keys = [key_list[i] for i in secondary_cluster_indices]\n",
    "\n",
    "secondary_x_values = {}\n",
    "\n",
    "for name, x in secondary_keys:\n",
    "    if name not in secondary_x_values:\n",
    "        secondary_x_values[name] = []\n",
    "    secondary_x_values[name].append(x)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#initial clustering plot\n",
    "fig = plt.figure(figsize=(10,4), dpi = 300)\n",
    "\n",
    "colors = [f\"C{label}\"  if label >= 0 else (0,1,1,1)  for label in labels1]\n",
    "\n",
    "gs = fig.add_gridspec(1, 1 )\n",
    "ax = fig.add_subplot(gs[0,0])\n",
    "\n",
    "x_vals = [v_dict[x][1] for x in v_dict.keys()]\n",
    "y_vals = [v_dict[x][3] for x in v_dict.keys()]\n",
    "ax.set_xlabel(\"skew\")\n",
    "ax.set_ylabel(\"Azimuthal angle\")\n",
    "\n",
    "\n",
    "ax.scatter(x_vals, y_vals, color=colors, s=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#getting convolved vectors from undefined indices\n",
    "\n",
    "v_dict_convolved = get_vectors_combined(point_clouds,convolved_clouds,secondary_x_values, y_span = 10)\n",
    "v_array_convolved = np.array(list(v_dict_convolved.values()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#secondary clustering\n",
    "dimensions = [3,4,8,10]\n",
    "hdbscan_refined = DBSCAN(min_samples = 45,\n",
    "                             metric = \"euclidean\",\n",
    "                             eps= 0.08,\n",
    "                             n_jobs=-1)\n",
    "\n",
    "labels2 = hdbscan_refined.fit_predict(v_array_convolved[:,dimensions])\n",
    "\n",
    "label_dictionary.update({key: 1 if label == 0 else -1 for key,label in zip(v_dict_convolved.keys(),labels2)})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#secondary clustering plot\n",
    "vectors = np.array(list(v_dict_convolved.values()))\n",
    "x = vectors[:,4]\n",
    "y = vectors[:,10]\n",
    "z = vectors[:,8]\n",
    "\n",
    "\n",
    "fig = go.Figure(data=[go.Scatter3d(\n",
    "    x=x, y=y, z=z,\n",
    "    mode='markers',\n",
    "    marker=dict(size=1.3, color=labels2, opacity=1),\n",
    ")])\n",
    "\n",
    "fig.update_layout(\n",
    "    title=\"3D Scatter of Vectors\",\n",
    "    scene=dict(\n",
    "        xaxis_title=\"mean\",\n",
    "        yaxis_title=\"skew\",\n",
    "        zaxis_title=\"azimuthal angle\",\n",
    "        camera=dict(projection=dict(type=\"orthographic\"))\n",
    "    ),\n",
    "    width=1000,\n",
    "    height=1000\n",
    ")\n",
    "\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#clustering results\n",
    "fig = plt.figure(figsize=(135, 5 * len(point_clouds)), dpi=200)  \n",
    "gs = fig.add_gridspec(len(point_clouds), 1, hspace=0.2)  \n",
    "\n",
    "label_colors = {\n",
    "    -1: \"C0\",\n",
    "    0: \"C1\",\n",
    "    1: \"C2\",\n",
    "    2: \"C3\",\n",
    "    3: (0,0,0,1) \n",
    "}\n",
    "\n",
    "for i, point_cloud in enumerate(point_clouds):\n",
    "    name = point_cloud[0]\n",
    "    cloud = point_cloud[1]\n",
    "    x_to_i = point_cloud[2]\n",
    "    x_vals = point_cloud[3]\n",
    "    y_vals = point_cloud[5]\n",
    "\n",
    "    labels = [label_dictionary.get((name, x), 3) for x in x_vals]\n",
    "    colors = [label_colors[label] if label in [-1, 0, 1, 2] else label_colors[3] for label in labels ]\n",
    "\n",
    "    ax = fig.add_subplot(gs[i, 0])\n",
    "\n",
    "    ax.imshow(cloud, cmap='binary_r', interpolation='nearest', \n",
    "              extent=[min(x_vals), max(x_vals), min(y_vals), max(y_vals)], \n",
    "              origin='lower') \n",
    "\n",
    "    ax.bar(x_vals, height=20, bottom=-10, color=colors, width=1, alpha=0.45)\n",
    "\n",
    "    ax.set_xticks(x_vals[::100])  \n",
    "    ax.set_xticklabels([f\"{x:.2f}\" for x in x_vals[::100]])\n",
    "\n",
    "    ax.set_yticks(y_vals[::25])\n",
    "    ax.set_yticklabels([f\"{y:.2f}\" for y in y_vals[::25]])\n",
    "\n",
    "    ax.set_xlabel(\"X Coordinate\")\n",
    "    ax.set_ylabel(\"Y Coordinate\")\n",
    "    ax.set_title(f\"Point Cloud: {name}\", fontsize=20)\n",
    "\n",
    "legend_patches = [mpatches.Patch(color=color, label=f\"Label {label}\") for label, color in label_colors.items()]\n",
    "fig.legend(handles=legend_patches, loc=\"upper center\", bbox_to_anchor=(0.5, 0.91), ncol=16, fontsize=40)\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "canny_clouds = []\n",
    "\n",
    "for point_cloud in point_clouds:\n",
    "    canny_clouds.append([point_cloud[0], canny(point_cloud,weak_threshold = 2,strong_threshold = 4),point_cloud[2],point_cloud[3],point_cloud[4],point_cloud[5]])\n",
    "    print(f\"done {point_cloud[0]}\")\n",
    "print(\"done canny\")\n",
    "fig = plt.figure(figsize=(70, 10 * len(point_clouds)), dpi=200)  \n",
    "gs = fig.add_gridspec(len(point_clouds), 1, hspace=0.45)  \n",
    "\n",
    "for (i, canny_cloud), (i2, point_cloud) in zip(enumerate(canny_clouds), enumerate(point_clouds)):\n",
    "    name = point_cloud[0]\n",
    "    cloud_1 = canny_cloud[1]\n",
    "    cloud_2 = point_cloud[1]\n",
    "    x_vals = point_cloud[3]\n",
    "    y_vals = point_cloud[5]\n",
    "\n",
    "    \n",
    "    ax = fig.add_subplot(gs[i, 0])\n",
    "\n",
    "    \n",
    "    ax.imshow(np.flipud(cloud_2), cmap='viridis', interpolation='nearest') \n",
    "    \n",
    "    ax.imshow(np.flipud(cloud_1), cmap='binary', interpolation='nearest' ) \n",
    "\n",
    "    ax.set_xlabel(\"X index\")\n",
    "    ax.set_ylabel(\"Y index\")\n",
    "    ax.set_title(f\"Point Cloud: {name}\", fontsize=40)\n",
    "\n",
    "\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "new_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
