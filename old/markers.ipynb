{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import matplotlib.pyplot    as plt\n",
    "import numpy                as np\n",
    "import matplotlib.patches   as mpatches\n",
    "import plotly.graph_objects as go\n",
    "from   scipy.stats      import skew, kurtosis, mode\n",
    "from   scipy.spatial    import KDTree\n",
    "from   sklearn.cluster  import DBSCAN\n",
    "from   scipy.ndimage    import convolve\n",
    "from   collections      import Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_vectors(data1, data2, x_vals, y_span=20):\n",
    "    vectors = {}\n",
    "    for x in x_vals:\n",
    "        distribution = get_distribution(data1,data2,x, y_span) \n",
    "        properties = get_props(distribution)\n",
    "        if not np.any(np.isnan(properties)):\n",
    "            vectors[x] = properties\n",
    "    return vectors\n",
    "\n",
    "def get_vectors_convolved(data1, data2, x_vals, y_span=20):\n",
    "    vectors = {}\n",
    "    for x in x_vals:\n",
    "        distribution = get_distribution(data1,data2,x, y_span)\n",
    "        if distribution.size > 0: \n",
    "            properties = get_props_convolved(distribution)\n",
    "        else:\n",
    "            properties = [0,0,0,0,0,0,0]\n",
    "        if not np.any(np.isnan(properties)):\n",
    "            vectors[x] = properties\n",
    "    return vectors\n",
    "\n",
    "def get_vectors_combined(tree, og, convolved, x_vals, y_span=20):\n",
    "    vectors = {}\n",
    "    for x in x_vals:\n",
    "        conv_dist = get_distribution(convolved,tree,x, y_span)\n",
    "        dist = get_distribution(og,tree,x,y_span)\n",
    "        if conv_dist.size > 0: \n",
    "            conv_props = get_props_convolved(conv_dist)\n",
    "        else:\n",
    "            conv_props = [0,0,0,0,0,0,0]\n",
    "        properties = np.hstack((conv_props, get_props(dist)))\n",
    "        if not (np.any(np.isnan(properties))):\n",
    "                vectors[x] = properties\n",
    "    return vectors\n",
    "\n",
    "def get_distribution(data1, data2, point, y_span):\n",
    "\n",
    "    indices = data2.query_ball_point((point,0), y_span)\n",
    "\n",
    "    result_points = data1[indices]\n",
    "\n",
    "    filtered_points = result_points[\n",
    "        (result_points[:, 0] == point) &\n",
    "        (np.abs(result_points[:, 1]) <= y_span) & \n",
    "        (result_points[:,2] != 0)\n",
    "    ]\n",
    "\n",
    "    return filtered_points[:, 2]\n",
    "\n",
    "\n",
    "def get_props_convolved(distribution):\n",
    "    properties = []\n",
    "\n",
    "    mean = np.sqrt(np.mean(distribution))\n",
    "    max = np.sqrt(np.max(distribution))\n",
    "\n",
    "    variance =  np.var(distribution)\n",
    "    skw = skew(distribution)\n",
    "    kurt = kurtosis(distribution)\n",
    "\n",
    "    \n",
    "    properties.append(variance)\n",
    "    properties.append(skw)\n",
    "    properties.append(kurt)\n",
    "    \n",
    "\n",
    "    norm = np.linalg.norm(properties)\n",
    "    \n",
    "    if norm > 0:\n",
    "        properties = [x / norm for x in properties]\n",
    "    \n",
    "\n",
    "    properties.append(mean)\n",
    "    properties.append(max)\n",
    "\n",
    "    z = properties[0]\n",
    "    y = properties[1]\n",
    "    x = properties[2]\n",
    "\n",
    "    properties.append((np.atan2(y,x) + (2 * np.pi)) % (2 * np.pi))\n",
    "    properties.append(np.atan(z)/(np.pi/2))\n",
    "\n",
    "\n",
    "    return properties\n",
    "\n",
    "def get_props(distribution):\n",
    "    properties = []\n",
    "\n",
    "    variance =  np.var(distribution)\n",
    "    skw = skew(distribution)\n",
    "    kurt = kurtosis(distribution)\n",
    "\n",
    "    \n",
    "    properties.append(variance)\n",
    "    properties.append(skw)\n",
    "    properties.append(kurt)\n",
    "\n",
    "    norm = np.linalg.norm(properties)\n",
    "    \n",
    "    if norm > 0:\n",
    "        properties = [x / norm for x in properties]\n",
    "\n",
    "    z = properties[0]\n",
    "\n",
    "    properties.append(np.acos(z)/(np.pi/2))\n",
    "\n",
    "    \n",
    "    return properties\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def trim_cloud(data,start,stop,span = 22):\n",
    "        data = data[\n",
    "            (data[:,0] >= stop) & \n",
    "            (data[:,0] <= start) \n",
    "            ]\n",
    "        data = data[(data[:,1] >= -span) & (data[:,1] <= span)]\n",
    "        return data\n",
    "\n",
    "\n",
    "def get_point_cloud(file_path):\n",
    "\n",
    "    point_cloud = []\n",
    "\n",
    "    with open(os.path.join(file_path, '.component_parameters.txt')) as file:\n",
    "            lines = file.readlines()\n",
    "            for line in lines:\n",
    "                if \"XRAY_DPP[Acquisition]#0.Y.Start:\" in line:\n",
    "                    y_offset = (float)(line.split(\"XRAY_DPP[Acquisition]#0.Y.Start:\")[1].strip())\n",
    "                elif \"XRAY_DPP[Acquisition]#0.X.Start:\" in line:\n",
    "                    x_start = (float)(line.split(\"XRAY_DPP[Acquisition]#0.X.Start:\")[1].strip())\n",
    "                elif \"XRAY_DPP[Acquisition]#0.X.Stop:\" in line:\n",
    "                    x_stop = (float)(line.split(\"XRAY_DPP[Acquisition]#0.X.Stop:\")[1].strip())\n",
    "\n",
    "\n",
    "    if os.path.isdir(file_path):\n",
    "        lidar_files = [fn for fn in os.listdir(\n",
    "            file_path) if fn.endswith('.bpc')]\n",
    "        if any(lidar_files):\n",
    "            lidar_filename = file_path + os.sep + lidar_files[0]\n",
    "\n",
    "    data = np.fromfile(lidar_filename, dtype=np.float32)\n",
    "    point_cloud = data.reshape(-1, 3) \n",
    "\n",
    "    ff = ~np.isnan(point_cloud).any(axis=1)\n",
    "    point_cloud = point_cloud[ff, ...]\n",
    "\n",
    "\n",
    "    print(f\"{file_path} is loaded. \\n# of point {point_cloud.shape[0]}\")\n",
    "\n",
    "    matrix_file = (os.path.join(file_path, \".XRAY_DPP_001.lidar2xrf\"))\n",
    "    with open(matrix_file, 'r') as file:\n",
    "        lines = file.readlines()\n",
    "\n",
    "    transformation_matrix = np.array([list(map(float, line.strip().split(\",\"))) for line in lines])\n",
    "\n",
    "    num_points = point_cloud.shape[0]\n",
    "\n",
    "\n",
    "    homogeneous_points = np.hstack((point_cloud, np.ones((num_points, 1))))\n",
    "    transformed_points = homogeneous_points @ transformation_matrix.T\n",
    "    point_cloud = transformed_points[:, :3]\n",
    "\n",
    "\n",
    "    point_cloud = trim_cloud(point_cloud,x_start,x_stop)\n",
    "\n",
    "\n",
    "    return point_cloud, x_start, x_stop\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convolve_data(data,kernels):\n",
    "    x_values = np.unique(data[:,0])\n",
    "    y_values = np.unique(data[:,1])\n",
    "    array = np.zeros((len(y_values), len(x_values)))\n",
    "    map = {(row[0],row[1]): (index, row[2]) for index,row in enumerate(data)}\n",
    "\n",
    "    for x in range (len(x_values)):\n",
    "        for y in range (len(y_values)):\n",
    "            x_val = x_values[x]\n",
    "            y_val = y_values[y]\n",
    "            z = map.get((x_val,y_val))\n",
    "            if z is not None:\n",
    "                array[y][x] = z[1]\n",
    "\n",
    "    result_array = np.zeros((len(y_values), len(x_values)))\n",
    "    \n",
    "    for kernel in kernels:\n",
    "        result_array += np.abs(convolve(array,kernel))\n",
    "\n",
    "    return_data = data.copy()\n",
    "\n",
    "    for x in range (len(x_values)):\n",
    "        for y in range (len(y_values)):\n",
    "            x_val = x_values[x]\n",
    "            y_val = y_values[y]\n",
    "            index = map.get((x_val,y_val))\n",
    "            if index is not None:\n",
    "                return_data[index[0],2] = result_array[y][x]\n",
    "    return return_data\n",
    "\n",
    "def canny(data):\n",
    "    sobel_x = np.array([\n",
    "        [-1, 0, 1],\n",
    "        [-2, 0, 2],\n",
    "        [-1, 0, 1]\n",
    "    ])\n",
    "    sobel_y = np.array([\n",
    "        [ 1, 2, 1],\n",
    "        [ 0, 0, 0],\n",
    "        [-1,-2,-1]\n",
    "    ])\n",
    "    angs = np.array([0, np.pi/4, np.pi/2, 3*np.pi/4])\n",
    "\n",
    "    x_values = np.unique(data[:,0])\n",
    "    y_values = np.unique(data[:,1])\n",
    "    array = np.zeros((len(y_values), len(x_values)))\n",
    "    map = {(row[0],row[1]): (index, row[2]) for index,row in enumerate(data)}\n",
    "\n",
    "    for x in range (len(x_values)):\n",
    "        for y in range (len(y_values)):\n",
    "            x_val = x_values[x]\n",
    "            y_val = y_values[y]\n",
    "            z = map.get((x_val,y_val))\n",
    "            if z is not None:\n",
    "                array[y][x] = z[1]\n",
    "\n",
    "    y_grad = np.zeros((len(y_values), len(x_values)))\n",
    "    x_grad = np.zeros((len(y_values), len(x_values)))\n",
    "    NMS_array = np.zeros(array.shape, dtype=object)\n",
    "\n",
    "    \n",
    "    y_grad = convolve(array,sobel_y)\n",
    "    x_grad = convolve(array,sobel_x)\n",
    "\n",
    "\n",
    "    for x in range (len(x_values)):\n",
    "        for y in range (len(y_values)):\n",
    "            Gx = x_grad[y][x]\n",
    "            Gy = y_grad[y][x]\n",
    "\n",
    "            Gtheta  = np.atan2(Gy,Gx) % np.pi\n",
    "            \n",
    "            theta = np.argmin(np.abs(Gtheta - angs))\n",
    "\n",
    "            NMS_array[y][x] = tuple((np.sqrt(Gx**2 + Gy**2),theta))\n",
    "\n",
    "    return_data = data.copy()\n",
    "\n",
    "\n",
    "    for x in range (1,len(x_values) - 1):\n",
    "        for y in range (1,len(y_values) - 1):\n",
    "            index = map.get((x_values[x],y_values[y]))\n",
    "            if index is not None:\n",
    "                i = index[0]\n",
    "                mag = (NMS_array[y][x])[0]\n",
    "                ang = (NMS_array[y][x])[1]\n",
    "                \n",
    "                if (ang == 0):\n",
    "                    n1 = (NMS_array[y][x + 1])[0]\n",
    "                    n2 = (NMS_array[y][x - 1])[0]\n",
    "                if (ang == 1):\n",
    "                    n1 = (NMS_array[y - 1][x - 1])[0]\n",
    "                    n2 = (NMS_array[y + 1][x + 1])[0]\n",
    "                if (ang == 2):\n",
    "                    n1 = (NMS_array[y + 1][x])[0]\n",
    "                    n2 = (NMS_array[y - 1][x])[0]\n",
    "                if (ang == 3):\n",
    "                    n1 = (NMS_array[y - 1][x + 1])[0]\n",
    "                    n2 = (NMS_array[y + 1][x - 1])[0]\n",
    "                if mag >= n1 and mag >= n2:\n",
    "                    return_data[i,2] = mag\n",
    "                else:\n",
    "                    return_data[i,2] = 0\n",
    "\n",
    "\n",
    "    return_data[:, 2] = np.where(return_data[:, 2] >= 2, 1,0)\n",
    "\n",
    "    #return_data[:, 2] = np.clip(return_data[:, 2], 0.1, 250)\n",
    "    \n",
    "    return return_data \n",
    "\n",
    "\n",
    "def get_hessian_dictionary(data):\n",
    "    hessian_dict = {}\n",
    "\n",
    "    kernel_xx = np.array([\n",
    "    [ 1, -2,  1],\n",
    "    [ 2, -4,  2],\n",
    "    [ 1, -2,  1]\n",
    "    ])\n",
    "    kernel_yy = np.array([\n",
    "    [ 1,  2,  1],\n",
    "    [-2, -4, -2],\n",
    "    [ 1,  2,  1]\n",
    "    ])\n",
    "    kernel_xy = np.array([\n",
    "    [ 0,  1,  0],\n",
    "    [ 1, -4,  1],\n",
    "    [ 0,  1,  0]\n",
    "    ])\n",
    "\n",
    "\n",
    "    x_values = np.unique(data[:,0])\n",
    "    y_values = np.unique(data[:,1])\n",
    "    array = np.zeros((len(y_values), len(x_values)))\n",
    "    map = {(row[0],row[1]): (index, row[2]) for index,row in enumerate(data)}\n",
    "\n",
    "    for x in range (len(x_values)):\n",
    "        for y in range (len(y_values)):\n",
    "            x_val = x_values[x]\n",
    "            y_val = y_values[y]\n",
    "            z = map.get((x_val,y_val))\n",
    "            if z is not None:\n",
    "                array[y][x] = z[1]\n",
    "\n",
    "    dxx = convolve(array,kernel_xx)\n",
    "    dyy = convolve(array,kernel_yy)\n",
    "    dxy = convolve(array,kernel_xy)\n",
    "\n",
    "\n",
    "    for x in range (len(x_values)):\n",
    "        for y in range (len(y_values)):\n",
    "            x_val = x_values[x]\n",
    "            y_val = y_values[y]\n",
    "            index = map.get((x_val,y_val))\n",
    "            if index is not None:\n",
    "                point_dxx = dxx[y][x]\n",
    "                point_dyy = dyy[y][x]\n",
    "                point_dxy = dxy[y][x]\n",
    "\n",
    "                hessian = np.array([[point_dxx, point_dxy], [point_dxy, point_dyy]])\n",
    "                eigens = np.linalg.eig(hessian)\n",
    "                hessian_dict[x_val,y_val] = eigens\n",
    "    \n",
    "    return hessian_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Get the paths of each part\n",
    "def find_parts(directory_path, str = \"AdaptiveZ_10mm\"):\n",
    "    parts_paths = []\n",
    "\n",
    "    for root, dirs, files in os.walk(directory_path):\n",
    "        for folder in dirs:\n",
    "            folder = os.path.join(root,folder)\n",
    "            if (str in folder) and folder.endswith(\"_4\"):\n",
    "                parts_paths.append(folder)\n",
    "    parts_paths.sort(reverse=True)\n",
    "    return parts_paths\n",
    "\n",
    "\n",
    "base_path = r\"\\\\192.168.1.100\\CoreScan3-2\\Acquisitions\\RnD\\XRF\\CH\\Macassa_clearance\"\n",
    "\n",
    "\n",
    "\n",
    "paths = find_parts(base_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Build the point cloud\n",
    "point_clouds = []\n",
    "\n",
    "global x_offset\n",
    "x_offset = 0\n",
    "\n",
    "for path in paths:\n",
    "    temp_cloud, x_start, x_stop = get_point_cloud(path)\n",
    "    x_offset -= x_stop\n",
    "    temp_cloud[:,0] += x_offset\n",
    "    x_offset += x_start\n",
    "    point_clouds.append(temp_cloud)\n",
    "   \n",
    "point_cloud = np.vstack(point_clouds)\n",
    "\n",
    "print(f\"total # of point {point_cloud.shape[0]}\")\n",
    "\n",
    "point_tree = KDTree(point_cloud[:,:2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#add to the point cloud\n",
    "#point_clouds = []\n",
    "#\n",
    "#for path in paths:\n",
    "#    temp_cloud, x_start, x_stop = get_point_cloud(path)\n",
    "#    x_offset -= x_stop\n",
    "#    temp_cloud[:,0] += x_offset\n",
    "#    x_offset += x_start\n",
    "#    point_clouds.append(temp_cloud)\n",
    "#\n",
    "#point_cloud_add = np.vstack(point_clouds)\n",
    "#point_cloud = np.concatenate((point_cloud,point_cloud_add))\n",
    "#\n",
    "#print(f\"total # of point {point_cloud.shape[0]}\")\n",
    "#\n",
    "#point_tree = KDTree(point_cloud[:,:2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create a convolved copy of the point_cloud\n",
    "\n",
    "kernels_y = []\n",
    "kernels_s = []\n",
    "kernels_x = []\n",
    "\n",
    "kernels_s.append(np.array([[1,2,1],[2,4,2],[1,2,1]]))\n",
    "kernels_y.append(np.array([[-1],[-2],[0],[2],[1]]))\n",
    "kernels_x.append(np.array([[-1,-2,0,2,1]]))\n",
    "\n",
    "\n",
    "point_cloud_convolved = convolve_data(point_cloud,kernels_y)\n",
    "\n",
    "point_cloud_edges = canny(convolve_data(point_cloud,kernels_s))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#further define border edges \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create a point_cloud with edges removed \n",
    "\n",
    "edge_indices = np.where(point_cloud_edges[:,2] == 1)[0]\n",
    "\n",
    "point_cloud_edgeless = point_cloud.copy()\n",
    "\n",
    "for i in edge_indices:\n",
    "    point_cloud_edgeless[i, 2] = np.nan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#fig = plt.figure(figsize=(500,10), dpi = 400)\n",
    "#\n",
    "#\n",
    "#gs = fig.add_gridspec(2, 1, hspace = 0.8)\n",
    "#\n",
    "#downsampled_indices = np.random.choice(point_cloud.shape[0], size=5000000, replace=False)\n",
    "#x_downsampled = point_cloud_edgeless[:, 0]\n",
    "#y_downsampled = point_cloud_edgeless[:, 1]\n",
    "#z_downsampled = point_cloud_edgeless[:, 2]\n",
    "#\n",
    "#\n",
    "#\n",
    "#\n",
    "#x_values = np.unique(point_cloud[:,0])\n",
    "#\n",
    "#ax_scatter = fig.add_subplot(gs[0,0])\n",
    "#\n",
    "#ax_scatter.scatter(\n",
    "#x_downsampled,\n",
    "#y_downsampled,\n",
    "#c=z_downsampled,\n",
    "#cmap='binary_r',  \n",
    "#s = 0.25\n",
    "#)\n",
    "#\n",
    "#\n",
    "#\n",
    "#\n",
    "#\n",
    "#ax_scatter.set_title('LIDAR data heatmap')\n",
    "#ax_scatter.set_xlabel('X-axis')\n",
    "#ax_scatter.set_ylabel('Y-axis')\n",
    "#\n",
    "#plt.show()\n",
    "#\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#initial clustering with the original point cloud\n",
    "\n",
    "# 0 = variance, 1 = skew, 2 = kurtosis, 3 = mean, 4 = polar\n",
    "\n",
    "\n",
    "x_values = np.unique(point_cloud[:,0])\n",
    "\n",
    "v_dict = get_vectors(point_cloud,point_tree,x_values, y_span = 10)\n",
    "v_array = np.array(list(v_dict.values()))\n",
    "print(v_array.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 0 = variance, 1 = skew, 2 = kurtosis, 3 = polar\n",
    "dimensions = [1,3] \n",
    "\n",
    "dbscan = DBSCAN(min_samples = 50, \n",
    "                metric = 'chebyshev', \n",
    "                eps = 0.054, \n",
    "                n_jobs = -1) \n",
    "\n",
    "labels1 = dbscan.fit_predict(v_array[:, dimensions])\n",
    "\n",
    "defined_indices = np.where(np.logical_or(labels1 == 0, labels1 == 2))[0]\n",
    "semi_defined_indices = np.where(labels1 == 1)[0]\n",
    "\n",
    "core_type_dictionary = {x: labels1[i] for i,x in enumerate(v_dict.keys())}\n",
    "\n",
    "fig = plt.figure(figsize=(10,4), dpi = 300)\n",
    "\n",
    "colors = [f\"C{label}\"  if label >= 0 else (0,1,1,1)  for label in labels1]\n",
    "\n",
    "gs = fig.add_gridspec(1, 1 )\n",
    "ax = fig.add_subplot(gs[0,0])\n",
    "\n",
    "\n",
    "\n",
    "x_vals = [v_dict[x][1] for x in v_dict.keys()]\n",
    "y_vals = [v_dict[x][3] for x in v_dict.keys()]\n",
    "ax.set_xlabel(\"skew\")\n",
    "ax.set_ylabel(\"Azimuthal angle\")\n",
    "\n",
    "\n",
    "ax.scatter(x_vals, y_vals, color=colors, s=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(150,15), dpi = 300)\n",
    "\n",
    "\n",
    "gs = fig.add_gridspec(2, 1, hspace = 0.8)\n",
    "\n",
    "downsampled_indices = np.random.choice(point_cloud.shape[0], size=1200000, replace=False)\n",
    "x1_downsampled = point_cloud[downsampled_indices, 0]\n",
    "y1_downsampled = point_cloud[downsampled_indices, 1]\n",
    "z1_downsampled = point_cloud[downsampled_indices, 2]\n",
    "\n",
    "\n",
    "\n",
    "downsampled_indices = np.where(point_cloud_edges[:,2] == 1)[0]\n",
    "\n",
    "print(len(downsampled_indices))\n",
    "\n",
    "x_downsampled = point_cloud_edges[downsampled_indices, 0]\n",
    "y_downsampled = point_cloud_edges[downsampled_indices, 1]\n",
    "z_downsampled = point_cloud_edges[downsampled_indices, 2]\n",
    "\n",
    "\n",
    "x_values = np.unique(point_cloud[:,0])\n",
    "\n",
    "ax_scatter = fig.add_subplot(gs[0,0])\n",
    "#ax_scatter.scatter(\n",
    "#x1_downsampled,\n",
    "#y1_downsampled,\n",
    "#c=z1_downsampled,\n",
    "#cmap='binary_r',  \n",
    "#s = 0.25\n",
    "#)\n",
    "\n",
    "ax_scatter.scatter(\n",
    "x_downsampled,\n",
    "y_downsampled,\n",
    "c=z_downsampled,\n",
    "cmap='binary_r',  \n",
    "s = 0.25\n",
    ")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "ax_scatter.set_title('LIDAR data heatmap')\n",
    "ax_scatter.set_xlabel('X-axis')\n",
    "ax_scatter.set_ylabel('Y-axis')\n",
    "\n",
    "ax_scatter.axhline(y=0.03, color='red', linestyle='-', label=\"Horizontal Line\")\n",
    "#bar_plot = fig.add_subplot(gs[1,0])\n",
    "#\n",
    "#\n",
    "#legend_labels = np.unique(labels1)\n",
    "#legend_colors = [f\"C{label}\"  if label >= 0 else (0,0,0,0) for label in legend_labels]\n",
    "#legend_handles = [mpatches.Patch(color=color, label=label) for label, color in zip(legend_labels, legend_colors)]\n",
    "#\n",
    "#bar_plot.bar(x_values, height=1.5, width=1.5, color=colors, edgecolor=\"none\")\n",
    "#\n",
    "#bar_plot.legend(handles=legend_handles, title=\"Core Type\", bbox_to_anchor=(1,1), loc=\"upper left\")\n",
    "#\n",
    "#bar_plot.set_title(\"Core Type by X-position\")\n",
    "#bar_plot.set_xlabel(\"X-Value\")\n",
    "#bar_plot.set_yticks([])\n",
    "#bar_plot.set_xticks(list(range(0, 31001, 1000)))\n",
    "#bar_plot.set_xticklabels(list(range(0, 31001, 1000)), rotation=70)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#getting convolved vectors from undefined indices\n",
    "\n",
    "x_values = [x for i, x in enumerate(v_dict.keys()) if i in semi_defined_indices]\n",
    "\n",
    "#x_values = np.unique(point_cloud[:,0])\n",
    "\n",
    "\n",
    "#v_dict_convolved = get_vectors_convolved(point_cloud_convolved, point_tree, x_values, y_span = 10)\n",
    "v_dict_convolved = get_vectors_combined(point_tree,point_cloud,point_cloud_convolved,x_values, y_span = 10)\n",
    "\n",
    "print (len(v_dict_convolved))\n",
    "v_array_convolved = np.array(list(v_dict_convolved.values()))\n",
    "\n",
    "#scaler = StandardScaler()\n",
    "#standardized_vectors = scaler.fit_transform(v_array2)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#secondary clustering\n",
    "dimensions = [3,4,8,10]\n",
    "hdbscan_refined = DBSCAN(min_samples = 45,\n",
    "                             metric = \"euclidean\",\n",
    "                             eps= 0.08,\n",
    "                             n_jobs=-1)\n",
    "\n",
    "labels = hdbscan_refined.fit_predict(v_array_convolved[:,dimensions])\n",
    "\n",
    "core_type_dictionary.update({x: 1 if labels[i] == 1 else -1 for i,x in enumerate(v_dict_convolved.keys())  })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(60,3), dpi = 150)\n",
    "\n",
    "gs = fig.add_gridspec(2, 1,)\n",
    "\n",
    "x_values = [x for i, x in enumerate(v_dict.keys()) if i in semi_defined_indices]\n",
    "\n",
    "\n",
    "colors = [f\"C{label}\"  if label >= 0 else \"black\"  for label in labels]\n",
    "\n",
    "bar_plot = fig.add_subplot(gs[1,0])\n",
    "\n",
    "\n",
    "legend_labels = np.unique(labels)\n",
    "legend_colors = [f\"C{label}\"  if label >= 0 else \"black\" for label in legend_labels]\n",
    "legend_handles = [mpatches.Patch(color=color, label=label) for label, color in zip(legend_labels, legend_colors)]\n",
    "\n",
    "bar_plot.bar(x_values, height=1.5, width=1.5, color=colors, edgecolor=\"none\")\n",
    "\n",
    "bar_plot.legend(handles=legend_handles, title=\"Core Type\", bbox_to_anchor=(1,1), loc=\"upper left\")\n",
    "\n",
    "bar_plot.set_title(\"Core Type by X-position\")\n",
    "bar_plot.set_xlabel(\"X-Value\")\n",
    "bar_plot.set_yticks([])\n",
    "bar_plot.set_xticks(list(range(0, 31001, 1000)))\n",
    "bar_plot.set_xticklabels(list(range(0, 31001, 1000)), rotation=70)\n",
    "\n",
    "ax = fig.add_subplot(gs[0,0])\n",
    "\n",
    "\n",
    "\n",
    "x_vals = [x for x in v_dict_convolved.keys()]\n",
    "y_vals = [v_dict_convolved[x][4] for x in v_dict_convolved.keys()]\n",
    "\n",
    "ax.scatter(x_vals, y_vals, color=colors, s=1)\n",
    "ax.set_xticks(list(range(0, 31001, 1000)))\n",
    "ax.set_xticklabels(list(range(0, 31001, 1000)), rotation=70)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectors = np.array(list(v_dict_convolved.values()))\n",
    "x = vectors[:,3]\n",
    "y = vectors[:,10]\n",
    "z = vectors[:,8]\n",
    "\n",
    "\n",
    "fig = go.Figure(data=[go.Scatter3d(\n",
    "    x=x, y=y, z=z,\n",
    "    mode='markers',\n",
    "    marker=dict(size=1.3, color=labels, opacity=1),\n",
    ")])\n",
    "\n",
    "fig.update_layout(\n",
    "    title=\"3D Scatter of Vectors\",\n",
    "    scene=dict(\n",
    "        xaxis_title=\"mean\",\n",
    "        yaxis_title=\"skew\",\n",
    "        zaxis_title=\"azimuthal angle\",\n",
    "        camera=dict(projection=dict(type=\"orthographic\"))\n",
    "    ),\n",
    "    width=1000,\n",
    "    height=1000\n",
    ")\n",
    "\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "fig = plt.figure(figsize=(150,3), dpi = 500)\n",
    "\n",
    "core_types = list(core_type_dictionary.values())\n",
    "x_positions = list(core_type_dictionary.keys())\n",
    "\n",
    "colors2 = [f\"C{type}\" if type >= 0  else (1,1,0,1)  for type in core_types]\n",
    "\n",
    "ax = fig.add_subplot(111)\n",
    "\n",
    "\n",
    "ax.scatter( point_cloud[:, 0], point_cloud[:, 1], c=point_cloud[:, 2], cmap='binary', s=0.09, alpha = 0.8)\n",
    "ax.bar(x_positions, height=20, width= 0.75, color=colors2, edgecolor=\"none\", bottom = -10, alpha = 0.45)\n",
    "\n",
    "\n",
    "\n",
    "legend_labels2 = np.unique(core_types)\n",
    "\n",
    "\n",
    "legend_colors2 = [f\"C{label}\"  if label >= 0  else (1,1,0,1) for label in legend_labels2 ]\n",
    "legend_handles2 = [mpatches.Patch(color=color, label = (\n",
    "                                    \"half\" if label == 0 else \n",
    "                                    \"empty\" if label == 2 else \n",
    "                                    \"full\" if label == 1 else \n",
    "                                    label \n",
    "                                    )) for label, color in zip(legend_labels2, legend_colors2)]\n",
    "\n",
    "ax.set_xticks(list(range(0, 31001, 500)))\n",
    "ax.set_xticklabels(list(range(0, 31001, 500)), rotation=70)\n",
    "ax.legend(handles=legend_handles2, title=\"Core Type\", bbox_to_anchor=(1,1), loc=\"upper left\")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#window_size = 7.5\n",
    "#\n",
    "#core_type_dictionary_denoised = {}\n",
    "#\n",
    "#for x in core_type_dictionary.keys():\n",
    "#    neighbours = np.unique(point_cloud[point_tree.query_ball_point((x,0), window_size),0])\n",
    "#    try:\n",
    "#         counts = Counter(core_type_dictionary[xi] for xi in neighbours)\n",
    "#    except Exception:\n",
    "#         print(\"bad index\")\n",
    "#         pass\n",
    "#    core_type_dictionary_denoised[x] = counts.most_common(1)[0][0]\n",
    "#\n",
    "#fig = plt.figure(figsize=(150,3), dpi = 500)\n",
    "#\n",
    "#\n",
    "#\n",
    "#\n",
    "#\n",
    "#center_y = point_cloud[np.abs(point_cloud[:, 1]).argmin(),1]\n",
    "#\n",
    "#mask_y = point_cloud_edges[:, 1] == center_y\n",
    "#\n",
    "#\n",
    "#\n",
    "#indices = np.where(mask_y)[0] \n",
    "#indices = sorted(indices, key = lambda i: point_cloud_edges[i,0])\n",
    "#\n",
    "#\n",
    "#edge_indices = np.where(point_cloud_edges[indices,2] == 1)[0]\n",
    "#\n",
    "#\n",
    "#\n",
    "#\n",
    "#for i_start, i_stop in zip(edge_indices, edge_indices[1:]):\n",
    "#   \n",
    "#    x_start = point_cloud_edges[indices[i_start],0]\n",
    "#    x_stop = point_cloud_edges[indices[i_stop],0]\n",
    "#\n",
    "#   \n",
    "#    \n",
    "#    if ((x_stop - x_start) >= 10):\n",
    "#        keys = point_cloud_edges[indices[i_start:i_stop],0]\n",
    "#        values = [core_type_dictionary_denoised[key] for key in keys]\n",
    "#        mode_value = mode(values)[0]\n",
    "#        for key in keys:\n",
    "#            core_type_dictionary_denoised[key] = mode_value\n",
    "#    else:\n",
    "#        for key in keys:\n",
    "#            core_type_dictionary_denoised[key] = -1\n",
    "#        \n",
    "#\n",
    "#\n",
    "#\n",
    "#core_types = list(core_type_dictionary_denoised.values())\n",
    "#x_positions = list(core_type_dictionary_denoised.keys())\n",
    "#\n",
    "#colors2 = [f\"C{type}\" if type >= 0  else (1,1,0,1)  for type in core_types]\n",
    "#\n",
    "#ax = fig.add_subplot(111)\n",
    "#\n",
    "#\n",
    "#ax.scatter( point_cloud[:, 0], point_cloud[:, 1], c=point_cloud[:, 2], cmap='binary', s=0.09, alpha = 0.8)\n",
    "#ax.bar(x_positions, height=20, width= 1, color=colors2, edgecolor=\"none\", bottom = -10, alpha = 0.45)\n",
    "#\n",
    "#\n",
    "#\n",
    "#legend_labels2 = np.unique(core_types)\n",
    "#\n",
    "#\n",
    "#legend_colors2 = [f\"C{label}\"  if label >= 0  else (1,1,0,1) for label in legend_labels2 ]\n",
    "#legend_handles2 = [mpatches.Patch(color=color, label = (\n",
    "#                                    \"half\" if label == 0 else \n",
    "#                                    \"empty\" if label == 2 else \n",
    "#                                    \"full\" if label == 4 else \n",
    "#                                    label \n",
    "#                                    )) for label, color in zip(legend_labels2, legend_colors2)]\n",
    "#\n",
    "#ax.set_xticks(list(range(0, 31001, 500)))\n",
    "#ax.set_xticklabels(list(range(0, 31001, 500)), rotation=70)\n",
    "#ax.legend(handles=legend_handles2, title=\"Core Type\", bbox_to_anchor=(1,1), loc=\"upper left\")\n",
    "#\n",
    "#plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "core_type_windows = core_type_dictionary.copy()\n",
    "\n",
    "center_y = point_cloud[np.abs(point_cloud[:, 1]).argmin(),1]\n",
    "\n",
    "mask_y = point_cloud_edges[:, 1] == center_y\n",
    "\n",
    "\n",
    "\n",
    "indices = np.where(mask_y)[0] \n",
    "indices = sorted(indices, key = lambda i: point_cloud_edges[i,0])\n",
    "\n",
    "edge_indices = np.where(point_cloud_edges[indices,2] == 1)[0]\n",
    "\n",
    "x_values = point_cloud_edges[indices,0]\n",
    "x_values = x_values[edge_indices]\n",
    "\n",
    "window_dict = {}\n",
    "\n",
    "rubble_windows = []\n",
    "\n",
    "\n",
    "for i_start, i_stop in zip(edge_indices, edge_indices[1:]):\n",
    "      \n",
    "    x_start = point_cloud_edges[indices[i_start],0]\n",
    "    x_stop = point_cloud_edges[indices[i_stop],0]\n",
    "\n",
    "    keys = point_cloud_edges[indices[i_start + 1:i_stop],0]\n",
    "\n",
    "    if ((x_stop - x_start) >= 10):\n",
    "        values = [core_type_windows[key] for key in keys]\n",
    "        mode_value = mode(values)[0]\n",
    "        window_dict[int(i_start)] = int(mode_value)\n",
    "    else:\n",
    "        window_dict[int(i_start)] = -1\n",
    "\n",
    "\n",
    "keys_to_remove = []\n",
    "\n",
    "for index1, index2 in zip(list(window_dict.keys()), list(window_dict.keys())[1:]):\n",
    "    type1 = window_dict[index1]\n",
    "    type2 = window_dict[index2]\n",
    "\n",
    "    if type1 == -1 and type2 == -1:\n",
    "        keys_to_remove.append(index2)\n",
    "\n",
    "for key in keys_to_remove:\n",
    "    del window_dict[key]\n",
    "\n",
    "for (i_start,i_stop) in zip(list(window_dict.keys()), list(window_dict.keys())[1:]):\n",
    "\n",
    "    core_type = window_dict[i_start]\n",
    "\n",
    "    keys = point_cloud_edges[indices[i_start + 1:i_stop],0]\n",
    "\n",
    "    if core_type == -1:\n",
    "        x_start = point_cloud_edges[indices[i_start],0]\n",
    "        x_stop = point_cloud_edges[indices[i_stop],0]\n",
    "        rubble_windows.append((x_start, x_stop)) \n",
    "\n",
    "\n",
    "    for key in keys:\n",
    "        if key not in x_values:\n",
    "            core_type_windows[key] = core_type\n",
    "\n",
    "\n",
    "fig = plt.figure(figsize=(200,3), dpi = 300)\n",
    "\n",
    "\n",
    "gs = fig.add_gridspec(1, 1, hspace = 0.8)\n",
    "\n",
    "downsampled_indices = np.random.choice(point_cloud.shape[0], size=90000, replace=False)\n",
    "\n",
    "x_downsampled = point_cloud[:, 0]\n",
    "y_downsampled = point_cloud[:, 1]\n",
    "z_downsampled = point_cloud[:, 2]\n",
    "\n",
    "\n",
    "ax_scatter = fig.add_subplot(gs[0,0])\n",
    "ax_scatter.scatter(\n",
    "x_downsampled,\n",
    "y_downsampled,\n",
    "c=z_downsampled,\n",
    "cmap='binary_r',\n",
    "s = 0.25\n",
    ")\n",
    "\n",
    "core_types = list(core_type_windows.values())\n",
    "x_positions = list(core_type_windows.keys())\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "ax_scatter.set_title('LIDAR data heatmap')\n",
    "ax_scatter.set_xlabel('X-axis')\n",
    "ax_scatter.set_ylabel('Y-axis')\n",
    "\n",
    "\n",
    "\n",
    "legend_labels = np.unique(core_types)\n",
    "legend_colors = [f\"C{label}\"  if label >= 0 else (0,1,1,1) for label in core_types]\n",
    "legend_handles = [mpatches.Patch(color=color, label=label) for label, color in zip(legend_labels, legend_colors)]\n",
    "\n",
    "ax_scatter.bar(x_positions, height=20, width=1, color=legend_colors, edgecolor=\"none\", bottom = -10, alpha = 0.4)\n",
    "\n",
    "ax_scatter.legend(handles=legend_handles, title=\"Core Type\", bbox_to_anchor=(1,1), loc=\"upper left\")\n",
    "\n",
    "plt.show()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(x_positions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(rubble_windows)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#h_dict = get_hessian_dictionary(point_cloud)\n",
    "#\n",
    "#\n",
    "#\n",
    "#eigens = h_dict.values()\n",
    "#\n",
    "#scaled_eigenvectors = []\n",
    "#\n",
    "#for eigenvalues, eigenvectors in eigens:\n",
    "#    scaled_vectors = eigenvectors * eigenvalues[:, np.newaxis]  \n",
    "#    scaled_eigenvectors.append(scaled_vectors)\n",
    "#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#x = np.concatenate([scaled_vec[0] for scaled_vec in scaled_eigenvectors])\n",
    "#y = np.concatenate([scaled_vec[1] for scaled_vec in scaled_eigenvectors])\n",
    "#\n",
    "#fig = go.Figure(data=[go.Scatter3d(\n",
    "#    x=x, y=y,\n",
    "#    mode='markers',\n",
    "#    marker=dict(size=1.3, opacity=1),\n",
    "#)])\n",
    "#\n",
    "#fig.update_layout(\n",
    "#    title=\"3D Scatter of Vectors by Core Type\",\n",
    "#    scene=dict(\n",
    "#        xaxis_title=\"0\",\n",
    "#        yaxis_title=\"1\",\n",
    "#        zaxis_title=\"2\",\n",
    "#        camera=dict(projection=dict(type=\"orthographic\"))\n",
    "#    ),\n",
    "#    width=1000,\n",
    "#    height=1000\n",
    "#)\n",
    "#\n",
    "#fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the directory where the LIDAR scans are located\n",
    "# lidar_scan_dir = r\"C:\\Users\\mcastillo\\gitlocal\\xray_spot\\data\\test_new_setup\\calibration_xray\\Core_000_Box_000_of_000_Pass_007\"\n",
    "# lidar_scan_dir = r\"\\\\192.168.1.100\\CoreScan3-2\\Acquisitions\\RnD\\XRF_SPOT\\AI21\\xray2lidar\\Core_000_Box_000_of_000_Pass_019\"\n",
    "lidar_scan_dir = r\"\\\\192.168.1.100\\CoreScan3-2\\Acquisitions\\Trailer-Calibration-Scans-DO-NOT-MOVE-OR-DELETE\\AI21\\Macassa3.5\\AI21-Dec27-2024\\Core_000_Box_005_of_999_Part_5_of_6\"\n",
    " \n",
    "# Load the point cloud from the LIDAR scan\n",
    "lidar_filename, point_cloud, intensity_map = load_point_cloud(lidar_scan_dir)\n",
    " \n",
    "# Create a scatter plot of the point cloud\n",
    "fig, ax = plt.subplots(1, 1, figsize=(10, 5))\n",
    "ax = display_scatter(point_cloud, ax=ax)\n",
    " \n",
    "# Read the configuration for the LIDAR scan\n",
    "conf = read_component_conf(scan_dir=lidar_scan_dir)\n",
    " \n",
    "# Get the starting Y coordinate for the LIDAR scan\n",
    "y_offset = float(conf['LIDAR_CAMERA']['Acquisition']['Y.Start'])\n",
    "print(f\"Y offset {y_offset}\")\n",
    " \n",
    "# Render the LIDAR scan to an image\n",
    "Tr_lidar2render, lidar_render, inpaint_mask, lidar_render_inpaint, (x_min, y_min, z_min), (x_max, y_max, z_max), reset_mask = render_lidar(point_cloud, flip_x = True, flip_y=True, inpaint_size = 10, clean_nan=True)\n",
    " \n",
    "# Render the intensity map image from the LIDAR scan\n",
    "intensity_img = render_lidar_intensity_map(point_cloud, intensity_map, Tr_lidar2render, (lidar_render.shape[1], lidar_render.shape[0]))\n",
    " \n",
    "# Display the rendered LIDAR scan and the intensity map image\n",
    "fig, axes = plt.subplots(1, 2, figsize=(10, 10))\n",
    " \n",
    "# Display the rendered LIDAR scan in the first subplot\n",
    "axes[0].imshow(lidar_render_inpaint)\n",
    " \n",
    "# Display the intensity map image in the second subplot\n",
    "axes[1].imshow(intensity_img)\n",
    " \n",
    "# Print lidar2render\n",
    "print(Tr_lidar2render)\n",
    " "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
