{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import csv\n",
    "import cv2\n",
    "import time\n",
    "import gc\n",
    "import matplotlib.pyplot    as plt\n",
    "import numpy                as np\n",
    "import plotly.graph_objects as go\n",
    "from scipy.stats        import skew, kurtosis\n",
    "from scipy.ndimage      import convolve\n",
    "from scipy.interpolate  import interp1d\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#vars\n",
    "name, heights, convolved_heights, intensity, x_to_i, i_to_x, y_to_i, i_to_y, sectioned = 0,1,2,3,4,5,6,7,8\n",
    "\n",
    "window_height = 10\n",
    "\n",
    "plot_clouds = False\n",
    "plot_cluster_1 = True\n",
    "plot_cluster_2 = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#functions\n",
    "def get_vectors(data, y_span=window_height):\n",
    "    vectors = []  \n",
    "    start_time = time.perf_counter()\n",
    "\n",
    "    def log(message):\n",
    "        elapsed = time.perf_counter() - start_time\n",
    "        print(f\"[{elapsed:.6f}s] {message}\")\n",
    "    gc.disable()\n",
    "\n",
    "    for point_cloud in data:\n",
    "        start_time = time.perf_counter()\n",
    "        \n",
    "        cloud = point_cloud[heights]\n",
    "        convolved_cloud = point_cloud[convolved_heights]\n",
    "        \n",
    "        y_to_i_list = point_cloud[y_to_i]\n",
    "        y_indices = [y_to_i_list[value] for value in y_to_i_list.keys() if abs(value) <= y_span]\n",
    "\n",
    "        for i in range(cloud.shape[1]):\n",
    "            distribution = cloud[y_indices, i]\n",
    "            convolved_distribution = convolved_cloud[y_indices, i]\n",
    "\n",
    "            properties = get_props(distribution)\n",
    "            convolved_properties = get_props_convolved(convolved_distribution)\n",
    "\n",
    "            vector = convolved_properties + properties\n",
    "\n",
    "            if not np.any(np.isnan(vector)):\n",
    "                vectors.append(vector)\n",
    "        log(f\"{point_cloud[0]} vectors added\")    \n",
    "    gc.enable()\n",
    "\n",
    "    return vectors\n",
    "\n",
    "def get_props_convolved(distribution):\n",
    "    properties = []\n",
    "\n",
    "    mean = np.sqrt(np.mean(distribution))\n",
    "    max = np.sqrt(np.max(distribution))\n",
    "\n",
    "    properties.append(mean)\n",
    "    properties.append(max)\n",
    "\n",
    "    return properties\n",
    "\n",
    "def get_props(distribution):\n",
    "    properties = []\n",
    "    return_properties = []\n",
    "\n",
    "    variance =  np.var(distribution) * ((10/window_height)**2)\n",
    "    skw = skew(distribution)\n",
    "    kurt = kurtosis(distribution)\n",
    "\n",
    "    \n",
    "    properties.append(variance)\n",
    "    properties.append(skw)\n",
    "    properties.append(kurt)\n",
    "\n",
    "    norm = np.linalg.norm(properties)\n",
    "    \n",
    "    if norm > 0:\n",
    "        properties = [x / norm for x in properties]\n",
    "\n",
    "    z = properties[0]\n",
    "\n",
    "    return_properties.append(properties[1])\n",
    "    return_properties.append(np.arccos(z)/(np.pi/2))\n",
    "\n",
    "    return return_properties\n",
    "\n",
    "def interpolate_x(table_file,lidar_file):\n",
    "    with open(table_file) as file:\n",
    "        lines = file.readlines()\n",
    "\n",
    "        positions = []\n",
    "        table_timestamps = []\n",
    "\n",
    "        char = '-'\n",
    "\n",
    "        for line in lines:\n",
    "            if (\"+\") in line:\n",
    "                char = '+'\n",
    "            time = line.split('T')[1]\n",
    "            x = float(line.split(',')[0])\n",
    "            parts = time.split(':')\n",
    "            t = float(parts[0]) * 3600 + float(parts[1]) * 60 + float(parts[2].split(char)[0]) \n",
    "            positions.append(x)\n",
    "            table_timestamps.append(t)\n",
    "\n",
    "    ordered_positions = []\n",
    "    ordered_timestamps = []\n",
    "    if char == '-':\n",
    "        for i in range(len(positions)-1):\n",
    "            if positions[i + 1] < positions[i]:\n",
    "                ordered_positions.append(positions[i])\n",
    "                ordered_timestamps.append(table_timestamps[i])\n",
    "\n",
    "    if char == '+':\n",
    "         for i in range(len(positions)-1):\n",
    "            if positions[i + 1] > positions[i]:\n",
    "                ordered_positions.append(positions[i])\n",
    "                ordered_timestamps.append(table_timestamps[i])\n",
    "\n",
    "\n",
    "    with open(lidar_file) as file:\n",
    "        lines = file.readlines()\n",
    "\n",
    "        lidar_timestamps = []\n",
    "\n",
    "        time = lines[0].split('T')[1]\n",
    "        parts = time.split(':')\n",
    "        min_t = float(parts[1]) * 60  + float(parts[0]) * 3600 + float(parts[2].split(char)[0]) \n",
    "\n",
    "        for line in lines:\n",
    "            time = line.split('T')[1]\n",
    "            parts = time.split(':')\n",
    "            t = float(parts[0]) * 3600 + float(parts[1]) * 60 + float(parts[2].split(char)[0]) - min_t\n",
    "            lidar_timestamps.append(t)\n",
    "\n",
    "\n",
    "    lidar_timestamps = np.array(lidar_timestamps)\n",
    "    lidar_timestamps_rounded = np.round(lidar_timestamps/0.02)*0.02\n",
    "    ordered_timestamps = np.array(ordered_timestamps)[::-1]\n",
    "    ordered_timestamps -= min_t\n",
    "    ordered_positions = ordered_positions[::-1]\n",
    "\n",
    "    ordered_timestamps = np.concatenate([ordered_timestamps[:2], ordered_timestamps[-2:]])\n",
    "    ordered_positions = np.concatenate([ordered_positions[:2], ordered_positions[-2:]])\n",
    "\n",
    "    interp_func = interp1d(ordered_timestamps, ordered_positions, kind=\"linear\", fill_value=(ordered_positions[-1], ordered_positions[0]), bounds_error=False) \n",
    "\n",
    "    interpolated = interp_func(lidar_timestamps)\n",
    "            \n",
    "    return interpolated\n",
    "\n",
    "def get_point_cloud(paths, y_window = window_height + 5, upsample_ratio = 2):\n",
    "    print(\"loading\",end = \"... \")\n",
    "\n",
    "    x_start = 5000\n",
    "    x_stop = 0\n",
    "\n",
    "    with open(paths[1]) as file:\n",
    "            lines = file.readlines()\n",
    "            for line in lines:\n",
    "                if \"XRAY_DPP[Acquisition]#0.X.Start:\" in line:\n",
    "                    x_start = (float)(line.split(\"XRAY_DPP[Acquisition]#0.X.Start:\")[1].strip())\n",
    "                if \"XRAY_DPP[Acquisition]#0.X.Stop:\" in line:\n",
    "                    x_stop = (float)(line.split(\"XRAY_DPP[Acquisition]#0.X.Stop:\")[1].strip())\n",
    "                if \"XRAY_DPP[Acquisition]#0.Y.Start:\" in line:\n",
    "                    y_offset = (float)(line.split(\"XRAY_DPP[Acquisition]#0.Y.Start:\")[1].strip())\n",
    "                    print(f\"y_offset: {y_offset}\")\n",
    "\n",
    "    with open(paths[2]) as file:\n",
    "        lines = file.readlines()\n",
    "        transformation_matrix = np.array([list(map(float, line.strip().split(\",\"))) for line in lines])\n",
    "\n",
    "    imread = lambda fn: cv2.imread(fn, cv2.IMREAD_ANYDEPTH)\n",
    "    \n",
    "    point_cloud  = np.fromfile(paths[3], dtype=np.float32).reshape(-1, 3) \n",
    "\n",
    "    #interpolated_x = interpolate_x(paths[5],paths[6])\n",
    "    #interpolated_x = np.repeat(interpolated_x, len(np.unique(point_cloud[:, 1])))\n",
    "\n",
    "    #point_cloud[:,0] = interpolated_x\n",
    "\n",
    "    intensity_map = imread(paths[4])\n",
    "    \n",
    "    print(f\"{paths[0]} loaded, {point_cloud.shape[0]} points\")\n",
    "    print(\"trimming\",end = \"... \")\n",
    "    \n",
    "    intensity_values = np.reshape(intensity_map, (-1, 1))\n",
    "    intensity_cloud = np.hstack((point_cloud[:,:2], intensity_values))\n",
    "\n",
    "    point_cloud = (np.hstack((point_cloud, np.ones((point_cloud.shape[0], 1)))) @ transformation_matrix.T)[:,:3]\n",
    "    intensity_cloud = (np.hstack((intensity_cloud, np.ones((intensity_cloud.shape[0], 1)))) @ transformation_matrix.T)[:,:3]\n",
    "\n",
    "    mask = (point_cloud[:,0] <= x_start) & (point_cloud[:,0] >= x_stop) & ((np.abs(point_cloud[:,1])) <= y_window)\n",
    "    point_cloud = point_cloud[mask]\n",
    "    intensity_cloud = intensity_cloud[mask]\n",
    "\n",
    "    min_intensity = np.nanmax(intensity_cloud[:,2])\n",
    "    min_z = np.nanmax(point_cloud[:,2])\n",
    "    \n",
    "    print(f\"trimmed to {point_cloud.shape[0]} points\")\n",
    "\n",
    "    print(\"converting to arrays\",end = \"... \")\n",
    "\n",
    "    minimum_x = point_cloud[np.argmin(np.abs(point_cloud[:,0] - x_stop)),0]\n",
    "\n",
    "    point_cloud[:,0] -= minimum_x\n",
    "    intensity_cloud[:,0] -= minimum_x\n",
    "    \n",
    "    x_values = np.unique(point_cloud[:,0])\n",
    "    y_values = np.unique(point_cloud[:,1]) \n",
    "\n",
    "    x_range = len(x_values)\n",
    "\n",
    "    if upsample_ratio > 1:\n",
    "        index_step = (np.nanmean(np.diff(x_values))) / upsample_ratio \n",
    "        index_steps = np.arange(int(round(np.nanmax(x_values)/index_step))+1) * index_step\n",
    "\n",
    "        x_range = len(index_steps)\n",
    "        x_value_dict = {x: np.argmin(np.abs(index_steps - x)) for x in x_values}\n",
    "        known_indices = list(x_value_dict.values())\n",
    "        known_x_values = np.array(list(x_value_dict.keys()), dtype=float)\n",
    "        all_indices = np.arange(x_range)\n",
    "\n",
    "        interp_func = interp1d(known_indices, known_x_values, kind=\"linear\", fill_value=\"extrapolate\")\n",
    "        x_values = interp_func(all_indices)\n",
    "    \n",
    "    x_value_dict = {x: index for index,x in enumerate(x_values)}\n",
    "    y_value_dict = {y: index for index,y in enumerate(y_values)}\n",
    "\n",
    "    point_array = np.full((len(y_values), x_range),np.nan)\n",
    "    intensity_array = np.full((len(y_values), x_range),np.nan)\n",
    "    point_dictionary = {(row[0],row[1]): (index, row[2]) for index,row in enumerate(point_cloud)}\n",
    "    intensity_dictionary = {(row[0],row[1]): (index, row[2]) for index,row in enumerate(intensity_cloud)}\n",
    "\n",
    "    for x in range (x_range):\n",
    "        for y in range (len(y_values)):\n",
    "            x_val = x_values[x]\n",
    "            y_val = y_values[y]\n",
    "\n",
    "            point_z = point_dictionary.get((x_val,y_val))\n",
    "            intensity_z = intensity_dictionary.get((x_val,y_val))\n",
    "\n",
    "            if point_z is not None:\n",
    "                point_array[y,x] = point_z[1]\n",
    "            else:\n",
    "                point_array[y,x] = min_z\n",
    "            if intensity_z is not None:\n",
    "                intensity_array[y,x] = intensity_z[1]\n",
    "            else:\n",
    "                intensity_array[y,x] = min_intensity\n",
    "\n",
    "    print(f\"arrays built\")\n",
    "    if upsample_ratio > 1:\n",
    "        print(\"upsampling\",end = \"... \")\n",
    "\n",
    "        for y in range(len(y_values)):\n",
    "\n",
    "            interpolated_z_values= []\n",
    "            interpolated_i_values = []\n",
    "\n",
    "            for dy in [-1,0,1]:\n",
    "                y_dy = y + dy\n",
    "                if (y_dy >= 0) & (y_dy < len(y_values)):\n",
    "                    known_z = point_array[y_dy,known_indices]\n",
    "                    known_i = intensity_array[y_dy,known_indices]\n",
    "                    known_x = x_values[known_indices]\n",
    "                    mask = ~np.isnan(known_z)\n",
    "                    z_interp = interp1d(known_x[mask], known_z[mask], kind='linear', fill_value=\"extrapolate\")\n",
    "                    i_interp = interp1d(known_x[mask], known_i[mask], kind='linear', fill_value=\"extrapolate\")\n",
    "\n",
    "                    interpolated_z_values.append(z_interp(x_values))\n",
    "                    interpolated_i_values.append(i_interp(x_values))\n",
    "\n",
    "            point_array[y, :] = np.mean(interpolated_z_values, axis=0)\n",
    "            intensity_array[y, :] = np.mean(interpolated_i_values, axis=0)\n",
    "    \n",
    "    intensity_array = np.log(np.abs(intensity_array))\n",
    "    kernel_y = np.array([[-1],[-2],[0],[2],[1]])\n",
    "    convolved_array = np.abs(convolve(point_array,kernel_y))\n",
    "\n",
    "    print(f\"upsampled to {point_array.size} points\")\n",
    "    print(f\"{paths[0]} finished \\n\")\n",
    "\n",
    "    return [paths[0],point_array, convolved_array, intensity_array, x_value_dict, x_values, y_value_dict, y_values]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#define parsers\n",
    "class MacassaFileParser:\n",
    "    def __init__(self, root_dir):\n",
    "        self.root_dir = root_dir\n",
    "        self.box_folders = []\n",
    "\n",
    "    def find_folders(self):\n",
    "        for root, dirs, files in os.walk(self.root_dir):\n",
    "                for dir_name in dirs:\n",
    "                    for i in range(10,11):\n",
    "                        if dir_name.startswith(f\"AdaptiveZ_{i}mm\"):\n",
    "                            folder = os.path.join(root, dir_name)\n",
    "                            if os.path.isdir(folder): \n",
    "                                for part_folder in os.listdir(folder):\n",
    "                                    part_folder = os.path.join(dir_name,part_folder)\n",
    "                                    full_part_path = os.path.join(root, part_folder)\n",
    "                                    if os.path.isdir(full_part_path) and \"Part\" in part_folder:\n",
    "                                        component_parameters_path = None\n",
    "                                        lidar2xrf_path = None\n",
    "                                        bpc_path = None\n",
    "                                        intensity_path = None\n",
    "                                        real_dbg_path = None\n",
    "                                        lidar_times_path = None\n",
    "                                        for file_name in os.listdir(full_part_path):\n",
    "                                            if file_name.endswith(\".component_parameters.txt\"):\n",
    "                                                component_parameters_path = os.path.join(full_part_path, file_name)\n",
    "                                            elif file_name.endswith(\".lidar2xrf\"):\n",
    "                                                lidar2xrf_path = os.path.join(full_part_path, file_name)\n",
    "                                            elif file_name.endswith(\".bpc\"):\n",
    "                                                bpc_path = os.path.join(full_part_path, file_name)\n",
    "                                            elif file_name.endswith(\"_intensity.png\"):\n",
    "                                                intensity_path = os.path.join(full_part_path, file_name)\n",
    "                                            elif file_name.endswith(\"real.dbg\"):\n",
    "                                                real_dbg_path = os.path.join(full_part_path, file_name)\n",
    "                                            elif file_name.endswith(\".dbg\"):\n",
    "                                                lidar_times_path = os.path.join(full_part_path, file_name)\n",
    "\n",
    "                                        self.box_folders.append((part_folder,component_parameters_path, lidar2xrf_path, bpc_path, intensity_path, real_dbg_path, lidar_times_path))\n",
    "\n",
    "\n",
    "    def get_box_folders(self):\n",
    "        self.find_folders()\n",
    "        return self.box_folders\n",
    "    \n",
    "class BasicParser:\n",
    "    def __init__(self, root_dir):\n",
    "        self.root_dir = root_dir\n",
    "        self.box_folders = []\n",
    "\n",
    "    def find_folders(self):\n",
    "        for root, dirs, files in os.walk(self.root_dir):\n",
    "                for dir_name in dirs:\n",
    "                    if dir_name.startswith(\"Core\"):\n",
    "                        folder = os.path.join(root,dir_name)\n",
    "                      \n",
    "                        if os.path.isdir(folder) and \"0\" in folder:\n",
    "                            component_parameters_path = None\n",
    "                            lidar2xrf_path = None\n",
    "                            bpc_path = None\n",
    "                            intensity_path = None\n",
    "                            real_dbg_path = None\n",
    "                            lidar_times_path = None\n",
    "                            for file_name in os.listdir(folder):\n",
    "                                if file_name.endswith(\".component_parameters.txt\"):\n",
    "                                    component_parameters_path = os.path.join(folder, file_name)\n",
    "                                elif file_name.endswith(\".lidar2xrf\"):\n",
    "                                    lidar2xrf_path = os.path.join(folder, file_name)\n",
    "                                elif file_name.endswith(\".bpc\"):\n",
    "                                    bpc_path = os.path.join(folder, file_name)\n",
    "                                elif file_name.endswith(\"_intensity.png\"):\n",
    "                                    intensity_path = os.path.join(folder, file_name)\n",
    "                                elif file_name.endswith(\"real.dbg\"):\n",
    "                                    real_dbg_path = os.path.join(folder, file_name)\n",
    "                                elif file_name.endswith(\".dbg\"):\n",
    "                                    lidar_times_path = os.path.join(folder, file_name)\n",
    "\n",
    "                            self.box_folders.append((folder,component_parameters_path, lidar2xrf_path, bpc_path, intensity_path, real_dbg_path, lidar_times_path))\n",
    "\n",
    "\n",
    "    def get_box_folders(self):\n",
    "        self.find_folders()\n",
    "        return self.box_folders\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#choose and use parser\n",
    "parser = MacassaFileParser(r\"C:\\Users\\edwar\\Desktop\\local macassa\")\n",
    "parser = BasicParser(r\"C:\\Users\\eashenhurst\\Desktop\\local scans\\test_csv_core\")\n",
    "paths_list = parser.get_box_folders()\n",
    "\n",
    "for name, component_parameters_path, lidar2xrf_path, bpc_path, intensity_path, real_dbg_path, lidar_times_path  in paths_list:\n",
    "    print(f\"Part: {name}\")\n",
    "    if component_parameters_path:\n",
    "        print(f\"  Component Parameters: {component_parameters_path}\")\n",
    "    if lidar2xrf_path:\n",
    "        print(f\"  LIDAR to XRF: {lidar2xrf_path}\")\n",
    "    if bpc_path:\n",
    "        print(f\"  BPC File: {bpc_path}\")\n",
    "    if intensity_path:\n",
    "        print(f\"  Intensity File: {intensity_path}\")\n",
    "    if lidar_times_path:\n",
    "        print(f\"  lidar time stamps file: {lidar_times_path}\")\n",
    "    if real_dbg_path:\n",
    "        print(f\"  real dbg file: {real_dbg_path}\")\n",
    "\n",
    "valid = np.sum([all(item is not None for item in sublist) for sublist in paths_list])\n",
    "\n",
    "print(f\"{len(paths_list)} part paths found\")\n",
    "print(f\"{valid} valid paths found\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Get the point clouds\n",
    "point_clouds = []\n",
    "\n",
    "for paths in paths_list:\n",
    "    if None not in paths:\n",
    "        point_clouds.append(get_point_cloud(paths, upsample_ratio= 0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectors = get_vectors(point_clouds)\n",
    "\n",
    "print(f\"{len(vectors)} vectors loaded\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if True:\n",
    "    fig = plt.figure(figsize=(150, 1.5 * len(point_clouds)), dpi=150)  \n",
    "    gs = fig.add_gridspec(int(len(point_clouds) *2) + 1, 1, hspace=0.25)  \n",
    "    \n",
    "    for (i, point_cloud) in enumerate(point_clouds):\n",
    "        cloud_name = point_cloud[0]\n",
    "        cloud_1 = point_cloud[heights]\n",
    "        cloud_2 = point_cloud[intensity]\n",
    "        \n",
    "    \n",
    "        ax = fig.add_subplot(gs[i * 2, 0])\n",
    "        ax.imshow(np.flipud(cloud_1), cmap='nipy_spectral', interpolation='nearest', alpha = 1)    \n",
    "        ax.set_xlabel(\"X index\")\n",
    "        ax.set_ylabel(\"Y index\")\n",
    "        ax.set_title(f\"Point Cloud: {cloud_name}\", fontsize =7 ) \n",
    "    \n",
    "        ax = fig.add_subplot(gs[i* 2 + 1, 0])\n",
    "        ax.imshow(np.flipud(cloud_2), cmap='bone', interpolation='nearest', alpha = 1)    \n",
    "        ax.set_xlabel(\"X index\")\n",
    "        ax.set_ylabel(\"Y index\") \n",
    "    \n",
    "    \n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if plot_cluster_1:\n",
    "    fig = plt.figure(figsize=(15, 4), dpi=100)\n",
    "    gs = fig.add_gridspec(1, 1)\n",
    "    ax = fig.add_subplot(gs[0, 0])\n",
    "\n",
    "    x_vals = [v[2] for v in vectors]\n",
    "    y_vals = [v[3] for v in vectors]\n",
    "\n",
    "    ax.set_xlabel(\"skew\")\n",
    "    ax.set_ylabel(\"Azimuthal angle\")\n",
    "\n",
    "    ax.scatter(x_vals, y_vals, color=\"red\", s=1)\n",
    "\n",
    "    a = 0.1\n",
    "    s = 7\n",
    "    t = 6.5\n",
    "    x_func = np.linspace(-1, 1, 100)\n",
    "    y_func = (t - (1 / np.sqrt(2 * np.pi * a**2)) * np.exp(-((x_func)**2) / (2 * a**2))) / s\n",
    "\n",
    "    ax.plot(x_func, y_func, color='cyan', linestyle='--', linewidth=2, label=\"gauss\")\n",
    "\n",
    "    triangle_x = [0.5, 0.775, 0.5, 0.5]\n",
    "    triangle_y = [0.6, 0.55, 0.4, 0.6]\n",
    "\n",
    "    ax.plot(triangle_x, triangle_y, color='magenta', linestyle='-', linewidth=2, label=\"Triangle\")\n",
    "\n",
    "\n",
    "\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if plot_cluster_1:\n",
    "    fig = plt.figure(figsize=(15, 4), dpi=100)\n",
    "    gs = fig.add_gridspec(1, 1)\n",
    "    ax = fig.add_subplot(gs[0, 0])\n",
    "\n",
    "    x_vals = [v[0] for v in vectors]\n",
    "    y_vals = [v[1] for v in vectors]\n",
    "\n",
    "    ax.set_xlabel(\"skew\")\n",
    "    ax.set_ylabel(\"Azimuthal angle\")\n",
    "\n",
    "    ax.scatter(x_vals, y_vals, color=\"red\", s=1)\n",
    "\n",
    "    a = 0.1\n",
    "    s = 7\n",
    "    t = 6.5\n",
    "    x_func = np.linspace(-1, 1, 100)\n",
    "    y_func = (t - (1 / np.sqrt(2 * np.pi * a**2)) * np.exp(-((x_func)**2) / (2 * a**2))) / s\n",
    "\n",
    "    ax.plot(x_func, y_func, color='cyan', linestyle='--', linewidth=2, label=\"gauss\")\n",
    "\n",
    "    triangle_x = [0.5, 0.775, 0.5, 0.5]\n",
    "    triangle_y = [0.6, 0.55, 0.4, 0.6]\n",
    "\n",
    "    ax.plot(triangle_x, triangle_y, color='magenta', linestyle='-', linewidth=2, label=\"Triangle\")\n",
    "\n",
    "\n",
    "\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if plot_cluster_2:\n",
    "    x = [v[1] for v in vectors]\n",
    "    y = [v[2] for v in vectors]\n",
    "    z = [v[3] for v in vectors]\n",
    "    c = [v[0] for v in vectors]\n",
    "\n",
    "    ds_f = 5\n",
    "\n",
    "    x = x[::ds_f]\n",
    "    y = y[::ds_f]\n",
    "    z = z[::ds_f]\n",
    "    c = c[::ds_f]\n",
    "\n",
    "\n",
    "    fig = go.Figure(data=[go.Scatter3d(\n",
    "        x=x, y=y, z=z,\n",
    "        mode='markers',\n",
    "        marker=dict(size=1.3, color=c, opacity=1),\n",
    "    )])\n",
    "\n",
    "    fig.update_layout(\n",
    "        title=\"3D Scatter of Vectors\",\n",
    "        scene=dict(\n",
    "            xaxis_title=\"mean\",\n",
    "            yaxis_title=\"skew\",\n",
    "            zaxis_title=\"azimuthal angle\",\n",
    "            camera=dict(projection=dict(type=\"orthographic\"))\n",
    "        ),\n",
    "        width=1200,\n",
    "        height=600\n",
    "    )\n",
    "\n",
    "    fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stop #only add vectors once the vector space has been normalized (correct window_height)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#add vectors to csv\n",
    "file_path = 'distribution_vectors.csv'\n",
    "\n",
    "with open(file_path, mode='a', newline='') as file:\n",
    "    writer = csv.writer(file)\n",
    "    for value in vectors:\n",
    "        writer.writerow([value])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#filter out repeated vectors \n",
    "import ast\n",
    "\n",
    "with open('distribution_vectors.csv', 'r') as file:\n",
    "    data = file.read()\n",
    "\n",
    "vectors = [ast.literal_eval(vec) for vec in data.strip().split('\"') if vec.strip()]\n",
    "vectors = np.array(vectors)\n",
    "print(vectors.shape)\n",
    "unique_vectors = np.unique(vectors, axis = 0)\n",
    "print(unique_vectors.shape)\n",
    "\n",
    "with open('distribution_vectors.csv', 'w') as file:\n",
    "    for vec in unique_vectors:\n",
    "        file.write(f'\"{list(vec)}\"\\n')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "new_env2",
   "language": "python",
   "name": "new_env2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
